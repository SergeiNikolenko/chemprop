{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jZnD-vU9Fd-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGZxehx_44Rj",
        "outputId": "80a3e295-1e8e-4f1e-ad31-cba1a0719aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting chemprop\n",
            "  Downloading chemprop-1.6.1-py3-none-any.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (3.0.0)\n",
            "Requirement already satisfied: hyperopt>=0.2.3 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (0.2.7)\n",
            "Requirement already satisfied: matplotlib>=3.1.3 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (1.26.2)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (1.5.3)\n",
            "Requirement already satisfied: pandas-flavor>=0.2.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (0.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (1.3.2)\n",
            "Collecting sphinx>=3.1.2 (from chemprop)\n",
            "  Downloading sphinx-7.2.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tensorboardX>=2.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (2.6.2.2)\n",
            "Requirement already satisfied: torch>=1.4.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (2.1.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (4.65.0)\n",
            "Collecting typed-argument-parser>=1.6.1 (from chemprop)\n",
            "  Downloading typed-argument-parser-1.9.0.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: rdkit>=2020.03.1.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from chemprop) (2023.9.2)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from flask>=1.1.2->chemprop) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from flask>=1.1.2->chemprop) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from flask>=1.1.2->chemprop) (2.1.2)\n",
            "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from flask>=1.1.2->chemprop) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from flask>=1.1.2->chemprop) (1.7.0)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (1.11.4)\n",
            "Requirement already satisfied: six in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (3.0)\n",
            "Requirement already satisfied: future in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (3.0.0)\n",
            "Requirement already satisfied: py4j in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from hyperopt>=0.2.3->chemprop) (0.10.9.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from matplotlib>=3.1.3->chemprop) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from matplotlib>=3.1.3->chemprop) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from matplotlib>=3.1.3->chemprop) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from matplotlib>=3.1.3->chemprop) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from matplotlib>=3.1.3->chemprop) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from pandas>=1.0.3->chemprop) (2023.3.post1)\n",
            "Requirement already satisfied: xarray in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from pandas-flavor>=0.2.0->chemprop) (2023.12.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->chemprop) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->chemprop) (3.2.0)\n",
            "Collecting sphinxcontrib-applehelp (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting sphinxcontrib-devhelp (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting sphinxcontrib-jsmath (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-htmlhelp>=2.0.0 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting sphinxcontrib-qthelp (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: Pygments>=2.14 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from sphinx>=3.1.2->chemprop) (2.15.1)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting snowballstemmer>=2.0 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting babel>=2.9 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting alabaster<0.8,>=0.7 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting imagesize>=1.3 (from sphinx>=3.1.2->chemprop)\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: requests>=2.25.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from sphinx>=3.1.2->chemprop) (2.28.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from sphinx>=3.1.2->chemprop) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from tensorboardX>=2.0->chemprop) (4.23.4)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from torch>=1.4.0->chemprop) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from torch>=1.4.0->chemprop) (4.9.0)\n",
            "Requirement already satisfied: sympy in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from torch>=1.4.0->chemprop) (1.12)\n",
            "Requirement already satisfied: fsspec in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from torch>=1.4.0->chemprop) (2023.4.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from torch>=1.4.0->chemprop) (2.1.0)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser>=1.6.1->chemprop)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting docstring-parser>=0.15 (from typed-argument-parser>=1.6.1->chemprop)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask>=1.1.2->chemprop) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=3.1.2->chemprop) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=3.1.2->chemprop) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=3.1.2->chemprop) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=3.1.2->chemprop) (2024.2.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser>=1.6.1->chemprop)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from sympy->torch>=1.4.0->chemprop) (1.3.0)\n",
            "Downloading chemprop-1.6.1-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx-7.2.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n",
            "Downloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.0.5-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_serializinghtml-1.1.10-py3-none-any.whl (92 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading sphinxcontrib_applehelp-1.0.8-py3-none-any.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_devhelp-1.0.6-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_qthelp-1.0.7-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: typed-argument-parser\n",
            "  Building wheel for typed-argument-parser (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for typed-argument-parser: filename=typed_argument_parser-1.9.0-py3-none-any.whl size=25614 sha256=7d2004b9a89e736bc2d7b7303626da86fb5fd3d19e1d832d200cf8aa049d3f3b\n",
            "  Stored in directory: /home/nikolenko/.cache/pip/wheels/f0/94/0f/9539f578bed7e1bd423c702e403712f5ee8989f831a71db000\n",
            "Successfully built typed-argument-parser\n",
            "Installing collected packages: snowballstemmer, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, mypy-extensions, imagesize, docutils, docstring-parser, babel, alabaster, typing-inspect, sphinx, typed-argument-parser, chemprop\n",
            "Successfully installed alabaster-0.7.16 babel-2.14.0 chemprop-1.6.1 docstring-parser-0.15 docutils-0.20.1 imagesize-1.4.1 mypy-extensions-1.0.0 snowballstemmer-2.2.0 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.8 sphinxcontrib-devhelp-1.0.6 sphinxcontrib-htmlhelp-2.0.5 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.7 sphinxcontrib-serializinghtml-1.1.10 typed-argument-parser-1.9.0 typing-inspect-0.9.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from rdkit-pypi) (1.26.2)\n",
            "Requirement already satisfied: Pillow in /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages (from rdkit-pypi) (9.4.0)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.5\n",
            "/bin/bash: line 1: apt: command not found\n",
            "/bin/bash: line 1: svn: command not found\n"
          ]
        }
      ],
      "source": [
        "import chemprop\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import AnchoredText\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZVmFInN_qj4n"
      },
      "outputs": [],
      "source": [
        "def plot_parity(y_true, y_pred, y_pred_unc=None):\n",
        "    \n",
        "    axmin = min(min(y_true), min(y_pred)) - 0.1*(max(y_true)-min(y_true))\n",
        "    axmax = max(max(y_true), max(y_pred)) + 0.1*(max(y_true)-min(y_true))\n",
        "    \n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    \n",
        "    plt.plot([axmin, axmax], [axmin, axmax], '--k')\n",
        "\n",
        "    plt.errorbar(y_true, y_pred, yerr=y_pred_unc, linewidth=0, marker='o', markeredgecolor='w', alpha=1, elinewidth=1)\n",
        "    \n",
        "    plt.xlim((axmin, axmax))\n",
        "    plt.ylim((axmin, axmax))\n",
        "    \n",
        "    ax = plt.gca()\n",
        "    ax.set_aspect('equal')\n",
        "    \n",
        "    at = AnchoredText(\n",
        "    f\"MAE = {mae:.2f}\\nRMSE = {rmse:.2f}\", prop=dict(size=10), frameon=True, loc='upper left')\n",
        "    at.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\n",
        "    ax.add_artist(at)\n",
        "    \n",
        "    plt.xlabel('True')\n",
        "    plt.ylabel('Chemprop Predicted')\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ67V6hr_6Yz"
      },
      "source": [
        "# Train regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqtogu2T7OTd",
        "outputId": "afdbf19a-9d76-4fb3-bc2c-038101585f7c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /opt/anaconda3/envs/chemprop-atom-bond/lib/python3.10/site-packages/ipykernel_launcher.py --f=/home/nikolenko/.local/share/jupyter/runtime/kernel-v2-2131239J0V7lC3C37R3.json\n",
            "Args\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'activation': 'ReLU',\n",
            " 'adding_bond_types': True,\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_constraints': [],\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'atom_targets': [],\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_constraints': [],\n",
            " 'bond_descriptor_scaling': True,\n",
            " 'bond_descriptors': None,\n",
            " 'bond_descriptors_path': None,\n",
            " 'bond_descriptors_size': 0,\n",
            " 'bond_features_size': 0,\n",
            " 'bond_targets': [],\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'constraints_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': True,\n",
            " 'data_path': 'tests/data/regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cuda'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 1000,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'ignore_nan_metrics': False,\n",
            " 'init_lr': 0.0001,\n",
            " 'is_atom_bond_targets': False,\n",
            " 'keeping_atom_map': False,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_adding_bond_types': False,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_descriptor_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'no_shared_atom_bond_ffn': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 16,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_reg',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_descriptors_path': None,\n",
            " 'separate_test_constraints_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_descriptors_path': None,\n",
            " 'separate_val_constraints_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'shared_atom_bond_ffn': True,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['logSolubility'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0,\n",
            " 'weights_ffn_num_layers': 2}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 295207.21it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 220312.22it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 130322.64it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "0it [00:00, ?it/s]Warning: Repeated SMILES found in data, pickle file of split indices cannot distinguish entries and will not be generated.\n",
            "276it [00:00, 250949.04it/s]\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (readout): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 355,201\n",
            "Moving model to cuda\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0\n",
            "Validation rmse = 1.706184\n",
            "  0%|          | 1/1000 [00:00<04:23,  3.79it/s]Epoch 1\n",
            "Loss = 6.5336e-01, PNorm = 34.0271, GNorm = 6.2553, lr_0 = 7.1875e-04\n",
            "Validation rmse = 1.387885\n",
            "  0%|          | 2/1000 [00:00<04:27,  3.73it/s]Epoch 2\n",
            "Loss = 4.5432e-01, PNorm = 34.0849, GNorm = 9.2827, lr_0 = 9.9856e-04\n",
            "Validation rmse = 1.360534\n",
            "  0%|          | 3/1000 [00:00<04:24,  3.76it/s]Epoch 3\n",
            "Loss = 4.1107e-01, PNorm = 34.1440, GNorm = 10.8940, lr_0 = 9.9568e-04\n",
            "Validation rmse = 1.213822\n",
            "  0%|          | 4/1000 [00:01<04:23,  3.78it/s]Epoch 4\n",
            "Loss = 2.8775e-01, PNorm = 34.1932, GNorm = 6.3140, lr_0 = 9.9282e-04\n",
            "Validation rmse = 1.116338\n",
            "  0%|          | 5/1000 [00:01<04:22,  3.79it/s]Epoch 5\n",
            "Validation rmse = 1.223771\n",
            "  1%|          | 6/1000 [00:01<04:08,  4.00it/s]Epoch 6\n",
            "Loss = 2.6472e-01, PNorm = 34.2360, GNorm = 3.9318, lr_0 = 9.8996e-04\n",
            "Validation rmse = 1.009787\n",
            "  1%|          | 7/1000 [00:01<04:12,  3.93it/s]Epoch 7\n",
            "Loss = 1.8030e-01, PNorm = 34.2796, GNorm = 2.6117, lr_0 = 9.8711e-04\n",
            "Validation rmse = 0.931194\n",
            "  1%|          | 8/1000 [00:02<04:59,  3.31it/s]Epoch 8\n",
            "Loss = 1.7183e-01, PNorm = 34.3285, GNorm = 2.6430, lr_0 = 9.8426e-04\n",
            "Validation rmse = 0.873566\n",
            "  1%|          | 9/1000 [00:02<04:47,  3.45it/s]Epoch 9\n",
            "Loss = 1.4520e-01, PNorm = 34.3692, GNorm = 1.7800, lr_0 = 9.8143e-04\n",
            "Validation rmse = 0.819039\n",
            "  1%|          | 10/1000 [00:02<04:39,  3.54it/s]Epoch 10\n",
            "Validation rmse = 0.804226\n",
            "  1%|          | 11/1000 [00:03<04:34,  3.61it/s]Epoch 11\n",
            "Loss = 1.4594e-01, PNorm = 34.4104, GNorm = 7.6603, lr_0 = 9.7860e-04\n",
            "Validation rmse = 0.852307\n",
            "  1%|          | 12/1000 [00:03<04:19,  3.81it/s]Epoch 12\n",
            "Loss = 1.5470e-01, PNorm = 34.4472, GNorm = 4.8871, lr_0 = 9.7578e-04\n",
            "Validation rmse = 1.055779\n",
            "  1%|▏         | 13/1000 [00:03<04:08,  3.98it/s]Epoch 13\n",
            "Loss = 1.8202e-01, PNorm = 34.4869, GNorm = 8.2109, lr_0 = 9.7297e-04\n",
            "Validation rmse = 0.827967\n",
            "  1%|▏         | 14/1000 [00:03<04:00,  4.10it/s]Epoch 14\n",
            "Loss = 1.7297e-01, PNorm = 34.5310, GNorm = 3.9730, lr_0 = 9.7017e-04\n",
            "Validation rmse = 0.979382\n",
            "  2%|▏         | 15/1000 [00:03<03:56,  4.17it/s]Epoch 15\n",
            "Validation rmse = 0.738575\n",
            "  2%|▏         | 16/1000 [00:04<04:03,  4.05it/s]Epoch 16\n",
            "Loss = 1.2205e-01, PNorm = 34.5710, GNorm = 3.9282, lr_0 = 9.6738e-04\n",
            "Validation rmse = 0.788523\n",
            "  2%|▏         | 17/1000 [00:04<03:57,  4.15it/s]Epoch 17\n",
            "Loss = 9.4042e-02, PNorm = 34.6081, GNorm = 5.4745, lr_0 = 9.6459e-04\n",
            "Validation rmse = 0.720042\n",
            "  2%|▏         | 18/1000 [00:04<04:03,  4.03it/s]Epoch 18\n",
            "Loss = 8.4166e-02, PNorm = 34.6469, GNorm = 2.4374, lr_0 = 9.6181e-04\n",
            "Validation rmse = 0.686057\n",
            "  2%|▏         | 19/1000 [00:04<04:07,  3.96it/s]Epoch 19\n",
            "Loss = 7.6028e-02, PNorm = 34.6808, GNorm = 1.5223, lr_0 = 9.5904e-04\n",
            "Validation rmse = 0.722833\n",
            "  2%|▏         | 20/1000 [00:05<04:00,  4.07it/s]Epoch 20\n",
            "Validation rmse = 0.685647\n",
            "  2%|▏         | 21/1000 [00:05<04:06,  3.98it/s]Epoch 21\n",
            "Loss = 7.1863e-02, PNorm = 34.7156, GNorm = 3.2878, lr_0 = 9.5628e-04\n",
            "Validation rmse = 0.774265\n",
            "  2%|▏         | 22/1000 [00:05<03:58,  4.10it/s]Epoch 22\n",
            "Loss = 7.1896e-02, PNorm = 34.7488, GNorm = 2.3312, lr_0 = 9.5353e-04\n",
            "Validation rmse = 0.788115\n",
            "  2%|▏         | 23/1000 [00:05<03:53,  4.19it/s]Epoch 23\n",
            "Loss = 7.9547e-02, PNorm = 34.7855, GNorm = 7.0098, lr_0 = 9.5078e-04\n",
            "Validation rmse = 0.836003\n",
            "  2%|▏         | 24/1000 [00:06<03:49,  4.26it/s]Epoch 24\n",
            "Loss = 1.0488e-01, PNorm = 34.8223, GNorm = 3.3744, lr_0 = 9.4804e-04\n",
            "Validation rmse = 0.806420\n",
            "  2%|▎         | 25/1000 [00:06<03:46,  4.31it/s]Epoch 25\n",
            "Validation rmse = 0.756775\n",
            "  3%|▎         | 26/1000 [00:06<03:43,  4.35it/s]Epoch 26\n",
            "Loss = 1.1285e-01, PNorm = 34.8592, GNorm = 2.7031, lr_0 = 9.4531e-04\n",
            "Validation rmse = 0.998340\n",
            "  3%|▎         | 27/1000 [00:06<03:42,  4.37it/s]Epoch 27\n",
            "Loss = 1.2819e-01, PNorm = 34.8999, GNorm = 6.3549, lr_0 = 9.4259e-04\n",
            "Validation rmse = 0.813974\n",
            "  3%|▎         | 28/1000 [00:07<03:42,  4.37it/s]Epoch 28\n",
            "Loss = 8.6552e-02, PNorm = 34.9439, GNorm = 2.7772, lr_0 = 9.3988e-04\n",
            "Validation rmse = 0.695918\n",
            "  3%|▎         | 29/1000 [00:07<03:41,  4.38it/s]Epoch 29\n",
            "Loss = 5.9934e-02, PNorm = 34.9830, GNorm = 0.6732, lr_0 = 9.3717e-04\n",
            "Validation rmse = 0.709139\n",
            "  3%|▎         | 30/1000 [00:07<03:40,  4.39it/s]Epoch 30\n",
            "Validation rmse = 0.653701\n",
            "  3%|▎         | 31/1000 [00:07<03:50,  4.20it/s]Epoch 31\n",
            "Loss = 5.3288e-02, PNorm = 35.0239, GNorm = 2.7436, lr_0 = 9.3447e-04\n",
            "Validation rmse = 0.689471\n",
            "  3%|▎         | 32/1000 [00:07<03:46,  4.27it/s]Epoch 32\n",
            "Loss = 5.4099e-02, PNorm = 35.0590, GNorm = 2.0051, lr_0 = 9.3178e-04\n",
            "Validation rmse = 0.708380\n",
            "  3%|▎         | 33/1000 [00:08<03:44,  4.32it/s]Epoch 33\n",
            "Loss = 5.6243e-02, PNorm = 35.0942, GNorm = 4.0914, lr_0 = 9.2910e-04\n",
            "Validation rmse = 0.742678\n",
            "  3%|▎         | 34/1000 [00:08<03:41,  4.36it/s]Epoch 34\n",
            "Loss = 4.7035e-02, PNorm = 35.1326, GNorm = 1.9090, lr_0 = 9.2642e-04\n",
            "Validation rmse = 0.700753\n",
            "  4%|▎         | 35/1000 [00:08<03:40,  4.37it/s]Epoch 35\n",
            "Validation rmse = 0.687518\n",
            "  4%|▎         | 36/1000 [00:08<03:39,  4.40it/s]Epoch 36\n",
            "Loss = 4.0765e-02, PNorm = 35.1684, GNorm = 1.3476, lr_0 = 9.2375e-04\n",
            "Validation rmse = 0.697929\n",
            "  4%|▎         | 37/1000 [00:09<03:38,  4.40it/s]Epoch 37\n",
            "Loss = 3.4231e-02, PNorm = 35.2048, GNorm = 1.1247, lr_0 = 9.2109e-04\n",
            "Validation rmse = 0.693057\n",
            "  4%|▍         | 38/1000 [00:09<03:38,  4.40it/s]Epoch 38\n",
            "Loss = 4.5345e-02, PNorm = 35.2363, GNorm = 1.5877, lr_0 = 9.1844e-04\n",
            "Validation rmse = 0.689101\n",
            "  4%|▍         | 39/1000 [00:09<03:38,  4.40it/s]Epoch 39\n",
            "Loss = 4.1609e-02, PNorm = 35.2690, GNorm = 3.2226, lr_0 = 9.1580e-04\n",
            "Validation rmse = 0.700931\n",
            "  4%|▍         | 40/1000 [00:09<03:37,  4.41it/s]Epoch 40\n",
            "Validation rmse = 0.732066\n",
            "  4%|▍         | 41/1000 [00:09<03:36,  4.43it/s]Epoch 41\n",
            "Loss = 4.5901e-02, PNorm = 35.3023, GNorm = 2.3355, lr_0 = 9.1316e-04\n",
            "Validation rmse = 0.656146\n",
            "  4%|▍         | 42/1000 [00:10<03:36,  4.43it/s]Epoch 42\n",
            "Loss = 4.3472e-02, PNorm = 35.3356, GNorm = 3.0697, lr_0 = 9.1053e-04\n",
            "Validation rmse = 0.781175\n",
            "  4%|▍         | 43/1000 [00:10<03:35,  4.44it/s]Epoch 43\n",
            "Loss = 5.1421e-02, PNorm = 35.3673, GNorm = 2.6369, lr_0 = 9.0791e-04\n",
            "Validation rmse = 0.682812\n",
            "  4%|▍         | 44/1000 [00:10<03:35,  4.43it/s]Epoch 44\n",
            "Loss = 5.1415e-02, PNorm = 35.4045, GNorm = 0.5260, lr_0 = 9.0529e-04\n",
            "Validation rmse = 0.767395\n",
            "  4%|▍         | 45/1000 [00:10<03:35,  4.43it/s]Epoch 45\n",
            "Validation rmse = 0.695129\n",
            "  5%|▍         | 46/1000 [00:11<03:35,  4.44it/s]Epoch 46\n",
            "Loss = 2.8026e-02, PNorm = 35.4346, GNorm = 1.6429, lr_0 = 9.0268e-04\n",
            "Validation rmse = 0.699972\n",
            "  5%|▍         | 47/1000 [00:11<03:34,  4.43it/s]Epoch 47\n",
            "Loss = 3.5957e-02, PNorm = 35.4636, GNorm = 1.3880, lr_0 = 9.0009e-04\n",
            "Validation rmse = 0.755326\n",
            "  5%|▍         | 48/1000 [00:11<03:34,  4.44it/s]Epoch 48\n",
            "Loss = 3.5869e-02, PNorm = 35.4949, GNorm = 3.4831, lr_0 = 8.9749e-04\n",
            "Validation rmse = 0.756061\n",
            "  5%|▍         | 49/1000 [00:11<03:35,  4.42it/s]Epoch 49\n",
            "Loss = 4.5190e-02, PNorm = 35.5257, GNorm = 2.2703, lr_0 = 8.9491e-04\n",
            "Validation rmse = 0.880711\n",
            "  5%|▌         | 50/1000 [00:12<03:34,  4.42it/s]Epoch 50\n",
            "Validation rmse = 0.872928\n",
            "  5%|▌         | 51/1000 [00:12<03:34,  4.43it/s]Epoch 51\n",
            "Loss = 5.4308e-02, PNorm = 35.5581, GNorm = 0.7866, lr_0 = 8.9233e-04\n",
            "Validation rmse = 0.790269\n",
            "  5%|▌         | 52/1000 [00:12<03:34,  4.43it/s]Epoch 52\n",
            "Loss = 3.3677e-02, PNorm = 35.5903, GNorm = 1.8887, lr_0 = 8.8976e-04\n",
            "Validation rmse = 0.686334\n",
            "  5%|▌         | 53/1000 [00:12<03:33,  4.43it/s]Epoch 53\n",
            "Loss = 3.1880e-02, PNorm = 35.6201, GNorm = 2.7887, lr_0 = 8.8720e-04\n",
            "Validation rmse = 0.835325\n",
            "  5%|▌         | 54/1000 [00:12<03:34,  4.42it/s]Epoch 54\n",
            "Loss = 3.8814e-02, PNorm = 35.6460, GNorm = 2.1039, lr_0 = 8.8464e-04\n",
            "Validation rmse = 0.763801\n",
            "  6%|▌         | 55/1000 [00:13<03:33,  4.43it/s]Epoch 55\n",
            "Validation rmse = 0.749394\n",
            "  6%|▌         | 56/1000 [00:13<03:32,  4.44it/s]Epoch 56\n",
            "Loss = 2.4141e-02, PNorm = 35.6792, GNorm = 0.6572, lr_0 = 8.8210e-04\n",
            "Validation rmse = 0.695358\n",
            "  6%|▌         | 57/1000 [00:13<03:32,  4.44it/s]Epoch 57\n",
            "Loss = 1.7429e-02, PNorm = 35.7040, GNorm = 0.7115, lr_0 = 8.7956e-04\n",
            "Validation rmse = 0.707388\n",
            "  6%|▌         | 58/1000 [00:13<03:31,  4.45it/s]Epoch 58\n",
            "Loss = 1.8048e-02, PNorm = 35.7290, GNorm = 0.8879, lr_0 = 8.7702e-04\n",
            "Validation rmse = 0.736170\n",
            "  6%|▌         | 59/1000 [00:14<03:31,  4.45it/s]Epoch 59\n",
            "Loss = 2.2057e-02, PNorm = 35.7517, GNorm = 1.2370, lr_0 = 8.7450e-04\n",
            "Validation rmse = 0.724522\n",
            "  6%|▌         | 60/1000 [00:14<03:32,  4.43it/s]Epoch 60\n",
            "Validation rmse = 0.749381\n",
            "  6%|▌         | 61/1000 [00:14<03:31,  4.45it/s]Epoch 61\n",
            "Loss = 3.0554e-02, PNorm = 35.7752, GNorm = 2.3280, lr_0 = 8.7198e-04\n",
            "Validation rmse = 0.729229\n",
            "  6%|▌         | 62/1000 [00:14<03:31,  4.45it/s]Epoch 62\n",
            "Loss = 2.2482e-02, PNorm = 35.7995, GNorm = 0.6662, lr_0 = 8.6947e-04\n",
            "Validation rmse = 0.695529\n",
            "  6%|▋         | 63/1000 [00:14<03:31,  4.43it/s]Epoch 63\n",
            "Loss = 1.6505e-02, PNorm = 35.8236, GNorm = 0.8518, lr_0 = 8.6696e-04\n",
            "Validation rmse = 0.743090\n",
            "  6%|▋         | 64/1000 [00:15<03:31,  4.43it/s]Epoch 64\n",
            "Loss = 2.5700e-02, PNorm = 35.8460, GNorm = 0.4606, lr_0 = 8.6447e-04\n",
            "Validation rmse = 0.784828\n",
            "  6%|▋         | 65/1000 [00:15<03:31,  4.43it/s]Epoch 65\n",
            "Validation rmse = 0.791294\n",
            "  7%|▋         | 66/1000 [00:15<03:30,  4.43it/s]Epoch 66\n",
            "Loss = 2.3085e-02, PNorm = 35.8700, GNorm = 1.1571, lr_0 = 8.6198e-04\n",
            "Validation rmse = 0.751328\n",
            "  7%|▋         | 67/1000 [00:15<03:30,  4.44it/s]Epoch 67\n",
            "Loss = 1.7981e-02, PNorm = 35.8960, GNorm = 0.8220, lr_0 = 8.5950e-04\n",
            "Validation rmse = 0.732376\n",
            "  7%|▋         | 68/1000 [00:16<03:30,  4.44it/s]Epoch 68\n",
            "Loss = 2.0030e-02, PNorm = 35.9199, GNorm = 1.4569, lr_0 = 8.5702e-04\n",
            "Validation rmse = 0.731484\n",
            "  7%|▋         | 69/1000 [00:16<03:30,  4.43it/s]Epoch 69\n",
            "Loss = 2.8347e-02, PNorm = 35.9431, GNorm = 0.8427, lr_0 = 8.5455e-04\n",
            "Validation rmse = 0.747337\n",
            "  7%|▋         | 70/1000 [00:16<03:29,  4.43it/s]Epoch 70\n",
            "Validation rmse = 0.780640\n",
            "  7%|▋         | 71/1000 [00:16<03:28,  4.45it/s]Epoch 71\n",
            "Loss = 1.4321e-02, PNorm = 35.9703, GNorm = 0.6395, lr_0 = 8.5209e-04\n",
            "Validation rmse = 0.719016\n",
            "  7%|▋         | 72/1000 [00:16<03:28,  4.44it/s]Epoch 72\n",
            "Loss = 1.6450e-02, PNorm = 35.9926, GNorm = 1.7183, lr_0 = 8.4964e-04\n",
            "Validation rmse = 0.782067\n",
            "  7%|▋         | 73/1000 [00:17<03:28,  4.44it/s]Epoch 73\n",
            "Loss = 1.7811e-02, PNorm = 36.0146, GNorm = 0.9271, lr_0 = 8.4719e-04\n",
            "Validation rmse = 0.723003\n",
            "  7%|▋         | 74/1000 [00:17<03:28,  4.44it/s]Epoch 74\n",
            "Loss = 1.6051e-02, PNorm = 36.0357, GNorm = 1.6207, lr_0 = 8.4475e-04\n",
            "Validation rmse = 0.788918\n",
            "  8%|▊         | 75/1000 [00:17<03:28,  4.44it/s]Epoch 75\n",
            "Validation rmse = 0.739774\n",
            "  8%|▊         | 76/1000 [00:17<03:28,  4.44it/s]Epoch 76\n",
            "Loss = 2.1055e-02, PNorm = 36.0551, GNorm = 2.2556, lr_0 = 8.4232e-04\n",
            "Validation rmse = 0.841420\n",
            "  8%|▊         | 77/1000 [00:18<03:27,  4.44it/s]Epoch 77\n",
            "Loss = 2.5159e-02, PNorm = 36.0805, GNorm = 2.1587, lr_0 = 8.3989e-04\n",
            "Validation rmse = 0.733051\n",
            "  8%|▊         | 78/1000 [00:18<03:27,  4.44it/s]Epoch 78\n",
            "Loss = 1.8875e-02, PNorm = 36.1046, GNorm = 0.8150, lr_0 = 8.3747e-04\n",
            "Validation rmse = 0.799083\n",
            "  8%|▊         | 79/1000 [00:18<03:27,  4.44it/s]Epoch 79\n",
            "Loss = 1.8349e-02, PNorm = 36.1293, GNorm = 0.6817, lr_0 = 8.3506e-04\n",
            "Validation rmse = 0.741948\n",
            "  8%|▊         | 80/1000 [00:18<03:28,  4.42it/s]Epoch 80\n",
            "Validation rmse = 0.802837\n",
            "  8%|▊         | 81/1000 [00:19<03:27,  4.43it/s]Epoch 81\n",
            "Loss = 3.0033e-02, PNorm = 36.1491, GNorm = 2.4149, lr_0 = 8.3266e-04\n",
            "Validation rmse = 0.732000\n",
            "  8%|▊         | 82/1000 [00:19<04:09,  3.67it/s]Epoch 82\n",
            "Loss = 1.4218e-02, PNorm = 36.1747, GNorm = 1.2248, lr_0 = 8.3026e-04\n",
            "Validation rmse = 0.798684\n",
            "  8%|▊         | 83/1000 [00:19<03:57,  3.86it/s]Epoch 83\n",
            "Loss = 1.6732e-02, PNorm = 36.1926, GNorm = 1.0928, lr_0 = 8.2787e-04\n",
            "Validation rmse = 0.699116\n",
            "  8%|▊         | 84/1000 [00:19<03:49,  3.99it/s]Epoch 84\n",
            "Loss = 1.5884e-02, PNorm = 36.2129, GNorm = 1.7119, lr_0 = 8.2548e-04\n",
            "Validation rmse = 0.767745\n",
            "  8%|▊         | 85/1000 [00:20<03:42,  4.11it/s]Epoch 85\n",
            "Validation rmse = 0.732371\n",
            "  9%|▊         | 86/1000 [00:20<03:37,  4.21it/s]Epoch 86\n",
            "Loss = 1.6444e-02, PNorm = 36.2302, GNorm = 1.5394, lr_0 = 8.2311e-04\n",
            "Validation rmse = 0.732229\n",
            "  9%|▊         | 87/1000 [00:20<03:33,  4.27it/s]Epoch 87\n",
            "Loss = 1.0528e-02, PNorm = 36.2455, GNorm = 0.2931, lr_0 = 8.2074e-04\n",
            "Validation rmse = 0.742811\n",
            "  9%|▉         | 88/1000 [00:20<03:30,  4.32it/s]Epoch 88\n",
            "Loss = 1.3942e-02, PNorm = 36.2619, GNorm = 0.7467, lr_0 = 8.1837e-04\n",
            "Validation rmse = 0.774004\n",
            "  9%|▉         | 89/1000 [00:20<03:29,  4.36it/s]Epoch 89\n",
            "Loss = 1.6562e-02, PNorm = 36.2771, GNorm = 0.9816, lr_0 = 8.1602e-04\n",
            "Validation rmse = 0.728916\n",
            "  9%|▉         | 90/1000 [00:21<03:27,  4.38it/s]Epoch 90\n",
            "Validation rmse = 0.741431\n",
            "  9%|▉         | 91/1000 [00:21<03:26,  4.40it/s]Epoch 91\n",
            "Loss = 1.1781e-02, PNorm = 36.2962, GNorm = 1.2098, lr_0 = 8.1367e-04\n",
            "Validation rmse = 0.739162\n",
            "  9%|▉         | 92/1000 [00:21<03:25,  4.41it/s]Epoch 92\n",
            "Loss = 9.6674e-03, PNorm = 36.3119, GNorm = 0.6409, lr_0 = 8.1132e-04\n",
            "Validation rmse = 0.737413\n",
            "  9%|▉         | 93/1000 [00:21<03:25,  4.41it/s]Epoch 93\n",
            "Loss = 9.6892e-03, PNorm = 36.3280, GNorm = 0.3705, lr_0 = 8.0899e-04\n",
            "Validation rmse = 0.743034\n",
            "  9%|▉         | 94/1000 [00:22<03:24,  4.43it/s]Epoch 94\n",
            "Loss = 9.1079e-03, PNorm = 36.3411, GNorm = 1.0454, lr_0 = 8.0666e-04\n",
            "Validation rmse = 0.737644\n",
            " 10%|▉         | 95/1000 [00:22<03:24,  4.42it/s]Epoch 95\n",
            "Validation rmse = 0.747017\n",
            " 10%|▉         | 96/1000 [00:22<03:23,  4.44it/s]Epoch 96\n",
            "Loss = 1.0813e-02, PNorm = 36.3578, GNorm = 0.6736, lr_0 = 8.0433e-04\n",
            "Validation rmse = 0.747389\n",
            " 10%|▉         | 97/1000 [00:22<03:23,  4.44it/s]Epoch 97\n",
            "Loss = 7.8636e-03, PNorm = 36.3728, GNorm = 0.3483, lr_0 = 8.0202e-04\n",
            "Validation rmse = 0.719998\n",
            " 10%|▉         | 98/1000 [00:23<03:24,  4.41it/s]Epoch 98\n",
            "Loss = 9.7698e-03, PNorm = 36.3877, GNorm = 1.1538, lr_0 = 7.9971e-04\n",
            "Validation rmse = 0.757744\n",
            " 10%|▉         | 99/1000 [00:23<03:24,  4.41it/s]Epoch 99\n",
            "Loss = 9.4748e-03, PNorm = 36.4004, GNorm = 1.5450, lr_0 = 7.9740e-04\n",
            "Validation rmse = 0.730604\n",
            " 10%|█         | 100/1000 [00:23<03:24,  4.41it/s]Epoch 100\n",
            "Validation rmse = 0.745324\n",
            " 10%|█         | 101/1000 [00:23<03:24,  4.41it/s]Epoch 101\n",
            "Loss = 6.5924e-03, PNorm = 36.4125, GNorm = 0.9210, lr_0 = 7.9511e-04\n",
            "Validation rmse = 0.750161\n",
            " 10%|█         | 102/1000 [00:23<03:23,  4.42it/s]Epoch 102\n",
            "Loss = 8.0809e-03, PNorm = 36.4273, GNorm = 0.9389, lr_0 = 7.9282e-04\n",
            "Validation rmse = 0.738420\n",
            " 10%|█         | 103/1000 [00:24<03:22,  4.42it/s]Epoch 103\n",
            "Loss = 8.1040e-03, PNorm = 36.4402, GNorm = 0.3893, lr_0 = 7.9053e-04\n",
            "Validation rmse = 0.747045\n",
            " 10%|█         | 104/1000 [00:24<03:23,  4.41it/s]Epoch 104\n",
            "Loss = 1.0918e-02, PNorm = 36.4553, GNorm = 1.2765, lr_0 = 7.8826e-04\n",
            "Validation rmse = 0.747312\n",
            " 10%|█         | 105/1000 [00:24<03:22,  4.41it/s]Epoch 105\n",
            "Validation rmse = 0.736538\n",
            " 11%|█         | 106/1000 [00:24<03:21,  4.43it/s]Epoch 106\n",
            "Loss = 6.4119e-03, PNorm = 36.4667, GNorm = 0.6071, lr_0 = 7.8599e-04\n",
            "Validation rmse = 0.755384\n",
            " 11%|█         | 107/1000 [00:25<03:21,  4.44it/s]Epoch 107\n",
            "Loss = 1.5354e-02, PNorm = 36.4822, GNorm = 2.3360, lr_0 = 7.8372e-04\n",
            "Validation rmse = 0.770977\n",
            " 11%|█         | 108/1000 [00:25<03:21,  4.43it/s]Epoch 108\n",
            "Loss = 1.5752e-02, PNorm = 36.5004, GNorm = 0.9483, lr_0 = 7.8147e-04\n",
            "Validation rmse = 0.756978\n",
            " 11%|█         | 109/1000 [00:25<03:20,  4.44it/s]Epoch 109\n",
            "Loss = 1.0450e-02, PNorm = 36.5194, GNorm = 0.5282, lr_0 = 7.7922e-04\n",
            "Validation rmse = 0.779180\n",
            " 11%|█         | 110/1000 [00:25<03:20,  4.44it/s]Epoch 110\n",
            "Validation rmse = 0.757255\n",
            " 11%|█         | 111/1000 [00:25<03:19,  4.45it/s]Epoch 111\n",
            "Loss = 7.2806e-03, PNorm = 36.5345, GNorm = 0.7895, lr_0 = 7.7697e-04\n",
            "Validation rmse = 0.748568\n",
            " 11%|█         | 112/1000 [00:26<03:19,  4.44it/s]Epoch 112\n",
            "Loss = 7.2549e-03, PNorm = 36.5491, GNorm = 0.2652, lr_0 = 7.7474e-04\n",
            "Validation rmse = 0.732099\n",
            " 11%|█▏        | 113/1000 [00:26<03:19,  4.44it/s]Epoch 113\n",
            "Loss = 8.8354e-03, PNorm = 36.5594, GNorm = 0.2720, lr_0 = 7.7250e-04\n",
            "Validation rmse = 0.782781\n",
            " 11%|█▏        | 114/1000 [00:26<03:19,  4.44it/s]Epoch 114\n",
            "Loss = 1.3783e-02, PNorm = 36.5699, GNorm = 2.1768, lr_0 = 7.7028e-04\n",
            "Validation rmse = 0.751703\n",
            " 12%|█▏        | 115/1000 [00:26<03:19,  4.44it/s]Epoch 115\n",
            "Validation rmse = 0.753375\n",
            " 12%|█▏        | 116/1000 [00:27<03:18,  4.45it/s]Epoch 116\n",
            "Loss = 1.2627e-02, PNorm = 36.5832, GNorm = 2.0324, lr_0 = 7.6806e-04\n",
            "Validation rmse = 0.726487\n",
            " 12%|█▏        | 117/1000 [00:27<03:18,  4.45it/s]Epoch 117\n",
            "Loss = 1.0252e-02, PNorm = 36.5983, GNorm = 1.0962, lr_0 = 7.6585e-04\n",
            "Validation rmse = 0.718595\n",
            " 12%|█▏        | 118/1000 [00:27<03:18,  4.44it/s]Epoch 118\n",
            "Loss = 6.7011e-03, PNorm = 36.6125, GNorm = 0.2214, lr_0 = 7.6364e-04\n",
            "Validation rmse = 0.766032\n",
            " 12%|█▏        | 119/1000 [00:27<03:18,  4.44it/s]Epoch 119\n",
            "Loss = 8.2882e-03, PNorm = 36.6263, GNorm = 0.9600, lr_0 = 7.6144e-04\n",
            "Validation rmse = 0.751312\n",
            " 12%|█▏        | 120/1000 [00:27<03:18,  4.44it/s]Epoch 120\n",
            "Validation rmse = 0.740146\n",
            " 12%|█▏        | 121/1000 [00:28<03:17,  4.45it/s]Epoch 121\n",
            "Loss = 2.7250e-02, PNorm = 36.6396, GNorm = 3.9676, lr_0 = 7.5925e-04\n",
            "Validation rmse = 0.827290\n",
            " 12%|█▏        | 122/1000 [00:28<03:17,  4.45it/s]Epoch 122\n",
            "Loss = 1.4972e-02, PNorm = 36.6594, GNorm = 1.2417, lr_0 = 7.5707e-04\n",
            "Validation rmse = 0.758327\n",
            " 12%|█▏        | 123/1000 [00:28<03:17,  4.43it/s]Epoch 123\n",
            "Loss = 8.7445e-03, PNorm = 36.6743, GNorm = 0.8621, lr_0 = 7.5488e-04\n",
            "Validation rmse = 0.735181\n",
            " 12%|█▏        | 124/1000 [00:28<03:18,  4.42it/s]Epoch 124\n",
            "Loss = 9.8638e-03, PNorm = 36.6888, GNorm = 0.6454, lr_0 = 7.5271e-04\n",
            "Validation rmse = 0.746365\n",
            " 12%|█▎        | 125/1000 [00:29<03:18,  4.41it/s]Epoch 125\n",
            "Validation rmse = 0.744511\n",
            " 13%|█▎        | 126/1000 [00:29<03:17,  4.42it/s]Epoch 126\n",
            "Loss = 7.2161e-03, PNorm = 36.6989, GNorm = 1.6240, lr_0 = 7.5054e-04\n",
            "Validation rmse = 0.767474\n",
            " 13%|█▎        | 127/1000 [00:29<03:17,  4.43it/s]Epoch 127\n",
            "Loss = 1.2108e-02, PNorm = 36.7103, GNorm = 2.3368, lr_0 = 7.4838e-04\n",
            "Validation rmse = 0.754226\n",
            " 13%|█▎        | 128/1000 [00:29<03:16,  4.43it/s]Epoch 128\n",
            "Loss = 8.9875e-03, PNorm = 36.7263, GNorm = 0.2712, lr_0 = 7.4623e-04\n",
            "Validation rmse = 0.741630\n",
            " 13%|█▎        | 129/1000 [00:30<03:17,  4.41it/s]Epoch 129\n",
            "Loss = 7.0079e-03, PNorm = 36.7394, GNorm = 0.7126, lr_0 = 7.4408e-04\n",
            "Validation rmse = 0.770127\n",
            " 13%|█▎        | 130/1000 [00:30<03:16,  4.42it/s]Epoch 130\n",
            "Validation rmse = 0.785578\n",
            " 13%|█▎        | 131/1000 [00:30<03:15,  4.44it/s]Epoch 131\n",
            "Loss = 9.5448e-03, PNorm = 36.7484, GNorm = 0.6609, lr_0 = 7.4193e-04\n",
            "Validation rmse = 0.761780\n",
            " 13%|█▎        | 132/1000 [00:30<03:15,  4.44it/s]Epoch 132\n",
            "Loss = 8.1289e-03, PNorm = 36.7566, GNorm = 1.2414, lr_0 = 7.3980e-04\n",
            "Validation rmse = 0.742467\n",
            " 13%|█▎        | 133/1000 [00:30<03:15,  4.43it/s]Epoch 133\n",
            "Loss = 5.7422e-03, PNorm = 36.7652, GNorm = 0.2757, lr_0 = 7.3767e-04\n",
            "Validation rmse = 0.766167\n",
            " 13%|█▎        | 134/1000 [00:31<03:15,  4.42it/s]Epoch 134\n",
            "Loss = 6.4444e-03, PNorm = 36.7722, GNorm = 0.2028, lr_0 = 7.3554e-04\n",
            "Validation rmse = 0.762047\n",
            " 14%|█▎        | 135/1000 [00:31<03:15,  4.43it/s]Epoch 135\n",
            "Validation rmse = 0.792951\n",
            " 14%|█▎        | 136/1000 [00:31<03:19,  4.33it/s]Epoch 136\n",
            "Loss = 6.8787e-03, PNorm = 36.7791, GNorm = 0.1901, lr_0 = 7.3343e-04\n",
            "Validation rmse = 0.786378\n",
            " 14%|█▎        | 137/1000 [00:31<03:19,  4.33it/s]Epoch 137\n",
            "Loss = 6.1261e-03, PNorm = 36.7862, GNorm = 1.0254, lr_0 = 7.3131e-04\n",
            "Validation rmse = 0.742592\n",
            " 14%|█▍        | 138/1000 [00:32<03:17,  4.37it/s]Epoch 138\n",
            "Loss = 6.2654e-03, PNorm = 36.7949, GNorm = 0.6838, lr_0 = 7.2921e-04\n",
            "Validation rmse = 0.777708\n",
            " 14%|█▍        | 139/1000 [00:32<03:16,  4.38it/s]Epoch 139\n",
            "Loss = 6.1611e-03, PNorm = 36.8016, GNorm = 0.4478, lr_0 = 7.2711e-04\n",
            "Validation rmse = 0.764604\n",
            " 14%|█▍        | 140/1000 [00:32<03:15,  4.40it/s]Epoch 140\n",
            "Validation rmse = 0.748470\n",
            " 14%|█▍        | 141/1000 [00:32<03:14,  4.42it/s]Epoch 141\n",
            "Loss = 6.2201e-03, PNorm = 36.8092, GNorm = 0.3497, lr_0 = 7.2501e-04\n",
            "Validation rmse = 0.755841\n",
            " 14%|█▍        | 142/1000 [00:32<03:13,  4.43it/s]Epoch 142\n",
            "Loss = 5.7727e-03, PNorm = 36.8173, GNorm = 0.8943, lr_0 = 7.2292e-04\n",
            "Validation rmse = 0.754496\n",
            " 14%|█▍        | 143/1000 [00:33<03:13,  4.43it/s]Epoch 143\n",
            "Loss = 4.1120e-03, PNorm = 36.8267, GNorm = 0.3459, lr_0 = 7.2084e-04\n",
            "Validation rmse = 0.758323\n",
            " 14%|█▍        | 144/1000 [00:33<03:13,  4.43it/s]Epoch 144\n",
            "Loss = 4.9533e-03, PNorm = 36.8357, GNorm = 0.1632, lr_0 = 7.1877e-04\n",
            "Validation rmse = 0.768353\n",
            " 14%|█▍        | 145/1000 [00:33<03:12,  4.44it/s]Epoch 145\n",
            "Validation rmse = 0.751748\n",
            " 15%|█▍        | 146/1000 [00:33<03:12,  4.44it/s]Epoch 146\n",
            "Loss = 3.3388e-03, PNorm = 36.8413, GNorm = 0.2168, lr_0 = 7.1670e-04\n",
            "Validation rmse = 0.792515\n",
            " 15%|█▍        | 147/1000 [00:34<03:12,  4.44it/s]Epoch 147\n",
            "Loss = 3.7043e-03, PNorm = 36.8496, GNorm = 0.2943, lr_0 = 7.1463e-04\n",
            "Validation rmse = 0.771821\n",
            " 15%|█▍        | 148/1000 [00:34<03:11,  4.44it/s]Epoch 148\n",
            "Loss = 6.6278e-03, PNorm = 36.8589, GNorm = 0.3042, lr_0 = 7.1258e-04\n",
            "Validation rmse = 0.762737\n",
            " 15%|█▍        | 149/1000 [00:34<03:13,  4.40it/s]Epoch 149\n",
            "Loss = 7.2279e-03, PNorm = 36.8686, GNorm = 0.8392, lr_0 = 7.1052e-04\n",
            "Validation rmse = 0.783576\n",
            " 15%|█▌        | 150/1000 [00:34<03:12,  4.41it/s]Epoch 150\n",
            "Validation rmse = 0.744671\n",
            " 15%|█▌        | 151/1000 [00:34<03:11,  4.43it/s]Epoch 151\n",
            "Loss = 5.8330e-03, PNorm = 36.8777, GNorm = 0.4561, lr_0 = 7.0848e-04\n",
            "Validation rmse = 0.768990\n",
            " 15%|█▌        | 152/1000 [00:35<03:11,  4.42it/s]Epoch 152\n",
            "Loss = 5.8512e-03, PNorm = 36.8853, GNorm = 0.3152, lr_0 = 7.0644e-04\n",
            "Validation rmse = 0.737112\n",
            " 15%|█▌        | 153/1000 [00:35<03:11,  4.42it/s]Epoch 153\n",
            "Loss = 5.7377e-03, PNorm = 36.8913, GNorm = 0.4431, lr_0 = 7.0440e-04\n",
            "Validation rmse = 0.747979\n",
            " 15%|█▌        | 154/1000 [00:35<03:11,  4.43it/s]Epoch 154\n",
            "Loss = 6.9989e-03, PNorm = 36.9023, GNorm = 0.9293, lr_0 = 7.0237e-04\n",
            "Validation rmse = 0.805829\n",
            " 16%|█▌        | 155/1000 [00:35<03:10,  4.43it/s]Epoch 155\n",
            "Validation rmse = 0.760892\n",
            " 16%|█▌        | 156/1000 [00:36<03:09,  4.44it/s]Epoch 156\n",
            "Loss = 8.4442e-03, PNorm = 36.9105, GNorm = 1.3675, lr_0 = 7.0035e-04\n",
            "Validation rmse = 0.753646\n",
            " 16%|█▌        | 157/1000 [00:36<03:09,  4.44it/s]Epoch 157\n",
            "Loss = 6.5970e-03, PNorm = 36.9173, GNorm = 0.9661, lr_0 = 6.9833e-04\n",
            "Validation rmse = 0.812798\n",
            " 16%|█▌        | 158/1000 [00:36<03:09,  4.44it/s]Epoch 158\n",
            "Loss = 7.7021e-03, PNorm = 36.9261, GNorm = 1.0588, lr_0 = 6.9632e-04\n",
            "Validation rmse = 0.763304\n",
            " 16%|█▌        | 159/1000 [00:36<03:10,  4.42it/s]Epoch 159\n",
            "Loss = 1.1992e-02, PNorm = 36.9391, GNorm = 2.0810, lr_0 = 6.9432e-04\n",
            "Validation rmse = 0.767765\n",
            " 16%|█▌        | 160/1000 [00:37<03:09,  4.42it/s]Epoch 160\n",
            "Validation rmse = 0.774465\n",
            " 16%|█▌        | 161/1000 [00:37<03:08,  4.44it/s]Epoch 161\n",
            "Loss = 5.7629e-03, PNorm = 36.9525, GNorm = 0.7145, lr_0 = 6.9232e-04\n",
            "Validation rmse = 0.740403\n",
            " 16%|█▌        | 162/1000 [00:37<03:08,  4.44it/s]Epoch 162\n",
            "Loss = 4.6055e-03, PNorm = 36.9650, GNorm = 0.9096, lr_0 = 6.9032e-04\n",
            "Validation rmse = 0.786538\n",
            " 16%|█▋        | 163/1000 [00:37<03:08,  4.44it/s]Epoch 163\n",
            "Loss = 5.0072e-03, PNorm = 36.9734, GNorm = 0.2009, lr_0 = 6.8834e-04\n",
            "Validation rmse = 0.754832\n",
            " 16%|█▋        | 164/1000 [00:37<03:08,  4.44it/s]Epoch 164\n",
            "Loss = 5.1232e-03, PNorm = 36.9796, GNorm = 0.8391, lr_0 = 6.8635e-04\n",
            "Validation rmse = 0.757362\n",
            " 16%|█▋        | 165/1000 [00:38<03:08,  4.44it/s]Epoch 165\n",
            "Validation rmse = 0.774008\n",
            " 17%|█▋        | 166/1000 [00:38<03:07,  4.45it/s]Epoch 166\n",
            "Loss = 3.3574e-03, PNorm = 36.9836, GNorm = 0.7175, lr_0 = 6.8438e-04\n",
            "Validation rmse = 0.780536\n",
            " 17%|█▋        | 167/1000 [00:38<03:07,  4.45it/s]Epoch 167\n",
            "Loss = 7.1788e-03, PNorm = 36.9899, GNorm = 0.6061, lr_0 = 6.8241e-04\n",
            "Validation rmse = 0.759371\n",
            " 17%|█▋        | 168/1000 [00:38<03:06,  4.45it/s]Epoch 168\n",
            "Loss = 5.6951e-03, PNorm = 36.9971, GNorm = 0.6164, lr_0 = 6.8044e-04\n",
            "Validation rmse = 0.776215\n",
            " 17%|█▋        | 169/1000 [00:39<03:06,  4.45it/s]Epoch 169\n",
            "Loss = 6.8127e-03, PNorm = 37.0038, GNorm = 0.5634, lr_0 = 6.7848e-04\n",
            "Validation rmse = 0.811968\n",
            " 17%|█▋        | 170/1000 [00:39<03:06,  4.45it/s]Epoch 170\n",
            "Validation rmse = 0.769275\n",
            " 17%|█▋        | 171/1000 [00:39<03:05,  4.46it/s]Epoch 171\n",
            "Loss = 8.3772e-03, PNorm = 37.0120, GNorm = 0.2377, lr_0 = 6.7653e-04\n",
            "Validation rmse = 0.855484\n",
            " 17%|█▋        | 172/1000 [00:39<03:05,  4.46it/s]Epoch 172\n",
            "Loss = 1.2633e-02, PNorm = 37.0197, GNorm = 0.7516, lr_0 = 6.7458e-04\n",
            "Validation rmse = 0.777591\n",
            " 17%|█▋        | 173/1000 [00:39<03:06,  4.44it/s]Epoch 173\n",
            "Loss = 7.8140e-03, PNorm = 37.0339, GNorm = 0.3196, lr_0 = 6.7264e-04\n",
            "Validation rmse = 0.738061\n",
            " 17%|█▋        | 174/1000 [00:40<03:05,  4.45it/s]Epoch 174\n",
            "Loss = 7.0051e-03, PNorm = 37.0460, GNorm = 1.3584, lr_0 = 6.7070e-04\n",
            "Validation rmse = 0.779113\n",
            " 18%|█▊        | 175/1000 [00:40<03:05,  4.45it/s]Epoch 175\n",
            "Validation rmse = 0.740444\n",
            " 18%|█▊        | 176/1000 [00:40<03:04,  4.46it/s]Epoch 176\n",
            "Loss = 8.8591e-03, PNorm = 37.0565, GNorm = 1.2356, lr_0 = 6.6877e-04\n",
            "Validation rmse = 0.759026\n",
            " 18%|█▊        | 177/1000 [00:40<03:04,  4.46it/s]Epoch 177\n",
            "Loss = 7.4528e-03, PNorm = 37.0625, GNorm = 0.6907, lr_0 = 6.6684e-04\n",
            "Validation rmse = 0.816686\n",
            " 18%|█▊        | 178/1000 [00:41<03:04,  4.46it/s]Epoch 178\n",
            "Loss = 6.8530e-03, PNorm = 37.0712, GNorm = 0.5827, lr_0 = 6.6492e-04\n",
            "Validation rmse = 0.751857\n",
            " 18%|█▊        | 179/1000 [00:41<03:04,  4.45it/s]Epoch 179\n",
            "Loss = 5.6963e-03, PNorm = 37.0799, GNorm = 0.8649, lr_0 = 6.6301e-04\n",
            "Validation rmse = 0.749852\n",
            " 18%|█▊        | 180/1000 [00:41<03:04,  4.45it/s]Epoch 180\n",
            "Validation rmse = 0.785731\n",
            " 18%|█▊        | 181/1000 [00:41<03:03,  4.46it/s]Epoch 181\n",
            "Loss = 6.0662e-03, PNorm = 37.0885, GNorm = 0.6872, lr_0 = 6.6110e-04\n",
            "Validation rmse = 0.786460\n",
            " 18%|█▊        | 182/1000 [00:41<03:03,  4.45it/s]Epoch 182\n",
            "Loss = 5.8816e-03, PNorm = 37.0969, GNorm = 1.8910, lr_0 = 6.5919e-04\n",
            "Validation rmse = 0.765799\n",
            " 18%|█▊        | 183/1000 [00:42<03:03,  4.46it/s]Epoch 183\n",
            "Loss = 7.0049e-03, PNorm = 37.1049, GNorm = 2.1471, lr_0 = 6.5730e-04\n",
            "Validation rmse = 0.768185\n",
            " 18%|█▊        | 184/1000 [00:42<03:03,  4.46it/s]Epoch 184\n",
            "Loss = 9.9978e-03, PNorm = 37.1122, GNorm = 0.7768, lr_0 = 6.5540e-04\n",
            "Validation rmse = 0.767248\n",
            " 18%|█▊        | 185/1000 [00:42<03:03,  4.45it/s]Epoch 185\n",
            "Validation rmse = 0.759059\n",
            " 19%|█▊        | 186/1000 [00:42<03:02,  4.46it/s]Epoch 186\n",
            "Loss = 3.1609e-03, PNorm = 37.1223, GNorm = 0.8750, lr_0 = 6.5351e-04\n",
            "Validation rmse = 0.769549\n",
            " 19%|█▊        | 187/1000 [00:43<03:02,  4.45it/s]Epoch 187\n",
            "Loss = 6.1894e-03, PNorm = 37.1313, GNorm = 0.7020, lr_0 = 6.5163e-04\n",
            "Validation rmse = 0.812440\n",
            " 19%|█▉        | 188/1000 [00:43<03:03,  4.44it/s]Epoch 188\n",
            "Loss = 6.4280e-03, PNorm = 37.1396, GNorm = 0.4453, lr_0 = 6.4976e-04\n",
            "Validation rmse = 0.765289\n",
            " 19%|█▉        | 189/1000 [00:43<03:02,  4.44it/s]Epoch 189\n",
            "Loss = 5.2606e-03, PNorm = 37.1461, GNorm = 0.6616, lr_0 = 6.4789e-04\n",
            "Validation rmse = 0.780757\n",
            " 19%|█▉        | 190/1000 [00:43<03:02,  4.44it/s]Epoch 190\n",
            "Validation rmse = 0.767347\n",
            " 19%|█▉        | 191/1000 [00:43<03:01,  4.45it/s]Epoch 191\n",
            "Loss = 6.4932e-03, PNorm = 37.1518, GNorm = 0.9131, lr_0 = 6.4602e-04\n",
            "Validation rmse = 0.766791\n",
            " 19%|█▉        | 192/1000 [00:44<03:39,  3.69it/s]Epoch 192\n",
            "Loss = 4.3025e-03, PNorm = 37.1596, GNorm = 0.2894, lr_0 = 6.4416e-04\n",
            "Validation rmse = 0.760938\n",
            " 19%|█▉        | 193/1000 [00:44<03:27,  3.88it/s]Epoch 193\n",
            "Loss = 4.5437e-03, PNorm = 37.1662, GNorm = 0.4357, lr_0 = 6.4230e-04\n",
            "Validation rmse = 0.768816\n",
            " 19%|█▉        | 194/1000 [00:44<03:20,  4.02it/s]Epoch 194\n",
            "Loss = 5.0727e-03, PNorm = 37.1716, GNorm = 0.8944, lr_0 = 6.4045e-04\n",
            "Validation rmse = 0.781131\n",
            " 20%|█▉        | 195/1000 [00:45<03:14,  4.14it/s]Epoch 195\n",
            "Validation rmse = 0.803548\n",
            " 20%|█▉        | 196/1000 [00:45<03:09,  4.24it/s]Epoch 196\n",
            "Loss = 5.1759e-03, PNorm = 37.1787, GNorm = 0.9783, lr_0 = 6.3861e-04\n",
            "Validation rmse = 0.762015\n",
            " 20%|█▉        | 197/1000 [00:45<03:06,  4.30it/s]Epoch 197\n",
            "Loss = 3.0116e-03, PNorm = 37.1877, GNorm = 0.4291, lr_0 = 6.3677e-04\n",
            "Validation rmse = 0.774330\n",
            " 20%|█▉        | 198/1000 [00:45<03:04,  4.35it/s]Epoch 198\n",
            "Loss = 6.8770e-03, PNorm = 37.1938, GNorm = 0.3992, lr_0 = 6.3494e-04\n",
            "Validation rmse = 0.759012\n",
            " 20%|█▉        | 199/1000 [00:45<03:03,  4.37it/s]Epoch 199\n",
            "Loss = 6.9406e-03, PNorm = 37.2007, GNorm = 1.3638, lr_0 = 6.3311e-04\n",
            "Validation rmse = 0.793373\n",
            " 20%|██        | 200/1000 [00:46<03:01,  4.40it/s]Epoch 200\n",
            "Validation rmse = 0.764185\n",
            " 20%|██        | 201/1000 [00:46<03:00,  4.42it/s]Epoch 201\n",
            "Loss = 6.5680e-03, PNorm = 37.2078, GNorm = 0.5327, lr_0 = 6.3128e-04\n",
            "Validation rmse = 0.786864\n",
            " 20%|██        | 202/1000 [00:46<03:00,  4.42it/s]Epoch 202\n",
            "Loss = 5.4877e-03, PNorm = 37.2165, GNorm = 0.1602, lr_0 = 6.2947e-04\n",
            "Validation rmse = 0.755985\n",
            " 20%|██        | 203/1000 [00:46<02:59,  4.43it/s]Epoch 203\n",
            "Loss = 5.5743e-03, PNorm = 37.2224, GNorm = 0.5318, lr_0 = 6.2765e-04\n",
            "Validation rmse = 0.763302\n",
            " 20%|██        | 204/1000 [00:47<02:59,  4.44it/s]Epoch 204\n",
            "Loss = 6.7155e-03, PNorm = 37.2290, GNorm = 0.9597, lr_0 = 6.2585e-04\n",
            "Validation rmse = 0.844722\n",
            " 20%|██        | 205/1000 [00:47<02:58,  4.44it/s]Epoch 205\n",
            "Validation rmse = 0.761875\n",
            " 21%|██        | 206/1000 [00:47<02:58,  4.46it/s]Epoch 206\n",
            "Loss = 1.5378e-02, PNorm = 37.2372, GNorm = 1.4513, lr_0 = 6.2404e-04\n",
            "Validation rmse = 0.814220\n",
            " 21%|██        | 207/1000 [00:47<02:57,  4.46it/s]Epoch 207\n",
            "Loss = 7.7789e-03, PNorm = 37.2459, GNorm = 0.5639, lr_0 = 6.2225e-04\n",
            "Validation rmse = 0.758781\n",
            " 21%|██        | 208/1000 [00:47<02:57,  4.45it/s]Epoch 208\n",
            "Loss = 5.3210e-03, PNorm = 37.2554, GNorm = 0.3832, lr_0 = 6.2046e-04\n",
            "Validation rmse = 0.764374\n",
            " 21%|██        | 209/1000 [00:48<02:57,  4.46it/s]Epoch 209\n",
            "Loss = 8.2646e-03, PNorm = 37.2673, GNorm = 0.3204, lr_0 = 6.1867e-04\n",
            "Validation rmse = 0.780445\n",
            " 21%|██        | 210/1000 [00:48<02:57,  4.44it/s]Epoch 210\n",
            "Validation rmse = 0.809302\n",
            " 21%|██        | 211/1000 [00:48<02:57,  4.45it/s]Epoch 211\n",
            "Loss = 7.7607e-03, PNorm = 37.2776, GNorm = 0.7970, lr_0 = 6.1689e-04\n",
            "Validation rmse = 0.767957\n",
            " 21%|██        | 212/1000 [00:48<02:56,  4.45it/s]Epoch 212\n",
            "Loss = 6.9594e-03, PNorm = 37.2888, GNorm = 0.5183, lr_0 = 6.1511e-04\n",
            "Validation rmse = 0.793022\n",
            " 21%|██▏       | 213/1000 [00:49<02:56,  4.45it/s]Epoch 213\n",
            "Loss = 5.6988e-03, PNorm = 37.2954, GNorm = 0.8555, lr_0 = 6.1334e-04\n",
            "Validation rmse = 0.773708\n",
            " 21%|██▏       | 214/1000 [00:49<02:56,  4.45it/s]Epoch 214\n",
            "Loss = 6.1677e-03, PNorm = 37.3017, GNorm = 0.6184, lr_0 = 6.1157e-04\n",
            "Validation rmse = 0.754474\n",
            " 22%|██▏       | 215/1000 [00:49<02:56,  4.45it/s]Epoch 215\n",
            "Validation rmse = 0.792067\n",
            " 22%|██▏       | 216/1000 [00:49<02:55,  4.47it/s]Epoch 216\n",
            "Loss = 4.7645e-03, PNorm = 37.3068, GNorm = 0.4243, lr_0 = 6.0981e-04\n",
            "Validation rmse = 0.782889\n",
            " 22%|██▏       | 217/1000 [00:49<02:56,  4.45it/s]Epoch 217\n",
            "Loss = 5.7939e-03, PNorm = 37.3130, GNorm = 0.3950, lr_0 = 6.0806e-04\n",
            "Validation rmse = 0.769397\n",
            " 22%|██▏       | 218/1000 [00:50<02:55,  4.45it/s]Epoch 218\n",
            "Loss = 4.8080e-03, PNorm = 37.3205, GNorm = 0.4867, lr_0 = 6.0630e-04\n",
            "Validation rmse = 0.794064\n",
            " 22%|██▏       | 219/1000 [00:50<02:56,  4.44it/s]Epoch 219\n",
            "Loss = 4.1751e-03, PNorm = 37.3275, GNorm = 0.2917, lr_0 = 6.0456e-04\n",
            "Validation rmse = 0.800426\n",
            " 22%|██▏       | 220/1000 [00:50<02:55,  4.44it/s]Epoch 220\n",
            "Validation rmse = 0.764396\n",
            " 22%|██▏       | 221/1000 [00:50<02:55,  4.44it/s]Epoch 221\n",
            "Loss = 2.5940e-03, PNorm = 37.3341, GNorm = 0.1060, lr_0 = 6.0282e-04\n",
            "Validation rmse = 0.783138\n",
            " 22%|██▏       | 222/1000 [00:51<02:55,  4.44it/s]Epoch 222\n",
            "Loss = 2.6705e-03, PNorm = 37.3400, GNorm = 0.3826, lr_0 = 6.0108e-04\n",
            "Validation rmse = 0.753860\n",
            " 22%|██▏       | 223/1000 [00:51<02:55,  4.44it/s]Epoch 223\n",
            "Loss = 4.5408e-03, PNorm = 37.3464, GNorm = 0.4446, lr_0 = 5.9935e-04\n",
            "Validation rmse = 0.780214\n",
            " 22%|██▏       | 224/1000 [00:51<02:54,  4.44it/s]Epoch 224\n",
            "Loss = 3.3676e-03, PNorm = 37.3523, GNorm = 0.4616, lr_0 = 5.9762e-04\n",
            "Validation rmse = 0.781922\n",
            " 22%|██▎       | 225/1000 [00:51<02:54,  4.45it/s]Epoch 225\n",
            "Validation rmse = 0.766196\n",
            " 23%|██▎       | 226/1000 [00:52<02:53,  4.46it/s]Epoch 226\n",
            "Loss = 2.9825e-03, PNorm = 37.3572, GNorm = 0.9468, lr_0 = 5.9590e-04\n",
            "Validation rmse = 0.773820\n",
            " 23%|██▎       | 227/1000 [00:52<02:53,  4.46it/s]Epoch 227\n",
            "Loss = 4.3955e-03, PNorm = 37.3617, GNorm = 0.4008, lr_0 = 5.9419e-04\n",
            "Validation rmse = 0.777684\n",
            " 23%|██▎       | 228/1000 [00:52<02:53,  4.45it/s]Epoch 228\n",
            "Loss = 2.8409e-03, PNorm = 37.3668, GNorm = 0.3655, lr_0 = 5.9248e-04\n",
            "Validation rmse = 0.787679\n",
            " 23%|██▎       | 229/1000 [00:52<02:53,  4.43it/s]Epoch 229\n",
            "Loss = 3.5320e-03, PNorm = 37.3714, GNorm = 0.3559, lr_0 = 5.9077e-04\n",
            "Validation rmse = 0.775969\n",
            " 23%|██▎       | 230/1000 [00:52<02:53,  4.43it/s]Epoch 230\n",
            "Validation rmse = 0.771171\n",
            " 23%|██▎       | 231/1000 [00:53<02:52,  4.45it/s]Epoch 231\n",
            "Loss = 2.3542e-03, PNorm = 37.3758, GNorm = 0.8050, lr_0 = 5.8907e-04\n",
            "Validation rmse = 0.794948\n",
            " 23%|██▎       | 232/1000 [00:53<02:52,  4.45it/s]Epoch 232\n",
            "Loss = 3.1808e-03, PNorm = 37.3813, GNorm = 0.4114, lr_0 = 5.8737e-04\n",
            "Validation rmse = 0.761619\n",
            " 23%|██▎       | 233/1000 [00:53<02:52,  4.45it/s]Epoch 233\n",
            "Loss = 3.4720e-03, PNorm = 37.3859, GNorm = 0.9009, lr_0 = 5.8568e-04\n",
            "Validation rmse = 0.785846\n",
            " 23%|██▎       | 234/1000 [00:53<02:52,  4.45it/s]Epoch 234\n",
            "Loss = 3.2492e-03, PNorm = 37.3895, GNorm = 0.2236, lr_0 = 5.8399e-04\n",
            "Validation rmse = 0.777233\n",
            " 24%|██▎       | 235/1000 [00:54<02:51,  4.45it/s]Epoch 235\n",
            "Validation rmse = 0.787762\n",
            " 24%|██▎       | 236/1000 [00:54<02:51,  4.46it/s]Epoch 236\n",
            "Loss = 2.3617e-03, PNorm = 37.3964, GNorm = 0.1213, lr_0 = 5.8231e-04\n",
            "Validation rmse = 0.763296\n",
            " 24%|██▎       | 237/1000 [00:54<02:51,  4.46it/s]Epoch 237\n",
            "Loss = 3.8284e-03, PNorm = 37.4010, GNorm = 1.1221, lr_0 = 5.8063e-04\n",
            "Validation rmse = 0.791316\n",
            " 24%|██▍       | 238/1000 [00:54<02:51,  4.44it/s]Epoch 238\n",
            "Loss = 3.7935e-03, PNorm = 37.4059, GNorm = 0.5309, lr_0 = 5.7896e-04\n",
            "Validation rmse = 0.792582\n",
            " 24%|██▍       | 239/1000 [00:54<02:51,  4.44it/s]Epoch 239\n",
            "Loss = 4.3195e-03, PNorm = 37.4122, GNorm = 0.3819, lr_0 = 5.7729e-04\n",
            "Validation rmse = 0.767641\n",
            " 24%|██▍       | 240/1000 [00:55<02:51,  4.44it/s]Epoch 240\n",
            "Validation rmse = 0.794498\n",
            " 24%|██▍       | 241/1000 [00:55<02:50,  4.46it/s]Epoch 241\n",
            "Loss = 4.9076e-03, PNorm = 37.4185, GNorm = 0.8019, lr_0 = 5.7563e-04\n",
            "Validation rmse = 0.773229\n",
            " 24%|██▍       | 242/1000 [00:55<02:50,  4.45it/s]Epoch 242\n",
            "Loss = 3.8363e-03, PNorm = 37.4257, GNorm = 0.9075, lr_0 = 5.7397e-04\n",
            "Validation rmse = 0.777613\n",
            " 24%|██▍       | 243/1000 [00:55<02:50,  4.45it/s]Epoch 243\n",
            "Loss = 3.3365e-03, PNorm = 37.4302, GNorm = 0.1860, lr_0 = 5.7232e-04\n",
            "Validation rmse = 0.788599\n",
            " 24%|██▍       | 244/1000 [00:56<02:49,  4.45it/s]Epoch 244\n",
            "Loss = 2.9880e-03, PNorm = 37.4336, GNorm = 0.6639, lr_0 = 5.7067e-04\n",
            "Validation rmse = 0.792057\n",
            " 24%|██▍       | 245/1000 [00:56<02:49,  4.45it/s]Epoch 245\n",
            "Validation rmse = 0.789015\n",
            " 25%|██▍       | 246/1000 [00:56<02:48,  4.46it/s]Epoch 246\n",
            "Loss = 3.4404e-03, PNorm = 37.4380, GNorm = 0.1777, lr_0 = 5.6903e-04\n",
            "Validation rmse = 0.780055\n",
            " 25%|██▍       | 247/1000 [00:56<02:49,  4.45it/s]Epoch 247\n",
            "Loss = 1.5131e-03, PNorm = 37.4419, GNorm = 0.2246, lr_0 = 5.6739e-04\n",
            "Validation rmse = 0.765939\n",
            " 25%|██▍       | 248/1000 [00:56<02:49,  4.45it/s]Epoch 248\n",
            "Loss = 2.8161e-03, PNorm = 37.4465, GNorm = 0.4130, lr_0 = 5.6576e-04\n",
            "Validation rmse = 0.785654\n",
            " 25%|██▍       | 249/1000 [00:57<02:48,  4.45it/s]Epoch 249\n",
            "Loss = 2.7304e-03, PNorm = 37.4507, GNorm = 0.1371, lr_0 = 5.6413e-04\n",
            "Validation rmse = 0.779949\n",
            " 25%|██▌       | 250/1000 [00:57<02:48,  4.45it/s]Epoch 250\n",
            "Validation rmse = 0.790637\n",
            " 25%|██▌       | 251/1000 [00:57<02:47,  4.46it/s]Epoch 251\n",
            "Loss = 2.5659e-03, PNorm = 37.4552, GNorm = 0.8263, lr_0 = 5.6250e-04\n",
            "Validation rmse = 0.781214\n",
            " 25%|██▌       | 252/1000 [00:57<02:48,  4.45it/s]Epoch 252\n",
            "Loss = 1.9841e-03, PNorm = 37.4604, GNorm = 0.3645, lr_0 = 5.6088e-04\n",
            "Validation rmse = 0.812719\n",
            " 25%|██▌       | 253/1000 [00:58<02:47,  4.45it/s]Epoch 253\n",
            "Loss = 3.7708e-03, PNorm = 37.4651, GNorm = 0.2178, lr_0 = 5.5927e-04\n",
            "Validation rmse = 0.808396\n",
            " 25%|██▌       | 254/1000 [00:58<02:47,  4.45it/s]Epoch 254\n",
            "Loss = 4.7876e-03, PNorm = 37.4714, GNorm = 0.2863, lr_0 = 5.5766e-04\n",
            "Validation rmse = 0.760721\n",
            " 26%|██▌       | 255/1000 [00:58<02:47,  4.45it/s]Epoch 255\n",
            "Validation rmse = 0.811063\n",
            " 26%|██▌       | 256/1000 [00:58<02:47,  4.45it/s]Epoch 256\n",
            "Loss = 3.2502e-03, PNorm = 37.4770, GNorm = 0.5055, lr_0 = 5.5605e-04\n",
            "Validation rmse = 0.783713\n",
            " 26%|██▌       | 257/1000 [00:58<02:46,  4.45it/s]Epoch 257\n",
            "Loss = 3.6858e-03, PNorm = 37.4855, GNorm = 1.0403, lr_0 = 5.5445e-04\n",
            "Validation rmse = 0.765698\n",
            " 26%|██▌       | 258/1000 [00:59<02:46,  4.45it/s]Epoch 258\n",
            "Loss = 3.4085e-03, PNorm = 37.4913, GNorm = 0.2512, lr_0 = 5.5285e-04\n",
            "Validation rmse = 0.782344\n",
            " 26%|██▌       | 259/1000 [00:59<02:46,  4.45it/s]Epoch 259\n",
            "Loss = 2.6274e-03, PNorm = 37.4964, GNorm = 0.3701, lr_0 = 5.5126e-04\n",
            "Validation rmse = 0.796760\n",
            " 26%|██▌       | 260/1000 [00:59<02:46,  4.45it/s]Epoch 260\n",
            "Validation rmse = 0.774587\n",
            " 26%|██▌       | 261/1000 [00:59<02:45,  4.46it/s]Epoch 261\n",
            "Loss = 2.0634e-03, PNorm = 37.5012, GNorm = 0.2486, lr_0 = 5.4967e-04\n",
            "Validation rmse = 0.785222\n",
            " 26%|██▌       | 262/1000 [01:00<02:45,  4.46it/s]Epoch 262\n",
            "Loss = 2.2733e-03, PNorm = 37.5062, GNorm = 0.1500, lr_0 = 5.4809e-04\n",
            "Validation rmse = 0.785644\n",
            " 26%|██▋       | 263/1000 [01:00<02:45,  4.46it/s]Epoch 263\n",
            "Loss = 3.3670e-03, PNorm = 37.5100, GNorm = 0.3565, lr_0 = 5.4651e-04\n",
            "Validation rmse = 0.781836\n",
            " 26%|██▋       | 264/1000 [01:00<02:45,  4.45it/s]Epoch 264\n",
            "Loss = 4.0982e-03, PNorm = 37.5147, GNorm = 0.3720, lr_0 = 5.4494e-04\n",
            "Validation rmse = 0.810933\n",
            " 26%|██▋       | 265/1000 [01:00<02:45,  4.45it/s]Epoch 265\n",
            "Validation rmse = 0.766363\n",
            " 27%|██▋       | 266/1000 [01:00<02:44,  4.46it/s]Epoch 266\n",
            "Loss = 4.3157e-03, PNorm = 37.5198, GNorm = 0.4244, lr_0 = 5.4337e-04\n",
            "Validation rmse = 0.772990\n",
            " 27%|██▋       | 267/1000 [01:01<02:44,  4.44it/s]Epoch 267\n",
            "Loss = 4.4045e-03, PNorm = 37.5245, GNorm = 0.7657, lr_0 = 5.4180e-04\n",
            "Validation rmse = 0.794011\n",
            " 27%|██▋       | 268/1000 [01:01<02:44,  4.44it/s]Epoch 268\n",
            "Loss = 4.8987e-03, PNorm = 37.5295, GNorm = 0.5605, lr_0 = 5.4024e-04\n",
            "Validation rmse = 0.780915\n",
            " 27%|██▋       | 269/1000 [01:01<02:44,  4.44it/s]Epoch 269\n",
            "Loss = 3.8086e-03, PNorm = 37.5377, GNorm = 0.6152, lr_0 = 5.3869e-04\n",
            "Validation rmse = 0.810046\n",
            " 27%|██▋       | 270/1000 [01:01<02:44,  4.44it/s]Epoch 270\n",
            "Validation rmse = 0.777043\n",
            " 27%|██▋       | 271/1000 [01:02<02:43,  4.45it/s]Epoch 271\n",
            "Loss = 4.3024e-03, PNorm = 37.5459, GNorm = 0.2600, lr_0 = 5.3714e-04\n",
            "Validation rmse = 0.785463\n",
            " 27%|██▋       | 272/1000 [01:02<02:43,  4.46it/s]Epoch 272\n",
            "Loss = 3.2295e-03, PNorm = 37.5508, GNorm = 0.4348, lr_0 = 5.3559e-04\n",
            "Validation rmse = 0.782233\n",
            " 27%|██▋       | 273/1000 [01:02<02:43,  4.45it/s]Epoch 273\n",
            "Loss = 2.0207e-03, PNorm = 37.5565, GNorm = 0.2953, lr_0 = 5.3405e-04\n",
            "Validation rmse = 0.785940\n",
            " 27%|██▋       | 274/1000 [01:02<02:42,  4.45it/s]Epoch 274\n",
            "Loss = 2.9922e-03, PNorm = 37.5607, GNorm = 0.2650, lr_0 = 5.3251e-04\n",
            "Validation rmse = 0.785270\n",
            " 28%|██▊       | 275/1000 [01:03<02:43,  4.45it/s]Epoch 275\n",
            "Validation rmse = 0.778442\n",
            " 28%|██▊       | 276/1000 [01:03<02:42,  4.46it/s]Epoch 276\n",
            "Loss = 3.3029e-03, PNorm = 37.5662, GNorm = 0.3519, lr_0 = 5.3098e-04\n",
            "Validation rmse = 0.806399\n",
            " 28%|██▊       | 277/1000 [01:03<02:42,  4.45it/s]Epoch 277\n",
            "Loss = 3.4264e-03, PNorm = 37.5712, GNorm = 0.4252, lr_0 = 5.2945e-04\n",
            "Validation rmse = 0.777614\n",
            " 28%|██▊       | 278/1000 [01:03<02:42,  4.45it/s]Epoch 278\n",
            "Loss = 2.7317e-03, PNorm = 37.5755, GNorm = 0.2636, lr_0 = 5.2792e-04\n",
            "Validation rmse = 0.791209\n",
            " 28%|██▊       | 279/1000 [01:03<02:42,  4.43it/s]Epoch 279\n",
            "Loss = 2.8816e-03, PNorm = 37.5802, GNorm = 0.3398, lr_0 = 5.2640e-04\n",
            "Validation rmse = 0.797338\n",
            " 28%|██▊       | 280/1000 [01:04<02:42,  4.43it/s]Epoch 280\n",
            "Validation rmse = 0.775568\n",
            " 28%|██▊       | 281/1000 [01:04<02:41,  4.44it/s]Epoch 281\n",
            "Loss = 4.9882e-03, PNorm = 37.5845, GNorm = 0.8390, lr_0 = 5.2489e-04\n",
            "Validation rmse = 0.779896\n",
            " 28%|██▊       | 282/1000 [01:04<02:41,  4.45it/s]Epoch 282\n",
            "Loss = 2.4819e-03, PNorm = 37.5910, GNorm = 0.2133, lr_0 = 5.2337e-04\n",
            "Validation rmse = 0.791637\n",
            " 28%|██▊       | 283/1000 [01:04<02:41,  4.45it/s]Epoch 283\n",
            "Loss = 1.9967e-03, PNorm = 37.5962, GNorm = 0.3622, lr_0 = 5.2187e-04\n",
            "Validation rmse = 0.786336\n",
            " 28%|██▊       | 284/1000 [01:05<02:41,  4.44it/s]Epoch 284\n",
            "Loss = 2.4134e-03, PNorm = 37.5999, GNorm = 0.1673, lr_0 = 5.2036e-04\n",
            "Validation rmse = 0.782700\n",
            " 28%|██▊       | 285/1000 [01:05<02:40,  4.45it/s]Epoch 285\n",
            "Validation rmse = 0.798121\n",
            " 29%|██▊       | 286/1000 [01:05<02:40,  4.46it/s]Epoch 286\n",
            "Loss = 2.3235e-03, PNorm = 37.6048, GNorm = 0.1783, lr_0 = 5.1887e-04\n",
            "Validation rmse = 0.785688\n",
            " 29%|██▊       | 287/1000 [01:05<02:40,  4.45it/s]Epoch 287\n",
            "Loss = 2.3520e-03, PNorm = 37.6100, GNorm = 0.2866, lr_0 = 5.1737e-04\n",
            "Validation rmse = 0.781592\n",
            " 29%|██▉       | 288/1000 [01:05<02:40,  4.45it/s]Epoch 288\n",
            "Loss = 2.5165e-03, PNorm = 37.6153, GNorm = 0.3377, lr_0 = 5.1588e-04\n",
            "Validation rmse = 0.803677\n",
            " 29%|██▉       | 289/1000 [01:06<02:39,  4.45it/s]Epoch 289\n",
            "Loss = 4.2698e-03, PNorm = 37.6205, GNorm = 0.2174, lr_0 = 5.1440e-04\n",
            "Validation rmse = 0.783320\n",
            " 29%|██▉       | 290/1000 [01:06<02:40,  4.44it/s]Epoch 290\n",
            "Validation rmse = 0.812572\n",
            " 29%|██▉       | 291/1000 [01:06<02:39,  4.45it/s]Epoch 291\n",
            "Loss = 5.6258e-03, PNorm = 37.6268, GNorm = 0.4166, lr_0 = 5.1291e-04\n",
            "Validation rmse = 0.780837\n",
            " 29%|██▉       | 292/1000 [01:06<02:39,  4.45it/s]Epoch 292\n",
            "Loss = 6.7722e-03, PNorm = 37.6365, GNorm = 1.2485, lr_0 = 5.1144e-04\n",
            "Validation rmse = 0.773946\n",
            " 29%|██▉       | 293/1000 [01:07<02:38,  4.45it/s]Epoch 293\n",
            "Loss = 4.3378e-03, PNorm = 37.6423, GNorm = 0.4108, lr_0 = 5.0996e-04\n",
            "Validation rmse = 0.804139\n",
            " 29%|██▉       | 294/1000 [01:07<02:38,  4.45it/s]Epoch 294\n",
            "Loss = 3.8340e-03, PNorm = 37.6497, GNorm = 0.8555, lr_0 = 5.0850e-04\n",
            "Validation rmse = 0.809183\n",
            " 30%|██▉       | 295/1000 [01:07<02:38,  4.45it/s]Epoch 295\n",
            "Validation rmse = 0.776176\n",
            " 30%|██▉       | 296/1000 [01:07<02:37,  4.46it/s]Epoch 296\n",
            "Loss = 1.7374e-03, PNorm = 37.6549, GNorm = 0.1684, lr_0 = 5.0703e-04\n",
            "Validation rmse = 0.786320\n",
            " 30%|██▉       | 297/1000 [01:07<02:37,  4.46it/s]Epoch 297\n",
            "Loss = 3.0951e-03, PNorm = 37.6618, GNorm = 0.1391, lr_0 = 5.0557e-04\n",
            "Validation rmse = 0.777790\n",
            " 30%|██▉       | 298/1000 [01:08<02:37,  4.46it/s]Epoch 298\n",
            "Loss = 2.5440e-03, PNorm = 37.6664, GNorm = 0.2090, lr_0 = 5.0412e-04\n",
            "Validation rmse = 0.785580\n",
            " 30%|██▉       | 299/1000 [01:08<02:37,  4.45it/s]Epoch 299\n",
            "Loss = 4.3953e-03, PNorm = 37.6695, GNorm = 1.0994, lr_0 = 5.0266e-04\n",
            "Validation rmse = 0.793176\n",
            " 30%|███       | 300/1000 [01:08<02:37,  4.45it/s]Epoch 300\n",
            "Validation rmse = 0.785018\n",
            " 30%|███       | 301/1000 [01:08<02:37,  4.45it/s]Epoch 301\n",
            "Loss = 3.5634e-03, PNorm = 37.6738, GNorm = 0.7391, lr_0 = 5.0122e-04\n",
            "Validation rmse = 0.761499\n",
            " 30%|███       | 302/1000 [01:09<03:09,  3.69it/s]Epoch 302\n",
            "Loss = 2.3009e-03, PNorm = 37.6789, GNorm = 0.2991, lr_0 = 4.9977e-04\n",
            "Validation rmse = 0.802355\n",
            " 30%|███       | 303/1000 [01:09<02:59,  3.89it/s]Epoch 303\n",
            "Loss = 1.9564e-03, PNorm = 37.6849, GNorm = 0.3250, lr_0 = 4.9833e-04\n",
            "Validation rmse = 0.786918\n",
            " 30%|███       | 304/1000 [01:09<02:52,  4.04it/s]Epoch 304\n",
            "Loss = 2.7245e-03, PNorm = 37.6889, GNorm = 0.2344, lr_0 = 4.9690e-04\n",
            "Validation rmse = 0.774290\n",
            " 30%|███       | 305/1000 [01:09<02:47,  4.16it/s]Epoch 305\n",
            "Validation rmse = 0.789331\n",
            " 31%|███       | 306/1000 [01:10<02:43,  4.25it/s]Epoch 306\n",
            "Loss = 2.4541e-03, PNorm = 37.6938, GNorm = 0.2311, lr_0 = 4.9547e-04\n",
            "Validation rmse = 0.785307\n",
            " 31%|███       | 307/1000 [01:10<02:40,  4.31it/s]Epoch 307\n",
            "Loss = 3.3426e-03, PNorm = 37.6991, GNorm = 0.2411, lr_0 = 4.9404e-04\n",
            "Validation rmse = 0.798021\n",
            " 31%|███       | 308/1000 [01:10<02:38,  4.35it/s]Epoch 308\n",
            "Loss = 2.4428e-03, PNorm = 37.7023, GNorm = 0.1425, lr_0 = 4.9262e-04\n",
            "Validation rmse = 0.786596\n",
            " 31%|███       | 309/1000 [01:10<02:37,  4.39it/s]Epoch 309\n",
            "Loss = 2.0815e-03, PNorm = 37.7068, GNorm = 0.1704, lr_0 = 4.9120e-04\n",
            "Validation rmse = 0.800061\n",
            " 31%|███       | 310/1000 [01:11<02:36,  4.41it/s]Epoch 310\n",
            "Validation rmse = 0.787983\n",
            " 31%|███       | 311/1000 [01:11<02:36,  4.42it/s]Epoch 311\n",
            "Loss = 1.0519e-03, PNorm = 37.7114, GNorm = 0.1758, lr_0 = 4.8978e-04\n",
            "Validation rmse = 0.790690\n",
            " 31%|███       | 312/1000 [01:11<02:35,  4.43it/s]Epoch 312\n",
            "Loss = 2.2081e-03, PNorm = 37.7155, GNorm = 0.0958, lr_0 = 4.8837e-04\n",
            "Validation rmse = 0.790373\n",
            " 31%|███▏      | 313/1000 [01:11<02:34,  4.44it/s]Epoch 313\n",
            "Loss = 1.9672e-03, PNorm = 37.7204, GNorm = 0.2239, lr_0 = 4.8697e-04\n",
            "Validation rmse = 0.793353\n",
            " 31%|███▏      | 314/1000 [01:11<02:34,  4.44it/s]Epoch 314\n",
            "Loss = 2.1347e-03, PNorm = 37.7252, GNorm = 0.3373, lr_0 = 4.8557e-04\n",
            "Validation rmse = 0.799663\n",
            " 32%|███▏      | 315/1000 [01:12<02:34,  4.44it/s]Epoch 315\n",
            "Validation rmse = 0.777920\n",
            " 32%|███▏      | 316/1000 [01:12<02:33,  4.45it/s]Epoch 316\n",
            "Loss = 3.8106e-03, PNorm = 37.7281, GNorm = 0.4792, lr_0 = 4.8417e-04\n",
            "Validation rmse = 0.794281\n",
            " 32%|███▏      | 317/1000 [01:12<02:33,  4.45it/s]Epoch 317\n",
            "Loss = 2.2281e-03, PNorm = 37.7327, GNorm = 0.5612, lr_0 = 4.8277e-04\n",
            "Validation rmse = 0.792962\n",
            " 32%|███▏      | 318/1000 [01:12<02:34,  4.42it/s]Epoch 318\n",
            "Loss = 2.2333e-03, PNorm = 37.7380, GNorm = 0.2599, lr_0 = 4.8138e-04\n",
            "Validation rmse = 0.793094\n",
            " 32%|███▏      | 319/1000 [01:13<02:33,  4.43it/s]Epoch 319\n",
            "Loss = 2.2948e-03, PNorm = 37.7427, GNorm = 0.5225, lr_0 = 4.8000e-04\n",
            "Validation rmse = 0.803867\n",
            " 32%|███▏      | 320/1000 [01:13<02:33,  4.43it/s]Epoch 320\n",
            "Validation rmse = 0.793136\n",
            " 32%|███▏      | 321/1000 [01:13<02:32,  4.45it/s]Epoch 321\n",
            "Loss = 3.4184e-03, PNorm = 37.7488, GNorm = 0.8566, lr_0 = 4.7861e-04\n",
            "Validation rmse = 0.795780\n",
            " 32%|███▏      | 322/1000 [01:13<02:32,  4.45it/s]Epoch 322\n",
            "Loss = 3.6683e-03, PNorm = 37.7523, GNorm = 0.9403, lr_0 = 4.7724e-04\n",
            "Validation rmse = 0.800006\n",
            " 32%|███▏      | 323/1000 [01:13<02:32,  4.45it/s]Epoch 323\n",
            "Loss = 2.3938e-03, PNorm = 37.7565, GNorm = 0.5567, lr_0 = 4.7586e-04\n",
            "Validation rmse = 0.778993\n",
            " 32%|███▏      | 324/1000 [01:14<02:32,  4.44it/s]Epoch 324\n",
            "Loss = 2.4732e-03, PNorm = 37.7610, GNorm = 0.2864, lr_0 = 4.7449e-04\n",
            "Validation rmse = 0.790278\n",
            " 32%|███▎      | 325/1000 [01:14<02:32,  4.42it/s]Epoch 325\n",
            "Validation rmse = 0.824348\n",
            " 33%|███▎      | 326/1000 [01:14<02:32,  4.43it/s]Epoch 326\n",
            "Loss = 4.4109e-03, PNorm = 37.7660, GNorm = 0.9261, lr_0 = 4.7312e-04\n",
            "Validation rmse = 0.771143\n",
            " 33%|███▎      | 327/1000 [01:14<02:31,  4.43it/s]Epoch 327\n",
            "Loss = 5.1585e-03, PNorm = 37.7733, GNorm = 0.2774, lr_0 = 4.7176e-04\n",
            "Validation rmse = 0.803482\n",
            " 33%|███▎      | 328/1000 [01:15<02:31,  4.43it/s]Epoch 328\n",
            "Loss = 5.7660e-03, PNorm = 37.7802, GNorm = 0.9848, lr_0 = 4.7040e-04\n",
            "Validation rmse = 0.820390\n",
            " 33%|███▎      | 329/1000 [01:15<02:31,  4.43it/s]Epoch 329\n",
            "Loss = 3.9470e-03, PNorm = 37.7891, GNorm = 0.2965, lr_0 = 4.6905e-04\n",
            "Validation rmse = 0.774708\n",
            " 33%|███▎      | 330/1000 [01:15<02:31,  4.43it/s]Epoch 330\n",
            "Validation rmse = 0.821138\n",
            " 33%|███▎      | 331/1000 [01:15<02:30,  4.44it/s]Epoch 331\n",
            "Loss = 3.7649e-03, PNorm = 37.7963, GNorm = 0.2898, lr_0 = 4.6770e-04\n",
            "Validation rmse = 0.766630\n",
            " 33%|███▎      | 332/1000 [01:15<02:30,  4.44it/s]Epoch 332\n",
            "Loss = 3.6729e-03, PNorm = 37.8018, GNorm = 0.9005, lr_0 = 4.6635e-04\n",
            "Validation rmse = 0.825811\n",
            " 33%|███▎      | 333/1000 [01:16<02:30,  4.43it/s]Epoch 333\n",
            "Loss = 3.9249e-03, PNorm = 37.8079, GNorm = 0.5346, lr_0 = 4.6501e-04\n",
            "Validation rmse = 0.795571\n",
            " 33%|███▎      | 334/1000 [01:16<02:30,  4.43it/s]Epoch 334\n",
            "Loss = 2.2829e-03, PNorm = 37.8129, GNorm = 0.2904, lr_0 = 4.6367e-04\n",
            "Validation rmse = 0.781779\n",
            " 34%|███▎      | 335/1000 [01:16<02:30,  4.43it/s]Epoch 335\n",
            "Validation rmse = 0.810108\n",
            " 34%|███▎      | 336/1000 [01:16<02:29,  4.45it/s]Epoch 336\n",
            "Loss = 2.7961e-03, PNorm = 37.8178, GNorm = 0.4750, lr_0 = 4.6233e-04\n",
            "Validation rmse = 0.792890\n",
            " 34%|███▎      | 337/1000 [01:17<02:29,  4.45it/s]Epoch 337\n",
            "Loss = 1.2063e-03, PNorm = 37.8208, GNorm = 0.2316, lr_0 = 4.6100e-04\n",
            "Validation rmse = 0.795467\n",
            " 34%|███▍      | 338/1000 [01:17<02:29,  4.44it/s]Epoch 338\n",
            "Loss = 2.5489e-03, PNorm = 37.8258, GNorm = 0.1990, lr_0 = 4.5967e-04\n",
            "Validation rmse = 0.786715\n",
            " 34%|███▍      | 339/1000 [01:17<02:29,  4.43it/s]Epoch 339\n",
            "Loss = 2.1969e-03, PNorm = 37.8307, GNorm = 0.4614, lr_0 = 4.5835e-04\n",
            "Validation rmse = 0.814530\n",
            " 34%|███▍      | 340/1000 [01:17<02:28,  4.43it/s]Epoch 340\n",
            "Validation rmse = 0.779532\n",
            " 34%|███▍      | 341/1000 [01:18<02:28,  4.45it/s]Epoch 341\n",
            "Loss = 2.8833e-03, PNorm = 37.8358, GNorm = 0.3429, lr_0 = 4.5703e-04\n",
            "Validation rmse = 0.817887\n",
            " 34%|███▍      | 342/1000 [01:18<02:27,  4.45it/s]Epoch 342\n",
            "Loss = 3.0536e-03, PNorm = 37.8404, GNorm = 0.4346, lr_0 = 4.5571e-04\n",
            "Validation rmse = 0.788445\n",
            " 34%|███▍      | 343/1000 [01:18<02:27,  4.45it/s]Epoch 343\n",
            "Loss = 3.5160e-03, PNorm = 37.8445, GNorm = 0.5219, lr_0 = 4.5440e-04\n",
            "Validation rmse = 0.796219\n",
            " 34%|███▍      | 344/1000 [01:18<02:27,  4.45it/s]Epoch 344\n",
            "Loss = 2.3603e-03, PNorm = 37.8499, GNorm = 0.4616, lr_0 = 4.5309e-04\n",
            "Validation rmse = 0.791508\n",
            " 34%|███▍      | 345/1000 [01:18<02:27,  4.45it/s]Epoch 345\n",
            "Validation rmse = 0.790135\n",
            " 35%|███▍      | 346/1000 [01:19<02:26,  4.46it/s]Epoch 346\n",
            "Loss = 2.3583e-03, PNorm = 37.8534, GNorm = 0.2411, lr_0 = 4.5179e-04\n",
            "Validation rmse = 0.804129\n",
            " 35%|███▍      | 347/1000 [01:19<02:26,  4.46it/s]Epoch 347\n",
            "Loss = 2.5193e-03, PNorm = 37.8568, GNorm = 0.3517, lr_0 = 4.5049e-04\n",
            "Validation rmse = 0.793922\n",
            " 35%|███▍      | 348/1000 [01:19<02:26,  4.46it/s]Epoch 348\n",
            "Loss = 2.4261e-03, PNorm = 37.8606, GNorm = 0.9209, lr_0 = 4.4919e-04\n",
            "Validation rmse = 0.819366\n",
            " 35%|███▍      | 349/1000 [01:19<02:26,  4.46it/s]Epoch 349\n",
            "Loss = 2.1887e-03, PNorm = 37.8649, GNorm = 0.2216, lr_0 = 4.4790e-04\n",
            "Validation rmse = 0.800281\n",
            " 35%|███▌      | 350/1000 [01:20<02:25,  4.46it/s]Epoch 350\n",
            "Validation rmse = 0.789491\n",
            " 35%|███▌      | 351/1000 [01:20<02:25,  4.46it/s]Epoch 351\n",
            "Loss = 2.2799e-03, PNorm = 37.8689, GNorm = 0.6155, lr_0 = 4.4661e-04\n",
            "Validation rmse = 0.800273\n",
            " 35%|███▌      | 352/1000 [01:20<02:26,  4.44it/s]Epoch 352\n",
            "Loss = 3.4873e-03, PNorm = 37.8735, GNorm = 0.8278, lr_0 = 4.4532e-04\n",
            "Validation rmse = 0.787081\n",
            " 35%|███▌      | 353/1000 [01:20<02:25,  4.44it/s]Epoch 353\n",
            "Loss = 3.1212e-03, PNorm = 37.8761, GNorm = 0.5169, lr_0 = 4.4404e-04\n",
            "Validation rmse = 0.801599\n",
            " 35%|███▌      | 354/1000 [01:20<02:25,  4.44it/s]Epoch 354\n",
            "Loss = 3.3501e-03, PNorm = 37.8813, GNorm = 0.9637, lr_0 = 4.4276e-04\n",
            "Validation rmse = 0.783010\n",
            " 36%|███▌      | 355/1000 [01:21<02:25,  4.44it/s]Epoch 355\n",
            "Validation rmse = 0.798357\n",
            " 36%|███▌      | 356/1000 [01:21<02:25,  4.43it/s]Epoch 356\n",
            "Loss = 6.6406e-03, PNorm = 37.8866, GNorm = 1.4630, lr_0 = 4.4148e-04\n",
            "Validation rmse = 0.848506\n",
            " 36%|███▌      | 357/1000 [01:21<02:24,  4.44it/s]Epoch 357\n",
            "Loss = 5.7704e-03, PNorm = 37.8939, GNorm = 1.0038, lr_0 = 4.4021e-04\n",
            "Validation rmse = 0.794360\n",
            " 36%|███▌      | 358/1000 [01:21<02:24,  4.44it/s]Epoch 358\n",
            "Loss = 1.0320e-02, PNorm = 37.9011, GNorm = 1.7891, lr_0 = 4.3894e-04\n",
            "Validation rmse = 0.806347\n",
            " 36%|███▌      | 359/1000 [01:22<02:24,  4.44it/s]Epoch 359\n",
            "Loss = 7.3853e-03, PNorm = 37.9106, GNorm = 1.0087, lr_0 = 4.3768e-04\n",
            "Validation rmse = 0.801566\n",
            " 36%|███▌      | 360/1000 [01:22<02:23,  4.45it/s]Epoch 360\n",
            "Validation rmse = 0.777803\n",
            " 36%|███▌      | 361/1000 [01:22<02:23,  4.46it/s]Epoch 361\n",
            "Loss = 9.6505e-03, PNorm = 37.9217, GNorm = 1.7911, lr_0 = 4.3642e-04\n",
            "Validation rmse = 0.847194\n",
            " 36%|███▌      | 362/1000 [01:22<02:23,  4.45it/s]Epoch 362\n",
            "Loss = 4.5847e-03, PNorm = 37.9334, GNorm = 0.3916, lr_0 = 4.3516e-04\n",
            "Validation rmse = 0.790199\n",
            " 36%|███▋      | 363/1000 [01:22<02:23,  4.45it/s]Epoch 363\n",
            "Loss = 2.2321e-03, PNorm = 37.9445, GNorm = 0.3098, lr_0 = 4.3391e-04\n",
            "Validation rmse = 0.778188\n",
            " 36%|███▋      | 364/1000 [01:23<02:22,  4.45it/s]Epoch 364\n",
            "Loss = 3.2651e-03, PNorm = 37.9522, GNorm = 0.3977, lr_0 = 4.3266e-04\n",
            "Validation rmse = 0.820732\n",
            " 36%|███▋      | 365/1000 [01:23<02:23,  4.41it/s]Epoch 365\n",
            "Validation rmse = 0.791060\n",
            " 37%|███▋      | 366/1000 [01:23<02:23,  4.43it/s]Epoch 366\n",
            "Loss = 7.9865e-03, PNorm = 37.9578, GNorm = 1.1640, lr_0 = 4.3141e-04\n",
            "Validation rmse = 0.801214\n",
            " 37%|███▋      | 367/1000 [01:23<02:22,  4.44it/s]Epoch 367\n",
            "Loss = 2.6815e-03, PNorm = 37.9630, GNorm = 0.3132, lr_0 = 4.3017e-04\n",
            "Validation rmse = 0.780535\n",
            " 37%|███▋      | 368/1000 [01:24<02:22,  4.44it/s]Epoch 368\n",
            "Loss = 2.8341e-03, PNorm = 37.9675, GNorm = 0.3827, lr_0 = 4.2893e-04\n",
            "Validation rmse = 0.809012\n",
            " 37%|███▋      | 369/1000 [01:24<02:22,  4.44it/s]Epoch 369\n",
            "Loss = 2.6655e-03, PNorm = 37.9723, GNorm = 0.1059, lr_0 = 4.2770e-04\n",
            "Validation rmse = 0.785529\n",
            " 37%|███▋      | 370/1000 [01:24<02:22,  4.43it/s]Epoch 370\n",
            "Validation rmse = 0.802687\n",
            " 37%|███▋      | 371/1000 [01:24<02:21,  4.45it/s]Epoch 371\n",
            "Loss = 2.2203e-03, PNorm = 37.9766, GNorm = 0.2688, lr_0 = 4.2647e-04\n",
            "Validation rmse = 0.823521\n",
            " 37%|███▋      | 372/1000 [01:24<02:21,  4.45it/s]Epoch 372\n",
            "Loss = 2.0293e-03, PNorm = 37.9821, GNorm = 0.1933, lr_0 = 4.2524e-04\n",
            "Validation rmse = 0.809273\n",
            " 37%|███▋      | 373/1000 [01:25<02:21,  4.44it/s]Epoch 373\n",
            "Loss = 2.4350e-03, PNorm = 37.9841, GNorm = 0.1671, lr_0 = 4.2401e-04\n",
            "Validation rmse = 0.787107\n",
            " 37%|███▋      | 374/1000 [01:25<02:21,  4.44it/s]Epoch 374\n",
            "Loss = 1.8690e-03, PNorm = 37.9885, GNorm = 0.3216, lr_0 = 4.2279e-04\n",
            "Validation rmse = 0.803744\n",
            " 38%|███▊      | 375/1000 [01:25<02:20,  4.44it/s]Epoch 375\n",
            "Validation rmse = 0.805199\n",
            " 38%|███▊      | 376/1000 [01:25<02:20,  4.45it/s]Epoch 376\n",
            "Loss = 1.1893e-03, PNorm = 37.9929, GNorm = 0.1743, lr_0 = 4.2157e-04\n",
            "Validation rmse = 0.802829\n",
            " 38%|███▊      | 377/1000 [01:26<02:20,  4.44it/s]Epoch 377\n",
            "Loss = 2.4537e-03, PNorm = 37.9967, GNorm = 0.2097, lr_0 = 4.2036e-04\n",
            "Validation rmse = 0.806453\n",
            " 38%|███▊      | 378/1000 [01:26<02:19,  4.44it/s]Epoch 378\n",
            "Loss = 1.3546e-03, PNorm = 37.9999, GNorm = 0.1612, lr_0 = 4.1915e-04\n",
            "Validation rmse = 0.809762\n",
            " 38%|███▊      | 379/1000 [01:26<02:19,  4.45it/s]Epoch 379\n",
            "Loss = 1.6136e-03, PNorm = 38.0038, GNorm = 0.1685, lr_0 = 4.1794e-04\n",
            "Validation rmse = 0.805047\n",
            " 38%|███▊      | 380/1000 [01:26<02:19,  4.45it/s]Epoch 380\n",
            "Validation rmse = 0.813630\n",
            " 38%|███▊      | 381/1000 [01:27<02:18,  4.46it/s]Epoch 381\n",
            "Loss = 1.5050e-03, PNorm = 38.0075, GNorm = 0.1863, lr_0 = 4.1674e-04\n",
            "Validation rmse = 0.805369\n",
            " 38%|███▊      | 382/1000 [01:27<02:18,  4.46it/s]Epoch 382\n",
            "Loss = 3.6545e-03, PNorm = 38.0112, GNorm = 0.5557, lr_0 = 4.1554e-04\n",
            "Validation rmse = 0.779614\n",
            " 38%|███▊      | 383/1000 [01:27<02:18,  4.45it/s]Epoch 383\n",
            "Loss = 6.4280e-03, PNorm = 38.0160, GNorm = 1.2520, lr_0 = 4.1434e-04\n",
            "Validation rmse = 0.864609\n",
            " 38%|███▊      | 384/1000 [01:27<02:18,  4.45it/s]Epoch 384\n",
            "Loss = 3.8868e-03, PNorm = 38.0214, GNorm = 0.0955, lr_0 = 4.1315e-04\n",
            "Validation rmse = 0.789951\n",
            " 38%|███▊      | 385/1000 [01:27<02:18,  4.45it/s]Epoch 385\n",
            "Validation rmse = 0.818172\n",
            " 39%|███▊      | 386/1000 [01:28<02:17,  4.46it/s]Epoch 386\n",
            "Loss = 2.1376e-03, PNorm = 38.0262, GNorm = 0.3162, lr_0 = 4.1196e-04\n",
            "Validation rmse = 0.817705\n",
            " 39%|███▊      | 387/1000 [01:28<02:17,  4.46it/s]Epoch 387\n",
            "Loss = 2.5684e-03, PNorm = 38.0317, GNorm = 0.2127, lr_0 = 4.1077e-04\n",
            "Validation rmse = 0.800491\n",
            " 39%|███▉      | 388/1000 [01:28<02:17,  4.45it/s]Epoch 388\n",
            "Loss = 1.9299e-03, PNorm = 38.0361, GNorm = 0.1797, lr_0 = 4.0959e-04\n",
            "Validation rmse = 0.801056\n",
            " 39%|███▉      | 389/1000 [01:28<02:17,  4.44it/s]Epoch 389\n",
            "Loss = 2.0109e-03, PNorm = 38.0395, GNorm = 0.2494, lr_0 = 4.0841e-04\n",
            "Validation rmse = 0.822909\n",
            " 39%|███▉      | 390/1000 [01:29<02:17,  4.44it/s]Epoch 390\n",
            "Validation rmse = 0.797915\n",
            " 39%|███▉      | 391/1000 [01:29<02:16,  4.45it/s]Epoch 391\n",
            "Loss = 1.1228e-03, PNorm = 38.0449, GNorm = 0.3953, lr_0 = 4.0723e-04\n",
            "Validation rmse = 0.813967\n",
            " 39%|███▉      | 392/1000 [01:29<02:16,  4.45it/s]Epoch 392\n",
            "Loss = 1.8173e-03, PNorm = 38.0474, GNorm = 0.2862, lr_0 = 4.0606e-04\n",
            "Validation rmse = 0.794629\n",
            " 39%|███▉      | 393/1000 [01:29<02:17,  4.40it/s]Epoch 393\n",
            "Loss = 2.7712e-03, PNorm = 38.0518, GNorm = 0.4432, lr_0 = 4.0489e-04\n",
            "Validation rmse = 0.812201\n",
            " 39%|███▉      | 394/1000 [01:29<02:17,  4.41it/s]Epoch 394\n",
            "Loss = 2.3444e-03, PNorm = 38.0560, GNorm = 0.2633, lr_0 = 4.0373e-04\n",
            "Validation rmse = 0.808464\n",
            " 40%|███▉      | 395/1000 [01:30<02:16,  4.42it/s]Epoch 395\n",
            "Validation rmse = 0.801685\n",
            " 40%|███▉      | 396/1000 [01:30<02:16,  4.44it/s]Epoch 396\n",
            "Loss = 1.8380e-03, PNorm = 38.0595, GNorm = 0.3571, lr_0 = 4.0256e-04\n",
            "Validation rmse = 0.807304\n",
            " 40%|███▉      | 397/1000 [01:30<02:15,  4.45it/s]Epoch 397\n",
            "Loss = 1.7220e-03, PNorm = 38.0628, GNorm = 0.0988, lr_0 = 4.0140e-04\n",
            "Validation rmse = 0.811366\n",
            " 40%|███▉      | 398/1000 [01:30<02:15,  4.45it/s]Epoch 398\n",
            "Loss = 1.5099e-03, PNorm = 38.0657, GNorm = 0.1921, lr_0 = 4.0025e-04\n",
            "Validation rmse = 0.813819\n",
            " 40%|███▉      | 399/1000 [01:31<02:15,  4.45it/s]Epoch 399\n",
            "Loss = 2.0439e-03, PNorm = 38.0692, GNorm = 0.6336, lr_0 = 3.9910e-04\n",
            "Validation rmse = 0.814905\n",
            " 40%|████      | 400/1000 [01:31<02:14,  4.45it/s]Epoch 400\n",
            "Validation rmse = 0.795092\n",
            " 40%|████      | 401/1000 [01:31<02:14,  4.46it/s]Epoch 401\n",
            "Loss = 1.3130e-03, PNorm = 38.0730, GNorm = 0.1474, lr_0 = 3.9795e-04\n",
            "Validation rmse = 0.813652\n",
            " 40%|████      | 402/1000 [01:31<02:42,  3.67it/s]Epoch 402\n",
            "Loss = 2.4017e-03, PNorm = 38.0767, GNorm = 0.0991, lr_0 = 3.9680e-04\n",
            "Validation rmse = 0.799849\n",
            " 40%|████      | 403/1000 [01:32<02:34,  3.87it/s]Epoch 403\n",
            "Loss = 1.5703e-03, PNorm = 38.0801, GNorm = 0.2273, lr_0 = 3.9566e-04\n",
            "Validation rmse = 0.800054\n",
            " 40%|████      | 404/1000 [01:32<02:27,  4.03it/s]Epoch 404\n",
            "Loss = 1.4386e-03, PNorm = 38.0849, GNorm = 0.2193, lr_0 = 3.9452e-04\n",
            "Validation rmse = 0.804125\n",
            " 40%|████      | 405/1000 [01:32<02:23,  4.15it/s]Epoch 405\n",
            "Validation rmse = 0.803332\n",
            " 41%|████      | 406/1000 [01:32<02:20,  4.24it/s]Epoch 406\n",
            "Loss = 2.6287e-03, PNorm = 38.0876, GNorm = 0.7045, lr_0 = 3.9338e-04\n",
            "Validation rmse = 0.811648\n",
            " 41%|████      | 407/1000 [01:33<02:17,  4.30it/s]Epoch 407\n",
            "Loss = 1.7248e-03, PNorm = 38.0901, GNorm = 0.4589, lr_0 = 3.9225e-04\n",
            "Validation rmse = 0.797687\n",
            " 41%|████      | 408/1000 [01:33<02:16,  4.34it/s]Epoch 408\n",
            "Loss = 1.6810e-03, PNorm = 38.0929, GNorm = 0.5423, lr_0 = 3.9112e-04\n",
            "Validation rmse = 0.810667\n",
            " 41%|████      | 409/1000 [01:33<02:15,  4.37it/s]Epoch 409\n",
            "Loss = 1.4115e-03, PNorm = 38.0964, GNorm = 0.1785, lr_0 = 3.8999e-04\n",
            "Validation rmse = 0.804745\n",
            " 41%|████      | 410/1000 [01:33<02:14,  4.40it/s]Epoch 410\n",
            "Validation rmse = 0.805321\n",
            " 41%|████      | 411/1000 [01:33<02:13,  4.42it/s]Epoch 411\n",
            "Loss = 1.4073e-03, PNorm = 38.0999, GNorm = 0.2126, lr_0 = 3.8887e-04\n",
            "Validation rmse = 0.796980\n",
            " 41%|████      | 412/1000 [01:34<02:12,  4.43it/s]Epoch 412\n",
            "Loss = 1.9627e-03, PNorm = 38.1029, GNorm = 0.4771, lr_0 = 3.8775e-04\n",
            "Validation rmse = 0.820850\n",
            " 41%|████▏     | 413/1000 [01:34<02:12,  4.44it/s]Epoch 413\n",
            "Loss = 1.8239e-03, PNorm = 38.1052, GNorm = 0.4142, lr_0 = 3.8663e-04\n",
            "Validation rmse = 0.800332\n",
            " 41%|████▏     | 414/1000 [01:34<02:11,  4.44it/s]Epoch 414\n",
            "Loss = 3.4601e-03, PNorm = 38.1105, GNorm = 0.7446, lr_0 = 3.8552e-04\n",
            "Validation rmse = 0.814948\n",
            " 42%|████▏     | 415/1000 [01:34<02:11,  4.43it/s]Epoch 415\n",
            "Validation rmse = 0.808854\n",
            " 42%|████▏     | 416/1000 [01:35<02:11,  4.45it/s]Epoch 416\n",
            "Loss = 2.1454e-03, PNorm = 38.1178, GNorm = 0.6077, lr_0 = 3.8441e-04\n",
            "Validation rmse = 0.809292\n",
            " 42%|████▏     | 417/1000 [01:35<02:11,  4.45it/s]Epoch 417\n",
            "Loss = 2.2975e-03, PNorm = 38.1232, GNorm = 0.1794, lr_0 = 3.8330e-04\n",
            "Validation rmse = 0.794673\n",
            " 42%|████▏     | 418/1000 [01:35<02:10,  4.44it/s]Epoch 418\n",
            "Loss = 1.7680e-03, PNorm = 38.1278, GNorm = 0.3086, lr_0 = 3.8220e-04\n",
            "Validation rmse = 0.817085\n",
            " 42%|████▏     | 419/1000 [01:35<02:10,  4.45it/s]Epoch 419\n",
            "Loss = 1.8523e-03, PNorm = 38.1294, GNorm = 0.2654, lr_0 = 3.8110e-04\n",
            "Validation rmse = 0.800286\n",
            " 42%|████▏     | 420/1000 [01:35<02:11,  4.42it/s]Epoch 420\n",
            "Validation rmse = 0.805043\n",
            " 42%|████▏     | 421/1000 [01:36<02:10,  4.44it/s]Epoch 421\n",
            "Loss = 6.4373e-04, PNorm = 38.1339, GNorm = 0.1259, lr_0 = 3.8000e-04\n",
            "Validation rmse = 0.806037\n",
            " 42%|████▏     | 422/1000 [01:36<02:10,  4.44it/s]Epoch 422\n",
            "Loss = 5.0273e-04, PNorm = 38.1371, GNorm = 0.1101, lr_0 = 3.7891e-04\n",
            "Validation rmse = 0.822689\n",
            " 42%|████▏     | 423/1000 [01:36<02:09,  4.44it/s]Epoch 423\n",
            "Loss = 1.2179e-03, PNorm = 38.1405, GNorm = 0.2844, lr_0 = 3.7782e-04\n",
            "Validation rmse = 0.800679\n",
            " 42%|████▏     | 424/1000 [01:36<02:09,  4.44it/s]Epoch 424\n",
            "Loss = 1.6821e-03, PNorm = 38.1441, GNorm = 0.4578, lr_0 = 3.7673e-04\n",
            "Validation rmse = 0.806116\n",
            " 42%|████▎     | 425/1000 [01:37<02:09,  4.44it/s]Epoch 425\n",
            "Validation rmse = 0.812791\n",
            " 43%|████▎     | 426/1000 [01:37<02:08,  4.46it/s]Epoch 426\n",
            "Loss = 2.1244e-03, PNorm = 38.1467, GNorm = 0.3715, lr_0 = 3.7564e-04\n",
            "Validation rmse = 0.809873\n",
            " 43%|████▎     | 427/1000 [01:37<02:08,  4.46it/s]Epoch 427\n",
            "Loss = 1.0010e-03, PNorm = 38.1506, GNorm = 0.1993, lr_0 = 3.7456e-04\n",
            "Validation rmse = 0.822732\n",
            " 43%|████▎     | 428/1000 [01:37<02:08,  4.46it/s]Epoch 428\n",
            "Loss = 1.6169e-03, PNorm = 38.1536, GNorm = 0.2283, lr_0 = 3.7348e-04\n",
            "Validation rmse = 0.804895\n",
            " 43%|████▎     | 429/1000 [01:37<02:08,  4.46it/s]Epoch 429\n",
            "Loss = 1.3691e-03, PNorm = 38.1561, GNorm = 0.3726, lr_0 = 3.7241e-04\n",
            "Validation rmse = 0.801446\n",
            " 43%|████▎     | 430/1000 [01:38<02:08,  4.45it/s]Epoch 430\n",
            "Validation rmse = 0.835016\n",
            " 43%|████▎     | 431/1000 [01:38<02:07,  4.46it/s]Epoch 431\n",
            "Loss = 1.2591e-03, PNorm = 38.1588, GNorm = 0.1575, lr_0 = 3.7133e-04\n",
            "Validation rmse = 0.807180\n",
            " 43%|████▎     | 432/1000 [01:38<02:07,  4.45it/s]Epoch 432\n",
            "Loss = 2.1525e-03, PNorm = 38.1636, GNorm = 0.1866, lr_0 = 3.7026e-04\n",
            "Validation rmse = 0.819855\n",
            " 43%|████▎     | 433/1000 [01:38<02:07,  4.45it/s]Epoch 433\n",
            "Loss = 1.3928e-03, PNorm = 38.1693, GNorm = 0.2774, lr_0 = 3.6920e-04\n",
            "Validation rmse = 0.811204\n",
            " 43%|████▎     | 434/1000 [01:39<02:07,  4.45it/s]Epoch 434\n",
            "Loss = 1.5223e-03, PNorm = 38.1733, GNorm = 0.4648, lr_0 = 3.6813e-04\n",
            "Validation rmse = 0.814447\n",
            " 44%|████▎     | 435/1000 [01:39<02:06,  4.45it/s]Epoch 435\n",
            "Validation rmse = 0.804616\n",
            " 44%|████▎     | 436/1000 [01:39<02:06,  4.46it/s]Epoch 436\n",
            "Loss = 2.3511e-03, PNorm = 38.1763, GNorm = 0.7813, lr_0 = 3.6707e-04\n",
            "Validation rmse = 0.811580\n",
            " 44%|████▎     | 437/1000 [01:39<02:06,  4.46it/s]Epoch 437\n",
            "Loss = 1.5330e-03, PNorm = 38.1801, GNorm = 0.3002, lr_0 = 3.6602e-04\n",
            "Validation rmse = 0.818178\n",
            " 44%|████▍     | 438/1000 [01:39<02:06,  4.46it/s]Epoch 438\n",
            "Loss = 1.0783e-03, PNorm = 38.1824, GNorm = 0.0779, lr_0 = 3.6496e-04\n",
            "Validation rmse = 0.800526\n",
            " 44%|████▍     | 439/1000 [01:40<02:05,  4.45it/s]Epoch 439\n",
            "Loss = 1.9979e-03, PNorm = 38.1854, GNorm = 0.3288, lr_0 = 3.6391e-04\n",
            "Validation rmse = 0.809363\n",
            " 44%|████▍     | 440/1000 [01:40<02:05,  4.45it/s]Epoch 440\n",
            "Validation rmse = 0.828001\n",
            " 44%|████▍     | 441/1000 [01:40<02:05,  4.46it/s]Epoch 441\n",
            "Loss = 3.5055e-03, PNorm = 38.1880, GNorm = 0.5254, lr_0 = 3.6286e-04\n",
            "Validation rmse = 0.802968\n",
            " 44%|████▍     | 442/1000 [01:40<02:05,  4.46it/s]Epoch 442\n",
            "Loss = 2.2989e-03, PNorm = 38.1937, GNorm = 0.3681, lr_0 = 3.6182e-04\n",
            "Validation rmse = 0.807129\n",
            " 44%|████▍     | 443/1000 [01:41<02:05,  4.45it/s]Epoch 443\n",
            "Loss = 9.7144e-04, PNorm = 38.1977, GNorm = 0.4508, lr_0 = 3.6078e-04\n",
            "Validation rmse = 0.802028\n",
            " 44%|████▍     | 444/1000 [01:41<02:04,  4.45it/s]Epoch 444\n",
            "Loss = 1.9895e-03, PNorm = 38.2019, GNorm = 0.8217, lr_0 = 3.5974e-04\n",
            "Validation rmse = 0.802468\n",
            " 44%|████▍     | 445/1000 [01:41<02:05,  4.44it/s]Epoch 445\n",
            "Validation rmse = 0.831463\n",
            " 45%|████▍     | 446/1000 [01:41<02:04,  4.45it/s]Epoch 446\n",
            "Loss = 3.9084e-03, PNorm = 38.2059, GNorm = 0.7522, lr_0 = 3.5870e-04\n",
            "Validation rmse = 0.795705\n",
            " 45%|████▍     | 447/1000 [01:42<02:04,  4.45it/s]Epoch 447\n",
            "Loss = 2.7275e-03, PNorm = 38.2084, GNorm = 0.5193, lr_0 = 3.5767e-04\n",
            "Validation rmse = 0.813860\n",
            " 45%|████▍     | 448/1000 [01:42<02:04,  4.44it/s]Epoch 448\n",
            "Loss = 1.9575e-03, PNorm = 38.2149, GNorm = 0.2736, lr_0 = 3.5664e-04\n",
            "Validation rmse = 0.818997\n",
            " 45%|████▍     | 449/1000 [01:42<02:04,  4.43it/s]Epoch 449\n",
            "Loss = 3.5747e-03, PNorm = 38.2197, GNorm = 0.1673, lr_0 = 3.5561e-04\n",
            "Validation rmse = 0.801336\n",
            " 45%|████▌     | 450/1000 [01:42<02:03,  4.44it/s]Epoch 450\n",
            "Validation rmse = 0.832885\n",
            " 45%|████▌     | 451/1000 [01:42<02:03,  4.46it/s]Epoch 451\n",
            "Loss = 3.0728e-03, PNorm = 38.2237, GNorm = 0.6210, lr_0 = 3.5459e-04\n",
            "Validation rmse = 0.810079\n",
            " 45%|████▌     | 452/1000 [01:43<02:02,  4.46it/s]Epoch 452\n",
            "Loss = 2.0055e-03, PNorm = 38.2280, GNorm = 0.2257, lr_0 = 3.5357e-04\n",
            "Validation rmse = 0.817452\n",
            " 45%|████▌     | 453/1000 [01:43<02:02,  4.45it/s]Epoch 453\n",
            "Loss = 1.3758e-03, PNorm = 38.2311, GNorm = 0.2317, lr_0 = 3.5255e-04\n",
            "Validation rmse = 0.827693\n",
            " 45%|████▌     | 454/1000 [01:43<02:02,  4.45it/s]Epoch 454\n",
            "Loss = 1.8658e-03, PNorm = 38.2351, GNorm = 0.4402, lr_0 = 3.5153e-04\n",
            "Validation rmse = 0.799587\n",
            " 46%|████▌     | 455/1000 [01:43<02:02,  4.45it/s]Epoch 455\n",
            "Validation rmse = 0.815553\n",
            " 46%|████▌     | 456/1000 [01:44<02:01,  4.46it/s]Epoch 456\n",
            "Loss = 1.0915e-03, PNorm = 38.2383, GNorm = 0.3580, lr_0 = 3.5052e-04\n",
            "Validation rmse = 0.812682\n",
            " 46%|████▌     | 457/1000 [01:44<02:01,  4.46it/s]Epoch 457\n",
            "Loss = 1.5492e-03, PNorm = 38.2424, GNorm = 0.3023, lr_0 = 3.4951e-04\n",
            "Validation rmse = 0.815612\n",
            " 46%|████▌     | 458/1000 [01:44<02:01,  4.46it/s]Epoch 458\n",
            "Loss = 1.3032e-03, PNorm = 38.2451, GNorm = 0.3379, lr_0 = 3.4851e-04\n",
            "Validation rmse = 0.811516\n",
            " 46%|████▌     | 459/1000 [01:44<02:01,  4.46it/s]Epoch 459\n",
            "Loss = 1.2044e-03, PNorm = 38.2479, GNorm = 0.1592, lr_0 = 3.4750e-04\n",
            "Validation rmse = 0.818210\n",
            " 46%|████▌     | 460/1000 [01:44<02:01,  4.46it/s]Epoch 460\n",
            "Validation rmse = 0.808094\n",
            " 46%|████▌     | 461/1000 [01:45<02:01,  4.45it/s]Epoch 461\n",
            "Loss = 4.9466e-04, PNorm = 38.2509, GNorm = 0.1309, lr_0 = 3.4650e-04\n",
            "Validation rmse = 0.820085\n",
            " 46%|████▌     | 462/1000 [01:45<02:01,  4.44it/s]Epoch 462\n",
            "Loss = 6.7159e-04, PNorm = 38.2535, GNorm = 0.1837, lr_0 = 3.4550e-04\n",
            "Validation rmse = 0.807672\n",
            " 46%|████▋     | 463/1000 [01:45<02:00,  4.45it/s]Epoch 463\n",
            "Loss = 1.4020e-03, PNorm = 38.2569, GNorm = 0.3151, lr_0 = 3.4451e-04\n",
            "Validation rmse = 0.826300\n",
            " 46%|████▋     | 464/1000 [01:45<02:00,  4.45it/s]Epoch 464\n",
            "Loss = 1.3623e-03, PNorm = 38.2590, GNorm = 0.1624, lr_0 = 3.4352e-04\n",
            "Validation rmse = 0.803850\n",
            " 46%|████▋     | 465/1000 [01:46<02:00,  4.45it/s]Epoch 465\n",
            "Validation rmse = 0.822736\n",
            " 47%|████▋     | 466/1000 [01:46<01:59,  4.46it/s]Epoch 466\n",
            "Loss = 4.6289e-04, PNorm = 38.2617, GNorm = 0.1278, lr_0 = 3.4253e-04\n",
            "Validation rmse = 0.814704\n",
            " 47%|████▋     | 467/1000 [01:46<01:59,  4.46it/s]Epoch 467\n",
            "Loss = 1.1950e-03, PNorm = 38.2646, GNorm = 0.2064, lr_0 = 3.4154e-04\n",
            "Validation rmse = 0.818744\n",
            " 47%|████▋     | 468/1000 [01:46<01:59,  4.45it/s]Epoch 468\n",
            "Loss = 8.3910e-04, PNorm = 38.2678, GNorm = 0.1852, lr_0 = 3.4056e-04\n",
            "Validation rmse = 0.817774\n",
            " 47%|████▋     | 469/1000 [01:46<01:59,  4.45it/s]Epoch 469\n",
            "Loss = 1.0085e-03, PNorm = 38.2702, GNorm = 0.1742, lr_0 = 3.3958e-04\n",
            "Validation rmse = 0.807620\n",
            " 47%|████▋     | 470/1000 [01:47<01:59,  4.45it/s]Epoch 470\n",
            "Validation rmse = 0.817072\n",
            " 47%|████▋     | 471/1000 [01:47<01:58,  4.46it/s]Epoch 471\n",
            "Loss = 8.0155e-04, PNorm = 38.2738, GNorm = 0.1064, lr_0 = 3.3860e-04\n",
            "Validation rmse = 0.809216\n",
            " 47%|████▋     | 472/1000 [01:47<01:58,  4.45it/s]Epoch 472\n",
            "Loss = 1.2043e-03, PNorm = 38.2759, GNorm = 0.3718, lr_0 = 3.3762e-04\n",
            "Validation rmse = 0.830192\n",
            " 47%|████▋     | 473/1000 [01:47<01:58,  4.45it/s]Epoch 473\n",
            "Loss = 1.5430e-03, PNorm = 38.2783, GNorm = 0.3569, lr_0 = 3.3665e-04\n",
            "Validation rmse = 0.809245\n",
            " 47%|████▋     | 474/1000 [01:48<01:58,  4.45it/s]Epoch 474\n",
            "Loss = 1.7529e-03, PNorm = 38.2824, GNorm = 0.5343, lr_0 = 3.3568e-04\n",
            "Validation rmse = 0.836410\n",
            " 48%|████▊     | 475/1000 [01:48<01:58,  4.45it/s]Epoch 475\n",
            "Validation rmse = 0.804541\n",
            " 48%|████▊     | 476/1000 [01:48<01:57,  4.45it/s]Epoch 476\n",
            "Loss = 1.0213e-03, PNorm = 38.2862, GNorm = 0.1119, lr_0 = 3.3471e-04\n",
            "Validation rmse = 0.818133\n",
            " 48%|████▊     | 477/1000 [01:48<01:58,  4.43it/s]Epoch 477\n",
            "Loss = 1.4198e-03, PNorm = 38.2898, GNorm = 0.2001, lr_0 = 3.3375e-04\n",
            "Validation rmse = 0.807419\n",
            " 48%|████▊     | 478/1000 [01:48<01:57,  4.43it/s]Epoch 478\n",
            "Loss = 7.1375e-04, PNorm = 38.2924, GNorm = 0.1537, lr_0 = 3.3279e-04\n",
            "Validation rmse = 0.815427\n",
            " 48%|████▊     | 479/1000 [01:49<01:57,  4.44it/s]Epoch 479\n",
            "Loss = 1.0944e-03, PNorm = 38.2946, GNorm = 0.2734, lr_0 = 3.3183e-04\n",
            "Validation rmse = 0.813549\n",
            " 48%|████▊     | 480/1000 [01:49<01:57,  4.44it/s]Epoch 480\n",
            "Validation rmse = 0.816236\n",
            " 48%|████▊     | 481/1000 [01:49<01:56,  4.45it/s]Epoch 481\n",
            "Loss = 1.0126e-03, PNorm = 38.2967, GNorm = 0.1948, lr_0 = 3.3088e-04\n",
            "Validation rmse = 0.813910\n",
            " 48%|████▊     | 482/1000 [01:49<01:56,  4.45it/s]Epoch 482\n",
            "Loss = 1.1971e-03, PNorm = 38.2997, GNorm = 0.1193, lr_0 = 3.2992e-04\n",
            "Validation rmse = 0.817684\n",
            " 48%|████▊     | 483/1000 [01:50<01:56,  4.45it/s]Epoch 483\n",
            "Loss = 1.1878e-03, PNorm = 38.3027, GNorm = 0.2479, lr_0 = 3.2897e-04\n",
            "Validation rmse = 0.810056\n",
            " 48%|████▊     | 484/1000 [01:50<01:56,  4.45it/s]Epoch 484\n",
            "Loss = 1.6426e-03, PNorm = 38.3062, GNorm = 0.6905, lr_0 = 3.2802e-04\n",
            "Validation rmse = 0.804733\n",
            " 48%|████▊     | 485/1000 [01:50<01:55,  4.45it/s]Epoch 485\n",
            "Validation rmse = 0.842801\n",
            " 49%|████▊     | 486/1000 [01:50<01:55,  4.46it/s]Epoch 486\n",
            "Loss = 2.3169e-03, PNorm = 38.3099, GNorm = 0.7981, lr_0 = 3.2708e-04\n",
            "Validation rmse = 0.805047\n",
            " 49%|████▊     | 487/1000 [01:51<01:56,  4.42it/s]Epoch 487\n",
            "Loss = 1.8121e-03, PNorm = 38.3138, GNorm = 0.5710, lr_0 = 3.2614e-04\n",
            "Validation rmse = 0.821624\n",
            " 49%|████▉     | 488/1000 [01:51<01:55,  4.42it/s]Epoch 488\n",
            "Loss = 1.4293e-03, PNorm = 38.3162, GNorm = 0.0966, lr_0 = 3.2520e-04\n",
            "Validation rmse = 0.818740\n",
            " 49%|████▉     | 489/1000 [01:51<01:55,  4.42it/s]Epoch 489\n",
            "Loss = 1.6498e-03, PNorm = 38.3195, GNorm = 0.1293, lr_0 = 3.2426e-04\n",
            "Validation rmse = 0.811878\n",
            " 49%|████▉     | 490/1000 [01:51<01:55,  4.43it/s]Epoch 490\n",
            "Validation rmse = 0.816041\n",
            " 49%|████▉     | 491/1000 [01:51<01:54,  4.44it/s]Epoch 491\n",
            "Loss = 1.7723e-03, PNorm = 38.3222, GNorm = 0.0899, lr_0 = 3.2333e-04\n",
            "Validation rmse = 0.814622\n",
            " 49%|████▉     | 492/1000 [01:52<01:54,  4.44it/s]Epoch 492\n",
            "Loss = 1.1804e-03, PNorm = 38.3258, GNorm = 0.1065, lr_0 = 3.2240e-04\n",
            "Validation rmse = 0.825334\n",
            " 49%|████▉     | 493/1000 [01:52<01:54,  4.43it/s]Epoch 493\n",
            "Loss = 1.4307e-03, PNorm = 38.3285, GNorm = 0.1329, lr_0 = 3.2147e-04\n",
            "Validation rmse = 0.811878\n",
            " 49%|████▉     | 494/1000 [01:52<01:54,  4.44it/s]Epoch 494\n",
            "Loss = 1.2501e-03, PNorm = 38.3306, GNorm = 0.2970, lr_0 = 3.2054e-04\n",
            "Validation rmse = 0.806397\n",
            " 50%|████▉     | 495/1000 [01:52<01:53,  4.44it/s]Epoch 495\n",
            "Validation rmse = 0.817816\n",
            " 50%|████▉     | 496/1000 [01:53<01:53,  4.46it/s]Epoch 496\n",
            "Loss = 8.6170e-04, PNorm = 38.3337, GNorm = 0.2130, lr_0 = 3.1962e-04\n",
            "Validation rmse = 0.814216\n",
            " 50%|████▉     | 497/1000 [01:53<01:52,  4.46it/s]Epoch 497\n",
            "Loss = 9.7649e-04, PNorm = 38.3361, GNorm = 0.1775, lr_0 = 3.1870e-04\n",
            "Validation rmse = 0.824624\n",
            " 50%|████▉     | 498/1000 [01:53<01:52,  4.45it/s]Epoch 498\n",
            "Loss = 1.2781e-03, PNorm = 38.3384, GNorm = 0.5811, lr_0 = 3.1778e-04\n",
            "Validation rmse = 0.812092\n",
            " 50%|████▉     | 499/1000 [01:53<01:52,  4.45it/s]Epoch 499\n",
            "Loss = 1.3723e-03, PNorm = 38.3416, GNorm = 0.2685, lr_0 = 3.1687e-04\n",
            "Validation rmse = 0.820338\n",
            " 50%|█████     | 500/1000 [01:53<01:52,  4.45it/s]Epoch 500\n",
            "Validation rmse = 0.832070\n",
            " 50%|█████     | 501/1000 [01:54<01:51,  4.47it/s]Epoch 501\n",
            "Loss = 1.2944e-03, PNorm = 38.3445, GNorm = 0.3861, lr_0 = 3.1595e-04\n",
            "Validation rmse = 0.809844\n",
            " 50%|█████     | 502/1000 [01:54<01:51,  4.46it/s]Epoch 502\n",
            "Loss = 1.0589e-03, PNorm = 38.3486, GNorm = 0.1380, lr_0 = 3.1504e-04\n",
            "Validation rmse = 0.817562\n",
            " 50%|█████     | 503/1000 [01:54<02:13,  3.72it/s]Epoch 503\n",
            "Loss = 1.1373e-03, PNorm = 38.3501, GNorm = 0.3404, lr_0 = 3.1414e-04\n",
            "Validation rmse = 0.819517\n",
            " 50%|█████     | 504/1000 [01:54<02:06,  3.91it/s]Epoch 504\n",
            "Loss = 9.8158e-04, PNorm = 38.3532, GNorm = 0.3495, lr_0 = 3.1323e-04\n",
            "Validation rmse = 0.817018\n",
            " 50%|█████     | 505/1000 [01:55<02:02,  4.05it/s]Epoch 505\n",
            "Validation rmse = 0.809991\n",
            " 51%|█████     | 506/1000 [01:55<01:58,  4.17it/s]Epoch 506\n",
            "Loss = 8.0970e-04, PNorm = 38.3555, GNorm = 0.2366, lr_0 = 3.1233e-04\n",
            "Validation rmse = 0.834302\n",
            " 51%|█████     | 507/1000 [01:55<01:55,  4.26it/s]Epoch 507\n",
            "Loss = 1.3817e-03, PNorm = 38.3576, GNorm = 0.2212, lr_0 = 3.1143e-04\n",
            "Validation rmse = 0.813808\n",
            " 51%|█████     | 508/1000 [01:55<01:54,  4.31it/s]Epoch 508\n",
            "Loss = 1.2364e-03, PNorm = 38.3620, GNorm = 0.2033, lr_0 = 3.1053e-04\n",
            "Validation rmse = 0.808355\n",
            " 51%|█████     | 509/1000 [01:56<01:52,  4.35it/s]Epoch 509\n",
            "Loss = 1.4949e-03, PNorm = 38.3641, GNorm = 0.3656, lr_0 = 3.0964e-04\n",
            "Validation rmse = 0.827381\n",
            " 51%|█████     | 510/1000 [01:56<01:51,  4.38it/s]Epoch 510\n",
            "Validation rmse = 0.807461\n",
            " 51%|█████     | 511/1000 [01:56<01:50,  4.41it/s]Epoch 511\n",
            "Loss = 2.8512e-03, PNorm = 38.3660, GNorm = 0.8911, lr_0 = 3.0875e-04\n",
            "Validation rmse = 0.848072\n",
            " 51%|█████     | 512/1000 [01:56<01:50,  4.42it/s]Epoch 512\n",
            "Loss = 3.7101e-03, PNorm = 38.3699, GNorm = 0.8413, lr_0 = 3.0786e-04\n",
            "Validation rmse = 0.829534\n",
            " 51%|█████▏    | 513/1000 [01:56<01:49,  4.43it/s]Epoch 513\n",
            "Loss = 3.5004e-03, PNorm = 38.3743, GNorm = 0.5314, lr_0 = 3.0697e-04\n",
            "Validation rmse = 0.809924\n",
            " 51%|█████▏    | 514/1000 [01:57<01:49,  4.44it/s]Epoch 514\n",
            "Loss = 3.0446e-03, PNorm = 38.3786, GNorm = 0.3865, lr_0 = 3.0609e-04\n",
            "Validation rmse = 0.805954\n",
            " 52%|█████▏    | 515/1000 [01:57<01:49,  4.44it/s]Epoch 515\n",
            "Validation rmse = 0.823855\n",
            " 52%|█████▏    | 516/1000 [01:57<01:48,  4.46it/s]Epoch 516\n",
            "Loss = 1.7229e-03, PNorm = 38.3827, GNorm = 0.3015, lr_0 = 3.0521e-04\n",
            "Validation rmse = 0.830206\n",
            " 52%|█████▏    | 517/1000 [01:57<01:48,  4.45it/s]Epoch 517\n",
            "Loss = 2.2469e-03, PNorm = 38.3863, GNorm = 0.2665, lr_0 = 3.0433e-04\n",
            "Validation rmse = 0.798794\n",
            " 52%|█████▏    | 518/1000 [01:58<01:48,  4.45it/s]Epoch 518\n",
            "Loss = 1.7913e-03, PNorm = 38.3903, GNorm = 0.3067, lr_0 = 3.0345e-04\n",
            "Validation rmse = 0.821255\n",
            " 52%|█████▏    | 519/1000 [01:58<01:48,  4.45it/s]Epoch 519\n",
            "Loss = 2.3726e-03, PNorm = 38.3959, GNorm = 0.2261, lr_0 = 3.0258e-04\n",
            "Validation rmse = 0.794636\n",
            " 52%|█████▏    | 520/1000 [01:58<01:47,  4.45it/s]Epoch 520\n",
            "Validation rmse = 0.817010\n",
            " 52%|█████▏    | 521/1000 [01:58<01:47,  4.46it/s]Epoch 521\n",
            "Loss = 9.2594e-04, PNorm = 38.3996, GNorm = 0.2635, lr_0 = 3.0171e-04\n",
            "Validation rmse = 0.813497\n",
            " 52%|█████▏    | 522/1000 [01:59<01:47,  4.46it/s]Epoch 522\n",
            "Loss = 8.4748e-04, PNorm = 38.4033, GNorm = 0.1697, lr_0 = 3.0084e-04\n",
            "Validation rmse = 0.829860\n",
            " 52%|█████▏    | 523/1000 [01:59<01:46,  4.46it/s]Epoch 523\n",
            "Loss = 1.2870e-03, PNorm = 38.4076, GNorm = 0.2022, lr_0 = 2.9997e-04\n",
            "Validation rmse = 0.813296\n",
            " 52%|█████▏    | 524/1000 [01:59<01:46,  4.46it/s]Epoch 524\n",
            "Loss = 9.1020e-04, PNorm = 38.4098, GNorm = 0.1431, lr_0 = 2.9911e-04\n",
            "Validation rmse = 0.828102\n",
            " 52%|█████▎    | 525/1000 [01:59<01:46,  4.46it/s]Epoch 525\n",
            "Validation rmse = 0.817206\n",
            " 53%|█████▎    | 526/1000 [01:59<01:46,  4.47it/s]Epoch 526\n",
            "Loss = 4.8672e-04, PNorm = 38.4121, GNorm = 0.1236, lr_0 = 2.9825e-04\n",
            "Validation rmse = 0.817252\n",
            " 53%|█████▎    | 527/1000 [02:00<01:46,  4.46it/s]Epoch 527\n",
            "Loss = 5.4604e-04, PNorm = 38.4138, GNorm = 0.1882, lr_0 = 2.9739e-04\n",
            "Validation rmse = 0.824103\n",
            " 53%|█████▎    | 528/1000 [02:00<01:46,  4.43it/s]Epoch 528\n",
            "Loss = 5.1111e-04, PNorm = 38.4157, GNorm = 0.1068, lr_0 = 2.9653e-04\n",
            "Validation rmse = 0.814725\n",
            " 53%|█████▎    | 529/1000 [02:00<01:46,  4.44it/s]Epoch 529\n",
            "Loss = 9.4441e-04, PNorm = 38.4176, GNorm = 0.1761, lr_0 = 2.9568e-04\n",
            "Validation rmse = 0.813457\n",
            " 53%|█████▎    | 530/1000 [02:00<01:45,  4.44it/s]Epoch 530\n",
            "Validation rmse = 0.825652\n",
            " 53%|█████▎    | 531/1000 [02:01<01:45,  4.46it/s]Epoch 531\n",
            "Loss = 5.0039e-04, PNorm = 38.4191, GNorm = 0.0562, lr_0 = 2.9482e-04\n",
            "Validation rmse = 0.812896\n",
            " 53%|█████▎    | 532/1000 [02:01<01:45,  4.45it/s]Epoch 532\n",
            "Loss = 6.9022e-04, PNorm = 38.4213, GNorm = 0.2035, lr_0 = 2.9398e-04\n",
            "Validation rmse = 0.816090\n",
            " 53%|█████▎    | 533/1000 [02:01<01:44,  4.45it/s]Epoch 533\n",
            "Loss = 7.0397e-04, PNorm = 38.4243, GNorm = 0.2082, lr_0 = 2.9313e-04\n",
            "Validation rmse = 0.823705\n",
            " 53%|█████▎    | 534/1000 [02:01<01:44,  4.45it/s]Epoch 534\n",
            "Loss = 1.0064e-03, PNorm = 38.4259, GNorm = 0.0969, lr_0 = 2.9229e-04\n",
            "Validation rmse = 0.823919\n",
            " 54%|█████▎    | 535/1000 [02:01<01:44,  4.45it/s]Epoch 535\n",
            "Validation rmse = 0.817946\n",
            " 54%|█████▎    | 536/1000 [02:02<01:44,  4.46it/s]Epoch 536\n",
            "Loss = 7.6434e-04, PNorm = 38.4279, GNorm = 0.1860, lr_0 = 2.9144e-04\n",
            "Validation rmse = 0.814251\n",
            " 54%|█████▎    | 537/1000 [02:02<01:43,  4.46it/s]Epoch 537\n",
            "Loss = 6.5664e-04, PNorm = 38.4293, GNorm = 0.0896, lr_0 = 2.9060e-04\n",
            "Validation rmse = 0.830623\n",
            " 54%|█████▍    | 538/1000 [02:02<01:43,  4.45it/s]Epoch 538\n",
            "Loss = 1.1981e-03, PNorm = 38.4315, GNorm = 0.1279, lr_0 = 2.8977e-04\n",
            "Validation rmse = 0.814132\n",
            " 54%|█████▍    | 539/1000 [02:02<01:43,  4.45it/s]Epoch 539\n",
            "Loss = 1.1221e-03, PNorm = 38.4336, GNorm = 0.1936, lr_0 = 2.8893e-04\n",
            "Validation rmse = 0.818709\n",
            " 54%|█████▍    | 540/1000 [02:03<01:43,  4.46it/s]Epoch 540\n",
            "Validation rmse = 0.819855\n",
            " 54%|█████▍    | 541/1000 [02:03<01:42,  4.47it/s]Epoch 541\n",
            "Loss = 1.2473e-03, PNorm = 38.4358, GNorm = 0.3189, lr_0 = 2.8810e-04\n",
            "Validation rmse = 0.815047\n",
            " 54%|█████▍    | 542/1000 [02:03<01:42,  4.46it/s]Epoch 542\n",
            "Loss = 1.0012e-03, PNorm = 38.4381, GNorm = 0.1552, lr_0 = 2.8727e-04\n",
            "Validation rmse = 0.812389\n",
            " 54%|█████▍    | 543/1000 [02:03<01:42,  4.46it/s]Epoch 543\n",
            "Loss = 1.3601e-03, PNorm = 38.4396, GNorm = 0.2484, lr_0 = 2.8644e-04\n",
            "Validation rmse = 0.822307\n",
            " 54%|█████▍    | 544/1000 [02:03<01:42,  4.46it/s]Epoch 544\n",
            "Loss = 1.0119e-03, PNorm = 38.4421, GNorm = 0.2301, lr_0 = 2.8562e-04\n",
            "Validation rmse = 0.810592\n",
            " 55%|█████▍    | 545/1000 [02:04<01:42,  4.46it/s]Epoch 545\n",
            "Validation rmse = 0.820020\n",
            " 55%|█████▍    | 546/1000 [02:04<01:41,  4.47it/s]Epoch 546\n",
            "Loss = 1.3941e-03, PNorm = 38.4453, GNorm = 0.1822, lr_0 = 2.8480e-04\n",
            "Validation rmse = 0.826801\n",
            " 55%|█████▍    | 547/1000 [02:04<01:41,  4.46it/s]Epoch 547\n",
            "Loss = 9.4332e-04, PNorm = 38.4480, GNorm = 0.2177, lr_0 = 2.8398e-04\n",
            "Validation rmse = 0.814116\n",
            " 55%|█████▍    | 548/1000 [02:04<01:41,  4.44it/s]Epoch 548\n",
            "Loss = 7.0545e-04, PNorm = 38.4493, GNorm = 0.1215, lr_0 = 2.8316e-04\n",
            "Validation rmse = 0.821742\n",
            " 55%|█████▍    | 549/1000 [02:05<01:41,  4.44it/s]Epoch 549\n",
            "Loss = 8.2204e-04, PNorm = 38.4516, GNorm = 0.1124, lr_0 = 2.8234e-04\n",
            "Validation rmse = 0.816618\n",
            " 55%|█████▌    | 550/1000 [02:05<01:41,  4.44it/s]Epoch 550\n",
            "Validation rmse = 0.830744\n",
            " 55%|█████▌    | 551/1000 [02:05<01:40,  4.46it/s]Epoch 551\n",
            "Loss = 1.2412e-03, PNorm = 38.4535, GNorm = 0.1107, lr_0 = 2.8153e-04\n",
            "Validation rmse = 0.820939\n",
            " 55%|█████▌    | 552/1000 [02:05<01:40,  4.46it/s]Epoch 552\n",
            "Loss = 5.2704e-04, PNorm = 38.4555, GNorm = 0.1492, lr_0 = 2.8072e-04\n",
            "Validation rmse = 0.823933\n",
            " 55%|█████▌    | 553/1000 [02:05<01:40,  4.45it/s]Epoch 553\n",
            "Loss = 5.7356e-04, PNorm = 38.4568, GNorm = 0.1772, lr_0 = 2.7991e-04\n",
            "Validation rmse = 0.823749\n",
            " 55%|█████▌    | 554/1000 [02:06<01:40,  4.45it/s]Epoch 554\n",
            "Loss = 7.8504e-04, PNorm = 38.4583, GNorm = 0.0726, lr_0 = 2.7910e-04\n",
            "Validation rmse = 0.819444\n",
            " 56%|█████▌    | 555/1000 [02:06<01:39,  4.46it/s]Epoch 555\n",
            "Validation rmse = 0.830524\n",
            " 56%|█████▌    | 556/1000 [02:06<01:39,  4.47it/s]Epoch 556\n",
            "Loss = 4.0725e-04, PNorm = 38.4614, GNorm = 0.1799, lr_0 = 2.7830e-04\n",
            "Validation rmse = 0.812083\n",
            " 56%|█████▌    | 557/1000 [02:06<01:39,  4.46it/s]Epoch 557\n",
            "Loss = 1.7238e-03, PNorm = 38.4629, GNorm = 0.1808, lr_0 = 2.7750e-04\n",
            "Validation rmse = 0.825929\n",
            " 56%|█████▌    | 558/1000 [02:07<01:39,  4.46it/s]Epoch 558\n",
            "Loss = 1.5277e-03, PNorm = 38.4663, GNorm = 0.0807, lr_0 = 2.7670e-04\n",
            "Validation rmse = 0.825048\n",
            " 56%|█████▌    | 559/1000 [02:07<01:38,  4.46it/s]Epoch 559\n",
            "Loss = 1.2493e-03, PNorm = 38.4681, GNorm = 0.1257, lr_0 = 2.7590e-04\n",
            "Validation rmse = 0.809252\n",
            " 56%|█████▌    | 560/1000 [02:07<01:38,  4.46it/s]Epoch 560\n",
            "Validation rmse = 0.821675\n",
            " 56%|█████▌    | 561/1000 [02:07<01:38,  4.47it/s]Epoch 561\n",
            "Loss = 9.0645e-04, PNorm = 38.4695, GNorm = 0.2300, lr_0 = 2.7511e-04\n",
            "Validation rmse = 0.823128\n",
            " 56%|█████▌    | 562/1000 [02:07<01:38,  4.46it/s]Epoch 562\n",
            "Loss = 3.7164e-04, PNorm = 38.4719, GNorm = 0.0734, lr_0 = 2.7432e-04\n",
            "Validation rmse = 0.823374\n",
            " 56%|█████▋    | 563/1000 [02:08<01:37,  4.46it/s]Epoch 563\n",
            "Loss = 9.0013e-04, PNorm = 38.4738, GNorm = 0.0832, lr_0 = 2.7353e-04\n",
            "Validation rmse = 0.816543\n",
            " 56%|█████▋    | 564/1000 [02:08<01:37,  4.46it/s]Epoch 564\n",
            "Loss = 9.3987e-04, PNorm = 38.4764, GNorm = 0.1946, lr_0 = 2.7274e-04\n",
            "Validation rmse = 0.815319\n",
            " 56%|█████▋    | 565/1000 [02:08<01:37,  4.46it/s]Epoch 565\n",
            "Validation rmse = 0.827499\n",
            " 57%|█████▋    | 566/1000 [02:08<01:37,  4.47it/s]Epoch 566\n",
            "Loss = 5.8905e-04, PNorm = 38.4769, GNorm = 0.2968, lr_0 = 2.7195e-04\n",
            "Validation rmse = 0.831093\n",
            " 57%|█████▋    | 567/1000 [02:09<01:37,  4.44it/s]Epoch 567\n",
            "Loss = 1.1275e-03, PNorm = 38.4786, GNorm = 0.3575, lr_0 = 2.7117e-04\n",
            "Validation rmse = 0.817276\n",
            " 57%|█████▋    | 568/1000 [02:09<01:37,  4.44it/s]Epoch 568\n",
            "Loss = 1.3106e-03, PNorm = 38.4814, GNorm = 0.4557, lr_0 = 2.7039e-04\n",
            "Validation rmse = 0.821098\n",
            " 57%|█████▋    | 569/1000 [02:09<01:37,  4.41it/s]Epoch 569\n",
            "Loss = 1.1871e-03, PNorm = 38.4846, GNorm = 0.2654, lr_0 = 2.6961e-04\n",
            "Validation rmse = 0.833073\n",
            " 57%|█████▋    | 570/1000 [02:09<01:37,  4.42it/s]Epoch 570\n",
            "Validation rmse = 0.818698\n",
            " 57%|█████▋    | 571/1000 [02:10<01:36,  4.44it/s]Epoch 571\n",
            "Loss = 8.0540e-04, PNorm = 38.4868, GNorm = 0.3685, lr_0 = 2.6883e-04\n",
            "Validation rmse = 0.837693\n",
            " 57%|█████▋    | 572/1000 [02:10<01:36,  4.44it/s]Epoch 572\n",
            "Loss = 1.1551e-03, PNorm = 38.4899, GNorm = 0.0665, lr_0 = 2.6806e-04\n",
            "Validation rmse = 0.816284\n",
            " 57%|█████▋    | 573/1000 [02:10<01:36,  4.44it/s]Epoch 573\n",
            "Loss = 7.9609e-04, PNorm = 38.4906, GNorm = 0.0573, lr_0 = 2.6729e-04\n",
            "Validation rmse = 0.831222\n",
            " 57%|█████▋    | 574/1000 [02:10<01:35,  4.45it/s]Epoch 574\n",
            "Loss = 9.3162e-04, PNorm = 38.4916, GNorm = 0.2081, lr_0 = 2.6652e-04\n",
            "Validation rmse = 0.826835\n",
            " 57%|█████▊    | 575/1000 [02:10<01:35,  4.45it/s]Epoch 575\n",
            "Validation rmse = 0.818694\n",
            " 58%|█████▊    | 576/1000 [02:11<01:35,  4.46it/s]Epoch 576\n",
            "Loss = 5.7925e-04, PNorm = 38.4931, GNorm = 0.1110, lr_0 = 2.6575e-04\n",
            "Validation rmse = 0.829178\n",
            " 58%|█████▊    | 577/1000 [02:11<01:34,  4.46it/s]Epoch 577\n",
            "Loss = 1.2595e-03, PNorm = 38.4949, GNorm = 0.2389, lr_0 = 2.6499e-04\n",
            "Validation rmse = 0.823698\n",
            " 58%|█████▊    | 578/1000 [02:11<01:34,  4.46it/s]Epoch 578\n",
            "Loss = 8.3122e-04, PNorm = 38.4971, GNorm = 0.1492, lr_0 = 2.6422e-04\n",
            "Validation rmse = 0.818834\n",
            " 58%|█████▊    | 579/1000 [02:11<01:34,  4.45it/s]Epoch 579\n",
            "Loss = 1.0269e-03, PNorm = 38.4990, GNorm = 0.0598, lr_0 = 2.6346e-04\n",
            "Validation rmse = 0.812706\n",
            " 58%|█████▊    | 580/1000 [02:12<01:34,  4.46it/s]Epoch 580\n",
            "Validation rmse = 0.816738\n",
            " 58%|█████▊    | 581/1000 [02:12<01:33,  4.46it/s]Epoch 581\n",
            "Loss = 1.1955e-03, PNorm = 38.5011, GNorm = 0.1152, lr_0 = 2.6270e-04\n",
            "Validation rmse = 0.834121\n",
            " 58%|█████▊    | 582/1000 [02:12<01:33,  4.46it/s]Epoch 582\n",
            "Loss = 6.5841e-04, PNorm = 38.5023, GNorm = 0.1150, lr_0 = 2.6195e-04\n",
            "Validation rmse = 0.820096\n",
            " 58%|█████▊    | 583/1000 [02:12<01:33,  4.46it/s]Epoch 583\n",
            "Loss = 7.0875e-04, PNorm = 38.5042, GNorm = 0.2001, lr_0 = 2.6119e-04\n",
            "Validation rmse = 0.816972\n",
            " 58%|█████▊    | 584/1000 [02:12<01:33,  4.45it/s]Epoch 584\n",
            "Loss = 1.0585e-03, PNorm = 38.5066, GNorm = 0.1640, lr_0 = 2.6044e-04\n",
            "Validation rmse = 0.826438\n",
            " 58%|█████▊    | 585/1000 [02:13<01:33,  4.45it/s]Epoch 585\n",
            "Validation rmse = 0.828094\n",
            " 59%|█████▊    | 586/1000 [02:13<01:32,  4.46it/s]Epoch 586\n",
            "Loss = 5.0551e-04, PNorm = 38.5090, GNorm = 0.2109, lr_0 = 2.5969e-04\n",
            "Validation rmse = 0.820968\n",
            " 59%|█████▊    | 587/1000 [02:13<01:32,  4.45it/s]Epoch 587\n",
            "Loss = 8.9050e-04, PNorm = 38.5112, GNorm = 0.3260, lr_0 = 2.5894e-04\n",
            "Validation rmse = 0.816291\n",
            " 59%|█████▉    | 588/1000 [02:13<01:32,  4.45it/s]Epoch 588\n",
            "Loss = 1.1706e-03, PNorm = 38.5127, GNorm = 0.4373, lr_0 = 2.5820e-04\n",
            "Validation rmse = 0.831905\n",
            " 59%|█████▉    | 589/1000 [02:14<01:32,  4.45it/s]Epoch 589\n",
            "Loss = 1.5194e-03, PNorm = 38.5148, GNorm = 0.4567, lr_0 = 2.5745e-04\n",
            "Validation rmse = 0.822465\n",
            " 59%|█████▉    | 590/1000 [02:14<01:32,  4.45it/s]Epoch 590\n",
            "Validation rmse = 0.818112\n",
            " 59%|█████▉    | 591/1000 [02:14<01:31,  4.47it/s]Epoch 591\n",
            "Loss = 1.4545e-03, PNorm = 38.5174, GNorm = 0.6354, lr_0 = 2.5671e-04\n",
            "Validation rmse = 0.841348\n",
            " 59%|█████▉    | 592/1000 [02:14<01:31,  4.46it/s]Epoch 592\n",
            "Loss = 1.4381e-03, PNorm = 38.5194, GNorm = 0.4859, lr_0 = 2.5597e-04\n",
            "Validation rmse = 0.807666\n",
            " 59%|█████▉    | 593/1000 [02:14<01:31,  4.46it/s]Epoch 593\n",
            "Loss = 1.5039e-03, PNorm = 38.5220, GNorm = 0.3730, lr_0 = 2.5523e-04\n",
            "Validation rmse = 0.844392\n",
            " 59%|█████▉    | 594/1000 [02:15<01:31,  4.46it/s]Epoch 594\n",
            "Loss = 1.6630e-03, PNorm = 38.5249, GNorm = 0.4930, lr_0 = 2.5450e-04\n",
            "Validation rmse = 0.833338\n",
            " 60%|█████▉    | 595/1000 [02:15<01:30,  4.46it/s]Epoch 595\n",
            "Validation rmse = 0.824036\n",
            " 60%|█████▉    | 596/1000 [02:15<01:30,  4.46it/s]Epoch 596\n",
            "Loss = 8.3320e-04, PNorm = 38.5272, GNorm = 0.2492, lr_0 = 2.5377e-04\n",
            "Validation rmse = 0.822303\n",
            " 60%|█████▉    | 597/1000 [02:15<01:30,  4.46it/s]Epoch 597\n",
            "Loss = 9.5507e-04, PNorm = 38.5297, GNorm = 0.1325, lr_0 = 2.5304e-04\n",
            "Validation rmse = 0.825873\n",
            " 60%|█████▉    | 598/1000 [02:16<01:30,  4.46it/s]Epoch 598\n",
            "Loss = 1.0660e-03, PNorm = 38.5315, GNorm = 0.1238, lr_0 = 2.5231e-04\n",
            "Validation rmse = 0.815406\n",
            " 60%|█████▉    | 599/1000 [02:16<01:30,  4.45it/s]Epoch 599\n",
            "Loss = 1.3386e-03, PNorm = 38.5331, GNorm = 0.1074, lr_0 = 2.5158e-04\n",
            "Validation rmse = 0.835176\n",
            " 60%|██████    | 600/1000 [02:16<01:29,  4.45it/s]Epoch 600\n",
            "Validation rmse = 0.824636\n",
            " 60%|██████    | 601/1000 [02:16<01:29,  4.46it/s]Epoch 601\n",
            "Loss = 6.9944e-04, PNorm = 38.5354, GNorm = 0.1586, lr_0 = 2.5086e-04\n",
            "Validation rmse = 0.820365\n",
            " 60%|██████    | 602/1000 [02:16<01:29,  4.43it/s]Epoch 602\n",
            "Loss = 9.8437e-04, PNorm = 38.5365, GNorm = 0.2376, lr_0 = 2.5013e-04\n",
            "Validation rmse = 0.833750\n",
            " 60%|██████    | 603/1000 [02:17<01:29,  4.43it/s]Epoch 603\n",
            "Loss = 1.8104e-03, PNorm = 38.5392, GNorm = 0.5582, lr_0 = 2.4941e-04\n",
            "Validation rmse = 0.809727\n",
            " 60%|██████    | 604/1000 [02:17<01:29,  4.44it/s]Epoch 604\n",
            "Loss = 1.9673e-03, PNorm = 38.5431, GNorm = 0.5377, lr_0 = 2.4869e-04\n",
            "Validation rmse = 0.818217\n",
            " 60%|██████    | 605/1000 [02:17<01:28,  4.45it/s]Epoch 605\n",
            "Validation rmse = 0.824809\n",
            " 61%|██████    | 606/1000 [02:17<01:28,  4.45it/s]Epoch 606\n",
            "Loss = 1.9794e-03, PNorm = 38.5471, GNorm = 0.3098, lr_0 = 2.4798e-04\n",
            "Validation rmse = 0.812659\n",
            " 61%|██████    | 607/1000 [02:18<01:28,  4.45it/s]Epoch 607\n",
            "Loss = 1.6101e-03, PNorm = 38.5482, GNorm = 0.1341, lr_0 = 2.4726e-04\n",
            "Validation rmse = 0.821182\n",
            " 61%|██████    | 608/1000 [02:18<01:27,  4.46it/s]Epoch 608\n",
            "Loss = 1.1929e-03, PNorm = 38.5494, GNorm = 0.1399, lr_0 = 2.4655e-04\n",
            "Validation rmse = 0.823967\n",
            " 61%|██████    | 609/1000 [02:18<01:27,  4.46it/s]Epoch 609\n",
            "Loss = 9.4343e-04, PNorm = 38.5511, GNorm = 0.0885, lr_0 = 2.4584e-04\n",
            "Validation rmse = 0.830070\n",
            " 61%|██████    | 610/1000 [02:18<01:27,  4.45it/s]Epoch 610\n",
            "Validation rmse = 0.825921\n",
            " 61%|██████    | 611/1000 [02:18<01:27,  4.44it/s]Epoch 611\n",
            "Loss = 8.9644e-04, PNorm = 38.5531, GNorm = 0.1412, lr_0 = 2.4513e-04\n",
            "Validation rmse = 0.824070\n",
            " 61%|██████    | 612/1000 [02:19<01:27,  4.44it/s]Epoch 612\n",
            "Loss = 8.2872e-04, PNorm = 38.5539, GNorm = 0.1584, lr_0 = 2.4443e-04\n",
            "Validation rmse = 0.832303\n",
            " 61%|██████▏   | 613/1000 [02:19<01:27,  4.44it/s]Epoch 613\n",
            "Loss = 5.6301e-04, PNorm = 38.5556, GNorm = 0.0662, lr_0 = 2.4372e-04\n",
            "Validation rmse = 0.817968\n",
            " 61%|██████▏   | 614/1000 [02:19<01:26,  4.44it/s]Epoch 614\n",
            "Loss = 1.1254e-03, PNorm = 38.5578, GNorm = 0.2704, lr_0 = 2.4302e-04\n",
            "Validation rmse = 0.827496\n",
            " 62%|██████▏   | 615/1000 [02:19<01:26,  4.45it/s]Epoch 615\n",
            "Validation rmse = 0.817188\n",
            " 62%|██████▏   | 616/1000 [02:20<01:43,  3.70it/s]Epoch 616\n",
            "Loss = 2.1540e-04, PNorm = 38.5590, GNorm = 0.1747, lr_0 = 2.4232e-04\n",
            "Validation rmse = 0.823995\n",
            " 62%|██████▏   | 617/1000 [02:20<01:38,  3.89it/s]Epoch 617\n",
            "Loss = 8.6055e-04, PNorm = 38.5605, GNorm = 0.0730, lr_0 = 2.4162e-04\n",
            "Validation rmse = 0.818787\n",
            " 62%|██████▏   | 618/1000 [02:20<01:34,  4.04it/s]Epoch 618\n",
            "Loss = 1.0271e-03, PNorm = 38.5624, GNorm = 0.0923, lr_0 = 2.4093e-04\n",
            "Validation rmse = 0.826673\n",
            " 62%|██████▏   | 619/1000 [02:20<01:31,  4.15it/s]Epoch 619\n",
            "Loss = 7.4176e-04, PNorm = 38.5635, GNorm = 0.0703, lr_0 = 2.4023e-04\n",
            "Validation rmse = 0.826077\n",
            " 62%|██████▏   | 620/1000 [02:21<01:29,  4.23it/s]Epoch 620\n",
            "Validation rmse = 0.820879\n",
            " 62%|██████▏   | 621/1000 [02:21<01:28,  4.30it/s]Epoch 621\n",
            "Loss = 1.1598e-03, PNorm = 38.5650, GNorm = 0.1843, lr_0 = 2.3954e-04\n",
            "Validation rmse = 0.824048\n",
            " 62%|██████▏   | 622/1000 [02:21<01:26,  4.35it/s]Epoch 622\n",
            "Loss = 9.7575e-04, PNorm = 38.5661, GNorm = 0.1081, lr_0 = 2.3885e-04\n",
            "Validation rmse = 0.821448\n",
            " 62%|██████▏   | 623/1000 [02:21<01:26,  4.38it/s]Epoch 623\n",
            "Loss = 6.0592e-04, PNorm = 38.5679, GNorm = 0.2090, lr_0 = 2.3817e-04\n",
            "Validation rmse = 0.822525\n",
            " 62%|██████▏   | 624/1000 [02:22<01:25,  4.40it/s]Epoch 624\n",
            "Loss = 8.4693e-04, PNorm = 38.5692, GNorm = 0.1293, lr_0 = 2.3748e-04\n",
            "Validation rmse = 0.826283\n",
            " 62%|██████▎   | 625/1000 [02:22<01:24,  4.41it/s]Epoch 625\n",
            "Validation rmse = 0.826821\n",
            " 63%|██████▎   | 626/1000 [02:22<01:24,  4.44it/s]Epoch 626\n",
            "Loss = 1.3631e-03, PNorm = 38.5704, GNorm = 0.1400, lr_0 = 2.3680e-04\n",
            "Validation rmse = 0.824756\n",
            " 63%|██████▎   | 627/1000 [02:22<01:24,  4.44it/s]Epoch 627\n",
            "Loss = 1.0640e-03, PNorm = 38.5707, GNorm = 0.2085, lr_0 = 2.3611e-04\n",
            "Validation rmse = 0.820068\n",
            " 63%|██████▎   | 628/1000 [02:22<01:23,  4.43it/s]Epoch 628\n",
            "Loss = 8.2286e-04, PNorm = 38.5719, GNorm = 0.1400, lr_0 = 2.3543e-04\n",
            "Validation rmse = 0.828649\n",
            " 63%|██████▎   | 629/1000 [02:23<01:23,  4.43it/s]Epoch 629\n",
            "Loss = 8.4050e-04, PNorm = 38.5737, GNorm = 0.1960, lr_0 = 2.3476e-04\n",
            "Validation rmse = 0.822665\n",
            " 63%|██████▎   | 630/1000 [02:23<01:23,  4.44it/s]Epoch 630\n",
            "Validation rmse = 0.821646\n",
            " 63%|██████▎   | 631/1000 [02:23<01:22,  4.45it/s]Epoch 631\n",
            "Loss = 1.1300e-03, PNorm = 38.5753, GNorm = 0.0943, lr_0 = 2.3408e-04\n",
            "Validation rmse = 0.826142\n",
            " 63%|██████▎   | 632/1000 [02:23<01:22,  4.45it/s]Epoch 632\n",
            "Loss = 3.6565e-04, PNorm = 38.5769, GNorm = 0.1403, lr_0 = 2.3341e-04\n",
            "Validation rmse = 0.815330\n",
            " 63%|██████▎   | 633/1000 [02:24<01:22,  4.45it/s]Epoch 633\n",
            "Loss = 1.0938e-03, PNorm = 38.5784, GNorm = 0.0906, lr_0 = 2.3273e-04\n",
            "Validation rmse = 0.828582\n",
            " 63%|██████▎   | 634/1000 [02:24<01:22,  4.45it/s]Epoch 634\n",
            "Loss = 8.2089e-04, PNorm = 38.5796, GNorm = 0.0902, lr_0 = 2.3206e-04\n",
            "Validation rmse = 0.827601\n",
            " 64%|██████▎   | 635/1000 [02:24<01:21,  4.45it/s]Epoch 635\n",
            "Validation rmse = 0.824423\n",
            " 64%|██████▎   | 636/1000 [02:24<01:21,  4.46it/s]Epoch 636\n",
            "Loss = 1.2124e-03, PNorm = 38.5814, GNorm = 0.1674, lr_0 = 2.3139e-04\n",
            "Validation rmse = 0.821447\n",
            " 64%|██████▎   | 637/1000 [02:24<01:21,  4.46it/s]Epoch 637\n",
            "Loss = 6.5823e-04, PNorm = 38.5828, GNorm = 0.0841, lr_0 = 2.3073e-04\n",
            "Validation rmse = 0.827037\n",
            " 64%|██████▍   | 638/1000 [02:25<01:21,  4.46it/s]Epoch 638\n",
            "Loss = 6.8113e-04, PNorm = 38.5834, GNorm = 0.0881, lr_0 = 2.3006e-04\n",
            "Validation rmse = 0.835483\n",
            " 64%|██████▍   | 639/1000 [02:25<01:21,  4.43it/s]Epoch 639\n",
            "Loss = 9.7007e-04, PNorm = 38.5849, GNorm = 0.3198, lr_0 = 2.2940e-04\n",
            "Validation rmse = 0.819215\n",
            " 64%|██████▍   | 640/1000 [02:25<01:21,  4.44it/s]Epoch 640\n",
            "Validation rmse = 0.828246\n",
            " 64%|██████▍   | 641/1000 [02:25<01:20,  4.45it/s]Epoch 641\n",
            "Loss = 3.4358e-04, PNorm = 38.5864, GNorm = 0.1702, lr_0 = 2.2874e-04\n",
            "Validation rmse = 0.821203\n",
            " 64%|██████▍   | 642/1000 [02:26<01:20,  4.45it/s]Epoch 642\n",
            "Loss = 8.1953e-04, PNorm = 38.5885, GNorm = 0.1744, lr_0 = 2.2808e-04\n",
            "Validation rmse = 0.822837\n",
            " 64%|██████▍   | 643/1000 [02:26<01:20,  4.45it/s]Epoch 643\n",
            "Loss = 8.9132e-04, PNorm = 38.5908, GNorm = 0.1327, lr_0 = 2.2743e-04\n",
            "Validation rmse = 0.828728\n",
            " 64%|██████▍   | 644/1000 [02:26<01:19,  4.45it/s]Epoch 644\n",
            "Loss = 8.5874e-04, PNorm = 38.5926, GNorm = 0.1161, lr_0 = 2.2677e-04\n",
            "Validation rmse = 0.824748\n",
            " 64%|██████▍   | 645/1000 [02:26<01:19,  4.45it/s]Epoch 645\n",
            "Validation rmse = 0.824338\n",
            " 65%|██████▍   | 646/1000 [02:27<01:19,  4.46it/s]Epoch 646\n",
            "Loss = 9.7302e-04, PNorm = 38.5929, GNorm = 0.1575, lr_0 = 2.2612e-04\n",
            "Validation rmse = 0.837727\n",
            " 65%|██████▍   | 647/1000 [02:27<01:19,  4.46it/s]Epoch 647\n",
            "Loss = 4.2329e-04, PNorm = 38.5941, GNorm = 0.1478, lr_0 = 2.2547e-04\n",
            "Validation rmse = 0.827616\n",
            " 65%|██████▍   | 648/1000 [02:27<01:18,  4.46it/s]Epoch 648\n",
            "Loss = 7.8153e-04, PNorm = 38.5957, GNorm = 0.2083, lr_0 = 2.2482e-04\n",
            "Validation rmse = 0.823610\n",
            " 65%|██████▍   | 649/1000 [02:27<01:18,  4.46it/s]Epoch 649\n",
            "Loss = 7.5044e-04, PNorm = 38.5972, GNorm = 0.0512, lr_0 = 2.2417e-04\n",
            "Validation rmse = 0.825840\n",
            " 65%|██████▌   | 650/1000 [02:27<01:19,  4.43it/s]Epoch 650\n",
            "Validation rmse = 0.822028\n",
            " 65%|██████▌   | 651/1000 [02:28<01:18,  4.43it/s]Epoch 651\n",
            "Loss = 2.1358e-04, PNorm = 38.5983, GNorm = 0.0368, lr_0 = 2.2352e-04\n",
            "Validation rmse = 0.831848\n",
            " 65%|██████▌   | 652/1000 [02:28<01:18,  4.42it/s]Epoch 652\n",
            "Loss = 9.1169e-04, PNorm = 38.5999, GNorm = 0.1738, lr_0 = 2.2288e-04\n",
            "Validation rmse = 0.826104\n",
            " 65%|██████▌   | 653/1000 [02:28<01:18,  4.43it/s]Epoch 653\n",
            "Loss = 5.4069e-04, PNorm = 38.6012, GNorm = 0.2403, lr_0 = 2.2224e-04\n",
            "Validation rmse = 0.823479\n",
            " 65%|██████▌   | 654/1000 [02:28<01:17,  4.44it/s]Epoch 654\n",
            "Loss = 7.8017e-04, PNorm = 38.6021, GNorm = 0.2561, lr_0 = 2.2160e-04\n",
            "Validation rmse = 0.838200\n",
            " 66%|██████▌   | 655/1000 [02:29<01:17,  4.44it/s]Epoch 655\n",
            "Validation rmse = 0.823467\n",
            " 66%|██████▌   | 656/1000 [02:29<01:17,  4.45it/s]Epoch 656\n",
            "Loss = 4.7608e-04, PNorm = 38.6029, GNorm = 0.3402, lr_0 = 2.2096e-04\n",
            "Validation rmse = 0.824594\n",
            " 66%|██████▌   | 657/1000 [02:29<01:17,  4.45it/s]Epoch 657\n",
            "Loss = 7.1449e-04, PNorm = 38.6040, GNorm = 0.0924, lr_0 = 2.2032e-04\n",
            "Validation rmse = 0.825819\n",
            " 66%|██████▌   | 658/1000 [02:29<01:16,  4.45it/s]Epoch 658\n",
            "Loss = 7.2463e-04, PNorm = 38.6045, GNorm = 0.2307, lr_0 = 2.1969e-04\n",
            "Validation rmse = 0.828171\n",
            " 66%|██████▌   | 659/1000 [02:29<01:16,  4.45it/s]Epoch 659\n",
            "Loss = 6.1193e-04, PNorm = 38.6055, GNorm = 0.0721, lr_0 = 2.1906e-04\n",
            "Validation rmse = 0.826634\n",
            " 66%|██████▌   | 660/1000 [02:30<01:16,  4.45it/s]Epoch 660\n",
            "Validation rmse = 0.824665\n",
            " 66%|██████▌   | 661/1000 [02:30<01:15,  4.46it/s]Epoch 661\n",
            "Loss = 3.6052e-04, PNorm = 38.6069, GNorm = 0.1513, lr_0 = 2.1843e-04\n",
            "Validation rmse = 0.824546\n",
            " 66%|██████▌   | 662/1000 [02:30<01:15,  4.46it/s]Epoch 662\n",
            "Loss = 5.8518e-04, PNorm = 38.6080, GNorm = 0.0994, lr_0 = 2.1780e-04\n",
            "Validation rmse = 0.833974\n",
            " 66%|██████▋   | 663/1000 [02:30<01:15,  4.46it/s]Epoch 663\n",
            "Loss = 7.5664e-04, PNorm = 38.6096, GNorm = 0.1512, lr_0 = 2.1717e-04\n",
            "Validation rmse = 0.830586\n",
            " 66%|██████▋   | 664/1000 [02:31<01:15,  4.46it/s]Epoch 664\n",
            "Loss = 6.7011e-04, PNorm = 38.6106, GNorm = 0.1050, lr_0 = 2.1654e-04\n",
            "Validation rmse = 0.827072\n",
            " 66%|██████▋   | 665/1000 [02:31<01:15,  4.45it/s]Epoch 665\n",
            "Validation rmse = 0.833819\n",
            " 67%|██████▋   | 666/1000 [02:31<01:14,  4.46it/s]Epoch 666\n",
            "Loss = 1.0751e-03, PNorm = 38.6116, GNorm = 0.0664, lr_0 = 2.1592e-04\n",
            "Validation rmse = 0.832477\n",
            " 67%|██████▋   | 667/1000 [02:31<01:14,  4.46it/s]Epoch 667\n",
            "Loss = 1.2215e-03, PNorm = 38.6126, GNorm = 0.3692, lr_0 = 2.1530e-04\n",
            "Validation rmse = 0.825938\n",
            " 67%|██████▋   | 668/1000 [02:31<01:14,  4.45it/s]Epoch 668\n",
            "Loss = 6.7841e-04, PNorm = 38.6139, GNorm = 0.1861, lr_0 = 2.1468e-04\n",
            "Validation rmse = 0.829428\n",
            " 67%|██████▋   | 669/1000 [02:32<01:14,  4.45it/s]Epoch 669\n",
            "Loss = 8.5291e-04, PNorm = 38.6159, GNorm = 0.2217, lr_0 = 2.1406e-04\n",
            "Validation rmse = 0.829413\n",
            " 67%|██████▋   | 670/1000 [02:32<01:14,  4.45it/s]Epoch 670\n",
            "Validation rmse = 0.816258\n",
            " 67%|██████▋   | 671/1000 [02:32<01:13,  4.46it/s]Epoch 671\n",
            "Loss = 8.4281e-04, PNorm = 38.6170, GNorm = 0.0633, lr_0 = 2.1344e-04\n",
            "Validation rmse = 0.831510\n",
            " 67%|██████▋   | 672/1000 [02:32<01:13,  4.46it/s]Epoch 672\n",
            "Loss = 7.9133e-04, PNorm = 38.6187, GNorm = 0.2113, lr_0 = 2.1283e-04\n",
            "Validation rmse = 0.829265\n",
            " 67%|██████▋   | 673/1000 [02:33<01:13,  4.45it/s]Epoch 673\n",
            "Loss = 8.1965e-04, PNorm = 38.6204, GNorm = 0.1620, lr_0 = 2.1222e-04\n",
            "Validation rmse = 0.820344\n",
            " 67%|██████▋   | 674/1000 [02:33<01:13,  4.45it/s]Epoch 674\n",
            "Loss = 7.3039e-04, PNorm = 38.6220, GNorm = 0.0863, lr_0 = 2.1161e-04\n",
            "Validation rmse = 0.830317\n",
            " 68%|██████▊   | 675/1000 [02:33<01:13,  4.43it/s]Epoch 675\n",
            "Validation rmse = 0.827195\n",
            " 68%|██████▊   | 676/1000 [02:33<01:12,  4.45it/s]Epoch 676\n",
            "Loss = 9.3600e-04, PNorm = 38.6232, GNorm = 0.1017, lr_0 = 2.1100e-04\n",
            "Validation rmse = 0.820605\n",
            " 68%|██████▊   | 677/1000 [02:33<01:12,  4.45it/s]Epoch 677\n",
            "Loss = 6.9083e-04, PNorm = 38.6242, GNorm = 0.0530, lr_0 = 2.1039e-04\n",
            "Validation rmse = 0.831438\n",
            " 68%|██████▊   | 678/1000 [02:34<01:12,  4.45it/s]Epoch 678\n",
            "Loss = 8.6504e-04, PNorm = 38.6253, GNorm = 0.0608, lr_0 = 2.0978e-04\n",
            "Validation rmse = 0.823815\n",
            " 68%|██████▊   | 679/1000 [02:34<01:12,  4.44it/s]Epoch 679\n",
            "Loss = 6.7053e-04, PNorm = 38.6270, GNorm = 0.1716, lr_0 = 2.0918e-04\n",
            "Validation rmse = 0.827361\n",
            " 68%|██████▊   | 680/1000 [02:34<01:11,  4.45it/s]Epoch 680\n",
            "Validation rmse = 0.824776\n",
            " 68%|██████▊   | 681/1000 [02:34<01:11,  4.46it/s]Epoch 681\n",
            "Loss = 1.0168e-03, PNorm = 38.6273, GNorm = 0.0827, lr_0 = 2.0858e-04\n",
            "Validation rmse = 0.829818\n",
            " 68%|██████▊   | 682/1000 [02:35<01:11,  4.46it/s]Epoch 682\n",
            "Loss = 9.2246e-04, PNorm = 38.6283, GNorm = 0.1218, lr_0 = 2.0797e-04\n",
            "Validation rmse = 0.825496\n",
            " 68%|██████▊   | 683/1000 [02:35<01:11,  4.46it/s]Epoch 683\n",
            "Loss = 3.2339e-04, PNorm = 38.6297, GNorm = 0.1265, lr_0 = 2.0738e-04\n",
            "Validation rmse = 0.831152\n",
            " 68%|██████▊   | 684/1000 [02:35<01:10,  4.46it/s]Epoch 684\n",
            "Loss = 6.0806e-04, PNorm = 38.6307, GNorm = 0.1038, lr_0 = 2.0678e-04\n",
            "Validation rmse = 0.829187\n",
            " 68%|██████▊   | 685/1000 [02:35<01:10,  4.45it/s]Epoch 685\n",
            "Validation rmse = 0.825252\n",
            " 69%|██████▊   | 686/1000 [02:36<01:10,  4.46it/s]Epoch 686\n",
            "Loss = 9.7144e-04, PNorm = 38.6314, GNorm = 0.0646, lr_0 = 2.0618e-04\n",
            "Validation rmse = 0.829881\n",
            " 69%|██████▊   | 687/1000 [02:36<01:10,  4.45it/s]Epoch 687\n",
            "Loss = 1.6120e-04, PNorm = 38.6326, GNorm = 0.0492, lr_0 = 2.0559e-04\n",
            "Validation rmse = 0.832041\n",
            " 69%|██████▉   | 688/1000 [02:36<01:10,  4.44it/s]Epoch 688\n",
            "Loss = 5.7499e-04, PNorm = 38.6335, GNorm = 0.1250, lr_0 = 2.0500e-04\n",
            "Validation rmse = 0.825548\n",
            " 69%|██████▉   | 689/1000 [02:36<01:09,  4.44it/s]Epoch 689\n",
            "Loss = 5.7607e-04, PNorm = 38.6347, GNorm = 0.0841, lr_0 = 2.0441e-04\n",
            "Validation rmse = 0.827564\n",
            " 69%|██████▉   | 690/1000 [02:36<01:09,  4.44it/s]Epoch 690\n",
            "Validation rmse = 0.822642\n",
            " 69%|██████▉   | 691/1000 [02:37<01:09,  4.45it/s]Epoch 691\n",
            "Loss = 3.2570e-04, PNorm = 38.6362, GNorm = 0.0883, lr_0 = 2.0382e-04\n",
            "Validation rmse = 0.829923\n",
            " 69%|██████▉   | 692/1000 [02:37<01:09,  4.45it/s]Epoch 692\n",
            "Loss = 2.9361e-04, PNorm = 38.6371, GNorm = 0.0472, lr_0 = 2.0323e-04\n",
            "Validation rmse = 0.827541\n",
            " 69%|██████▉   | 693/1000 [02:37<01:08,  4.45it/s]Epoch 693\n",
            "Loss = 9.0645e-04, PNorm = 38.6380, GNorm = 0.0391, lr_0 = 2.0265e-04\n",
            "Validation rmse = 0.827283\n",
            " 69%|██████▉   | 694/1000 [02:37<01:08,  4.45it/s]Epoch 694\n",
            "Loss = 7.7609e-04, PNorm = 38.6388, GNorm = 0.1160, lr_0 = 2.0206e-04\n",
            "Validation rmse = 0.837137\n",
            " 70%|██████▉   | 695/1000 [02:38<01:08,  4.45it/s]Epoch 695\n",
            "Validation rmse = 0.822902\n",
            " 70%|██████▉   | 696/1000 [02:38<01:08,  4.46it/s]Epoch 696\n",
            "Loss = 1.5796e-03, PNorm = 38.6399, GNorm = 0.1284, lr_0 = 2.0148e-04\n",
            "Validation rmse = 0.827385\n",
            " 70%|██████▉   | 697/1000 [02:38<01:07,  4.46it/s]Epoch 697\n",
            "Loss = 5.8286e-04, PNorm = 38.6415, GNorm = 0.0434, lr_0 = 2.0090e-04\n",
            "Validation rmse = 0.827681\n",
            " 70%|██████▉   | 698/1000 [02:38<01:07,  4.45it/s]Epoch 698\n",
            "Loss = 4.9311e-04, PNorm = 38.6423, GNorm = 0.0535, lr_0 = 2.0032e-04\n",
            "Validation rmse = 0.820975\n",
            " 70%|██████▉   | 699/1000 [02:38<01:07,  4.45it/s]Epoch 699\n",
            "Loss = 8.2856e-04, PNorm = 38.6431, GNorm = 0.0594, lr_0 = 1.9975e-04\n",
            "Validation rmse = 0.826831\n",
            " 70%|███████   | 700/1000 [02:39<01:07,  4.45it/s]Epoch 700\n",
            "Validation rmse = 0.827342\n",
            " 70%|███████   | 701/1000 [02:39<01:07,  4.46it/s]Epoch 701\n",
            "Loss = 7.7012e-04, PNorm = 38.6447, GNorm = 0.2251, lr_0 = 1.9917e-04\n",
            "Validation rmse = 0.828750\n",
            " 70%|███████   | 702/1000 [02:39<01:06,  4.46it/s]Epoch 702\n",
            "Loss = 5.1035e-04, PNorm = 38.6458, GNorm = 0.0899, lr_0 = 1.9860e-04\n",
            "Validation rmse = 0.827232\n",
            " 70%|███████   | 703/1000 [02:39<01:06,  4.46it/s]Epoch 703\n",
            "Loss = 5.2799e-04, PNorm = 38.6468, GNorm = 0.0897, lr_0 = 1.9802e-04\n",
            "Validation rmse = 0.825193\n",
            " 70%|███████   | 704/1000 [02:40<01:06,  4.45it/s]Epoch 704\n",
            "Loss = 6.6369e-04, PNorm = 38.6484, GNorm = 0.1718, lr_0 = 1.9745e-04\n",
            "Validation rmse = 0.824304\n",
            " 70%|███████   | 705/1000 [02:40<01:06,  4.45it/s]Epoch 705\n",
            "Validation rmse = 0.825013\n",
            " 71%|███████   | 706/1000 [02:40<01:05,  4.46it/s]Epoch 706\n",
            "Loss = 1.0061e-03, PNorm = 38.6494, GNorm = 0.2262, lr_0 = 1.9689e-04\n",
            "Validation rmse = 0.833367\n",
            " 71%|███████   | 707/1000 [02:40<01:05,  4.46it/s]Epoch 707\n",
            "Loss = 4.4172e-04, PNorm = 38.6510, GNorm = 0.1962, lr_0 = 1.9632e-04\n",
            "Validation rmse = 0.823110\n",
            " 71%|███████   | 708/1000 [02:40<01:05,  4.46it/s]Epoch 708\n",
            "Loss = 1.0016e-03, PNorm = 38.6526, GNorm = 0.2628, lr_0 = 1.9575e-04\n",
            "Validation rmse = 0.829228\n",
            " 71%|███████   | 709/1000 [02:41<01:05,  4.46it/s]Epoch 709\n",
            "Loss = 8.1091e-04, PNorm = 38.6537, GNorm = 0.1906, lr_0 = 1.9519e-04\n",
            "Validation rmse = 0.826285\n",
            " 71%|███████   | 710/1000 [02:41<01:05,  4.46it/s]Epoch 710\n",
            "Validation rmse = 0.810972\n",
            " 71%|███████   | 711/1000 [02:41<01:04,  4.46it/s]Epoch 711\n",
            "Loss = 7.2811e-04, PNorm = 38.6548, GNorm = 0.2180, lr_0 = 1.9463e-04\n",
            "Validation rmse = 0.843967\n",
            " 71%|███████   | 712/1000 [02:41<01:04,  4.46it/s]Epoch 712\n",
            "Loss = 1.0485e-03, PNorm = 38.6562, GNorm = 0.2593, lr_0 = 1.9407e-04\n",
            "Validation rmse = 0.814900\n",
            " 71%|███████▏  | 713/1000 [02:42<01:04,  4.45it/s]Epoch 713\n",
            "Loss = 1.0226e-03, PNorm = 38.6575, GNorm = 0.1010, lr_0 = 1.9351e-04\n",
            "Validation rmse = 0.823184\n",
            " 71%|███████▏  | 714/1000 [02:42<01:04,  4.45it/s]Epoch 714\n",
            "Loss = 1.1313e-03, PNorm = 38.6592, GNorm = 0.4608, lr_0 = 1.9295e-04\n",
            "Validation rmse = 0.826023\n",
            " 72%|███████▏  | 715/1000 [02:42<01:03,  4.45it/s]Epoch 715\n",
            "Validation rmse = 0.844044\n",
            " 72%|███████▏  | 716/1000 [02:42<01:03,  4.46it/s]Epoch 716\n",
            "Loss = 1.8821e-03, PNorm = 38.6609, GNorm = 0.4580, lr_0 = 1.9239e-04\n",
            "Validation rmse = 0.824251\n",
            " 72%|███████▏  | 717/1000 [02:42<01:03,  4.46it/s]Epoch 717\n",
            "Loss = 1.0185e-03, PNorm = 38.6630, GNorm = 0.1632, lr_0 = 1.9184e-04\n",
            "Validation rmse = 0.817147\n",
            " 72%|███████▏  | 718/1000 [02:43<01:15,  3.71it/s]Epoch 718\n",
            "Loss = 1.0343e-03, PNorm = 38.6656, GNorm = 0.1529, lr_0 = 1.9129e-04\n",
            "Validation rmse = 0.831499\n",
            " 72%|███████▏  | 719/1000 [02:43<01:11,  3.90it/s]Epoch 719\n",
            "Loss = 8.6098e-04, PNorm = 38.6662, GNorm = 0.1116, lr_0 = 1.9074e-04\n",
            "Validation rmse = 0.826461\n",
            " 72%|███████▏  | 720/1000 [02:43<01:09,  4.05it/s]Epoch 720\n",
            "Validation rmse = 0.830008\n",
            " 72%|███████▏  | 721/1000 [02:44<01:07,  4.16it/s]Epoch 721\n",
            "Loss = 1.6300e-03, PNorm = 38.6681, GNorm = 0.1209, lr_0 = 1.9019e-04\n",
            "Validation rmse = 0.832670\n",
            " 72%|███████▏  | 722/1000 [02:44<01:05,  4.25it/s]Epoch 722\n",
            "Loss = 8.8229e-04, PNorm = 38.6692, GNorm = 0.2079, lr_0 = 1.8964e-04\n",
            "Validation rmse = 0.816512\n",
            " 72%|███████▏  | 723/1000 [02:44<01:04,  4.31it/s]Epoch 723\n",
            "Loss = 4.1959e-04, PNorm = 38.6709, GNorm = 0.0924, lr_0 = 1.8909e-04\n",
            "Validation rmse = 0.826784\n",
            " 72%|███████▏  | 724/1000 [02:44<01:03,  4.35it/s]Epoch 724\n",
            "Loss = 6.5884e-04, PNorm = 38.6718, GNorm = 0.1428, lr_0 = 1.8855e-04\n",
            "Validation rmse = 0.827683\n",
            " 72%|███████▎  | 725/1000 [02:44<01:02,  4.39it/s]Epoch 725\n",
            "Validation rmse = 0.831708\n",
            " 73%|███████▎  | 726/1000 [02:45<01:02,  4.40it/s]Epoch 726\n",
            "Loss = 4.4098e-04, PNorm = 38.6722, GNorm = 0.2160, lr_0 = 1.8801e-04\n",
            "Validation rmse = 0.824698\n",
            " 73%|███████▎  | 727/1000 [02:45<01:01,  4.42it/s]Epoch 727\n",
            "Loss = 3.0077e-04, PNorm = 38.6738, GNorm = 0.1485, lr_0 = 1.8747e-04\n",
            "Validation rmse = 0.830532\n",
            " 73%|███████▎  | 728/1000 [02:45<01:01,  4.43it/s]Epoch 728\n",
            "Loss = 5.0605e-04, PNorm = 38.6747, GNorm = 0.0442, lr_0 = 1.8693e-04\n",
            "Validation rmse = 0.823947\n",
            " 73%|███████▎  | 729/1000 [02:45<01:01,  4.43it/s]Epoch 729\n",
            "Loss = 6.0754e-04, PNorm = 38.6758, GNorm = 0.1261, lr_0 = 1.8639e-04\n",
            "Validation rmse = 0.830044\n",
            " 73%|███████▎  | 730/1000 [02:46<01:00,  4.44it/s]Epoch 730\n",
            "Validation rmse = 0.831982\n",
            " 73%|███████▎  | 731/1000 [02:46<01:00,  4.45it/s]Epoch 731\n",
            "Loss = 9.1014e-04, PNorm = 38.6766, GNorm = 0.1693, lr_0 = 1.8585e-04\n",
            "Validation rmse = 0.821487\n",
            " 73%|███████▎  | 732/1000 [02:46<01:00,  4.45it/s]Epoch 732\n",
            "Loss = 1.1214e-03, PNorm = 38.6776, GNorm = 0.1289, lr_0 = 1.8532e-04\n",
            "Validation rmse = 0.831394\n",
            " 73%|███████▎  | 733/1000 [02:46<00:59,  4.45it/s]Epoch 733\n",
            "Loss = 6.2200e-04, PNorm = 38.6783, GNorm = 0.0696, lr_0 = 1.8478e-04\n",
            "Validation rmse = 0.824970\n",
            " 73%|███████▎  | 734/1000 [02:46<00:59,  4.45it/s]Epoch 734\n",
            "Loss = 7.4240e-04, PNorm = 38.6792, GNorm = 0.1886, lr_0 = 1.8425e-04\n",
            "Validation rmse = 0.832104\n",
            " 74%|███████▎  | 735/1000 [02:47<00:59,  4.45it/s]Epoch 735\n",
            "Validation rmse = 0.826534\n",
            " 74%|███████▎  | 736/1000 [02:47<00:59,  4.46it/s]Epoch 736\n",
            "Loss = 3.8413e-04, PNorm = 38.6797, GNorm = 0.2069, lr_0 = 1.8372e-04\n",
            "Validation rmse = 0.829302\n",
            " 74%|███████▎  | 737/1000 [02:47<00:59,  4.45it/s]Epoch 737\n",
            "Loss = 5.5214e-04, PNorm = 38.6806, GNorm = 0.0611, lr_0 = 1.8319e-04\n",
            "Validation rmse = 0.825543\n",
            " 74%|███████▍  | 738/1000 [02:47<00:58,  4.45it/s]Epoch 738\n",
            "Loss = 5.6058e-04, PNorm = 38.6814, GNorm = 0.1270, lr_0 = 1.8266e-04\n",
            "Validation rmse = 0.828097\n",
            " 74%|███████▍  | 739/1000 [02:48<00:58,  4.45it/s]Epoch 739\n",
            "Loss = 8.2995e-04, PNorm = 38.6830, GNorm = 0.2356, lr_0 = 1.8214e-04\n",
            "Validation rmse = 0.823813\n",
            " 74%|███████▍  | 740/1000 [02:48<00:58,  4.45it/s]Epoch 740\n",
            "Validation rmse = 0.823230\n",
            " 74%|███████▍  | 741/1000 [02:48<00:58,  4.46it/s]Epoch 741\n",
            "Loss = 3.4919e-04, PNorm = 38.6839, GNorm = 0.1024, lr_0 = 1.8161e-04\n",
            "Validation rmse = 0.830160\n",
            " 74%|███████▍  | 742/1000 [02:48<00:57,  4.45it/s]Epoch 742\n",
            "Loss = 2.4584e-04, PNorm = 38.6847, GNorm = 0.1159, lr_0 = 1.8109e-04\n",
            "Validation rmse = 0.826680\n",
            " 74%|███████▍  | 743/1000 [02:48<00:57,  4.45it/s]Epoch 743\n",
            "Loss = 4.2301e-04, PNorm = 38.6859, GNorm = 0.0703, lr_0 = 1.8057e-04\n",
            "Validation rmse = 0.833751\n",
            " 74%|███████▍  | 744/1000 [02:49<00:57,  4.45it/s]Epoch 744\n",
            "Loss = 6.7154e-04, PNorm = 38.6869, GNorm = 0.1038, lr_0 = 1.8005e-04\n",
            "Validation rmse = 0.838196\n",
            " 74%|███████▍  | 745/1000 [02:49<00:57,  4.45it/s]Epoch 745\n",
            "Validation rmse = 0.827972\n",
            " 75%|███████▍  | 746/1000 [02:49<00:56,  4.46it/s]Epoch 746\n",
            "Loss = 1.6107e-03, PNorm = 38.6884, GNorm = 0.1223, lr_0 = 1.7953e-04\n",
            "Validation rmse = 0.826900\n",
            " 75%|███████▍  | 747/1000 [02:49<00:56,  4.46it/s]Epoch 747\n",
            "Loss = 4.4901e-04, PNorm = 38.6891, GNorm = 0.0937, lr_0 = 1.7901e-04\n",
            "Validation rmse = 0.828974\n",
            " 75%|███████▍  | 748/1000 [02:50<00:56,  4.44it/s]Epoch 748\n",
            "Loss = 4.3927e-04, PNorm = 38.6902, GNorm = 0.1561, lr_0 = 1.7850e-04\n",
            "Validation rmse = 0.824839\n",
            " 75%|███████▍  | 749/1000 [02:50<00:56,  4.44it/s]Epoch 749\n",
            "Loss = 6.6354e-04, PNorm = 38.6917, GNorm = 0.1584, lr_0 = 1.7798e-04\n",
            "Validation rmse = 0.828096\n",
            " 75%|███████▌  | 750/1000 [02:50<00:56,  4.44it/s]Epoch 750\n",
            "Validation rmse = 0.823808\n",
            " 75%|███████▌  | 751/1000 [02:50<00:55,  4.46it/s]Epoch 751\n",
            "Loss = 1.5137e-04, PNorm = 38.6921, GNorm = 0.0679, lr_0 = 1.7747e-04\n",
            "Validation rmse = 0.836453\n",
            " 75%|███████▌  | 752/1000 [02:50<00:55,  4.45it/s]Epoch 752\n",
            "Loss = 6.2942e-04, PNorm = 38.6930, GNorm = 0.1571, lr_0 = 1.7696e-04\n",
            "Validation rmse = 0.825048\n",
            " 75%|███████▌  | 753/1000 [02:51<00:55,  4.45it/s]Epoch 753\n",
            "Loss = 2.3868e-04, PNorm = 38.6937, GNorm = 0.0540, lr_0 = 1.7645e-04\n",
            "Validation rmse = 0.829806\n",
            " 75%|███████▌  | 754/1000 [02:51<00:55,  4.45it/s]Epoch 754\n",
            "Loss = 5.6699e-04, PNorm = 38.6944, GNorm = 0.0328, lr_0 = 1.7594e-04\n",
            "Validation rmse = 0.835958\n",
            " 76%|███████▌  | 755/1000 [02:51<00:55,  4.43it/s]Epoch 755\n",
            "Validation rmse = 0.817470\n",
            " 76%|███████▌  | 756/1000 [02:51<00:54,  4.45it/s]Epoch 756\n",
            "Loss = 5.8913e-04, PNorm = 38.6949, GNorm = 0.0947, lr_0 = 1.7543e-04\n",
            "Validation rmse = 0.834301\n",
            " 76%|███████▌  | 757/1000 [02:52<00:54,  4.45it/s]Epoch 757\n",
            "Loss = 1.0816e-03, PNorm = 38.6952, GNorm = 0.2089, lr_0 = 1.7493e-04\n",
            "Validation rmse = 0.834458\n",
            " 76%|███████▌  | 758/1000 [02:52<00:54,  4.45it/s]Epoch 758\n",
            "Loss = 6.8720e-04, PNorm = 38.6975, GNorm = 0.1320, lr_0 = 1.7442e-04\n",
            "Validation rmse = 0.822926\n",
            " 76%|███████▌  | 759/1000 [02:52<00:54,  4.45it/s]Epoch 759\n",
            "Loss = 8.2512e-04, PNorm = 38.6986, GNorm = 0.3573, lr_0 = 1.7392e-04\n",
            "Validation rmse = 0.829565\n",
            " 76%|███████▌  | 760/1000 [02:52<00:53,  4.45it/s]Epoch 760\n",
            "Validation rmse = 0.838129\n",
            " 76%|███████▌  | 761/1000 [02:52<00:53,  4.46it/s]Epoch 761\n",
            "Loss = 1.6941e-03, PNorm = 38.6996, GNorm = 0.2914, lr_0 = 1.7342e-04\n",
            "Validation rmse = 0.816885\n",
            " 76%|███████▌  | 762/1000 [02:53<00:53,  4.45it/s]Epoch 762\n",
            "Loss = 9.5847e-04, PNorm = 38.7007, GNorm = 0.0989, lr_0 = 1.7292e-04\n",
            "Validation rmse = 0.829872\n",
            " 76%|███████▋  | 763/1000 [02:53<00:53,  4.45it/s]Epoch 763\n",
            "Loss = 6.4794e-04, PNorm = 38.7010, GNorm = 0.1227, lr_0 = 1.7242e-04\n",
            "Validation rmse = 0.834028\n",
            " 76%|███████▋  | 764/1000 [02:53<00:53,  4.45it/s]Epoch 764\n",
            "Loss = 5.4976e-04, PNorm = 38.7021, GNorm = 0.1086, lr_0 = 1.7193e-04\n",
            "Validation rmse = 0.825380\n",
            " 76%|███████▋  | 765/1000 [02:53<00:52,  4.45it/s]Epoch 765\n",
            "Validation rmse = 0.828056\n",
            " 77%|███████▋  | 766/1000 [02:54<00:52,  4.45it/s]Epoch 766\n",
            "Loss = 1.4165e-03, PNorm = 38.7032, GNorm = 0.1678, lr_0 = 1.7143e-04\n",
            "Validation rmse = 0.843167\n",
            " 77%|███████▋  | 767/1000 [02:54<00:52,  4.45it/s]Epoch 767\n",
            "Loss = 8.6622e-04, PNorm = 38.7049, GNorm = 0.2646, lr_0 = 1.7094e-04\n",
            "Validation rmse = 0.818154\n",
            " 77%|███████▋  | 768/1000 [02:54<00:52,  4.45it/s]Epoch 768\n",
            "Loss = 5.9924e-04, PNorm = 38.7054, GNorm = 0.2158, lr_0 = 1.7045e-04\n",
            "Validation rmse = 0.839335\n",
            " 77%|███████▋  | 769/1000 [02:54<00:51,  4.45it/s]Epoch 769\n",
            "Loss = 9.9791e-04, PNorm = 38.7064, GNorm = 0.2545, lr_0 = 1.6996e-04\n",
            "Validation rmse = 0.839927\n",
            " 77%|███████▋  | 770/1000 [02:55<00:51,  4.45it/s]Epoch 770\n",
            "Validation rmse = 0.824313\n",
            " 77%|███████▋  | 771/1000 [02:55<00:51,  4.46it/s]Epoch 771\n",
            "Loss = 3.8326e-04, PNorm = 38.7078, GNorm = 0.0656, lr_0 = 1.6947e-04\n",
            "Validation rmse = 0.829651\n",
            " 77%|███████▋  | 772/1000 [02:55<00:51,  4.46it/s]Epoch 772\n",
            "Loss = 6.1496e-04, PNorm = 38.7083, GNorm = 0.1079, lr_0 = 1.6898e-04\n",
            "Validation rmse = 0.826430\n",
            " 77%|███████▋  | 773/1000 [02:55<00:50,  4.45it/s]Epoch 773\n",
            "Loss = 7.5845e-04, PNorm = 38.7094, GNorm = 0.0741, lr_0 = 1.6849e-04\n",
            "Validation rmse = 0.827856\n",
            " 77%|███████▋  | 774/1000 [02:55<00:50,  4.45it/s]Epoch 774\n",
            "Loss = 6.1443e-04, PNorm = 38.7100, GNorm = 0.0947, lr_0 = 1.6801e-04\n",
            "Validation rmse = 0.832127\n",
            " 78%|███████▊  | 775/1000 [02:56<00:50,  4.45it/s]Epoch 775\n",
            "Validation rmse = 0.829236\n",
            " 78%|███████▊  | 776/1000 [02:56<00:50,  4.44it/s]Epoch 776\n",
            "Loss = 2.3799e-04, PNorm = 38.7106, GNorm = 0.0572, lr_0 = 1.6752e-04\n",
            "Validation rmse = 0.821771\n",
            " 78%|███████▊  | 777/1000 [02:56<00:50,  4.44it/s]Epoch 777\n",
            "Loss = 4.0789e-04, PNorm = 38.7114, GNorm = 0.2571, lr_0 = 1.6704e-04\n",
            "Validation rmse = 0.837433\n",
            " 78%|███████▊  | 778/1000 [02:56<00:50,  4.44it/s]Epoch 778\n",
            "Loss = 9.5213e-04, PNorm = 38.7126, GNorm = 0.1362, lr_0 = 1.6656e-04\n",
            "Validation rmse = 0.823816\n",
            " 78%|███████▊  | 779/1000 [02:57<00:49,  4.44it/s]Epoch 779\n",
            "Loss = 6.5448e-04, PNorm = 38.7134, GNorm = 0.1979, lr_0 = 1.6608e-04\n",
            "Validation rmse = 0.826571\n",
            " 78%|███████▊  | 780/1000 [02:57<00:49,  4.44it/s]Epoch 780\n",
            "Validation rmse = 0.839106\n",
            " 78%|███████▊  | 781/1000 [02:57<00:49,  4.46it/s]Epoch 781\n",
            "Loss = 3.9090e-04, PNorm = 38.7144, GNorm = 0.0854, lr_0 = 1.6560e-04\n",
            "Validation rmse = 0.820341\n",
            " 78%|███████▊  | 782/1000 [02:57<00:50,  4.29it/s]Epoch 782\n",
            "Loss = 8.7538e-04, PNorm = 38.7162, GNorm = 0.0978, lr_0 = 1.6512e-04\n",
            "Validation rmse = 0.823351\n",
            " 78%|███████▊  | 783/1000 [02:57<00:50,  4.33it/s]Epoch 783\n",
            "Loss = 1.0043e-03, PNorm = 38.7169, GNorm = 0.1995, lr_0 = 1.6465e-04\n",
            "Validation rmse = 0.834946\n",
            " 78%|███████▊  | 784/1000 [02:58<00:49,  4.37it/s]Epoch 784\n",
            "Loss = 7.1586e-04, PNorm = 38.7173, GNorm = 0.1170, lr_0 = 1.6417e-04\n",
            "Validation rmse = 0.821398\n",
            " 78%|███████▊  | 785/1000 [02:58<00:48,  4.39it/s]Epoch 785\n",
            "Validation rmse = 0.827694\n",
            " 79%|███████▊  | 786/1000 [02:58<00:48,  4.41it/s]Epoch 786\n",
            "Loss = 2.3786e-04, PNorm = 38.7184, GNorm = 0.1371, lr_0 = 1.6370e-04\n",
            "Validation rmse = 0.830964\n",
            " 79%|███████▊  | 787/1000 [02:58<00:48,  4.42it/s]Epoch 787\n",
            "Loss = 5.6251e-04, PNorm = 38.7189, GNorm = 0.1205, lr_0 = 1.6323e-04\n",
            "Validation rmse = 0.824744\n",
            " 79%|███████▉  | 788/1000 [02:59<00:47,  4.43it/s]Epoch 788\n",
            "Loss = 7.4170e-04, PNorm = 38.7199, GNorm = 0.1439, lr_0 = 1.6276e-04\n",
            "Validation rmse = 0.832281\n",
            " 79%|███████▉  | 789/1000 [02:59<00:47,  4.43it/s]Epoch 789\n",
            "Loss = 7.5670e-04, PNorm = 38.7213, GNorm = 0.0743, lr_0 = 1.6229e-04\n",
            "Validation rmse = 0.819753\n",
            " 79%|███████▉  | 790/1000 [02:59<00:47,  4.44it/s]Epoch 790\n",
            "Validation rmse = 0.833673\n",
            " 79%|███████▉  | 791/1000 [02:59<00:46,  4.45it/s]Epoch 791\n",
            "Loss = 3.4674e-04, PNorm = 38.7226, GNorm = 0.1983, lr_0 = 1.6182e-04\n",
            "Validation rmse = 0.825811\n",
            " 79%|███████▉  | 792/1000 [02:59<00:46,  4.45it/s]Epoch 792\n",
            "Loss = 5.3358e-04, PNorm = 38.7233, GNorm = 0.0864, lr_0 = 1.6136e-04\n",
            "Validation rmse = 0.833450\n",
            " 79%|███████▉  | 793/1000 [03:00<00:46,  4.45it/s]Epoch 793\n",
            "Loss = 6.9735e-04, PNorm = 38.7238, GNorm = 0.1132, lr_0 = 1.6089e-04\n",
            "Validation rmse = 0.830671\n",
            " 79%|███████▉  | 794/1000 [03:00<00:46,  4.45it/s]Epoch 794\n",
            "Loss = 5.2740e-04, PNorm = 38.7248, GNorm = 0.0774, lr_0 = 1.6043e-04\n",
            "Validation rmse = 0.834074\n",
            " 80%|███████▉  | 795/1000 [03:00<00:46,  4.44it/s]Epoch 795\n",
            "Validation rmse = 0.829714\n",
            " 80%|███████▉  | 796/1000 [03:00<00:45,  4.45it/s]Epoch 796\n",
            "Loss = 1.4816e-04, PNorm = 38.7256, GNorm = 0.1001, lr_0 = 1.5997e-04\n",
            "Validation rmse = 0.831507\n",
            " 80%|███████▉  | 797/1000 [03:01<00:45,  4.45it/s]Epoch 797\n",
            "Loss = 5.2872e-04, PNorm = 38.7264, GNorm = 0.1443, lr_0 = 1.5951e-04\n",
            "Validation rmse = 0.827969\n",
            " 80%|███████▉  | 798/1000 [03:01<00:45,  4.44it/s]Epoch 798\n",
            "Loss = 1.9022e-04, PNorm = 38.7272, GNorm = 0.0545, lr_0 = 1.5905e-04\n",
            "Validation rmse = 0.831146\n",
            " 80%|███████▉  | 799/1000 [03:01<00:45,  4.45it/s]Epoch 799\n",
            "Loss = 6.0397e-04, PNorm = 38.7279, GNorm = 0.0999, lr_0 = 1.5859e-04\n",
            "Validation rmse = 0.828632\n",
            " 80%|████████  | 800/1000 [03:01<00:44,  4.45it/s]Epoch 800\n",
            "Validation rmse = 0.827064\n",
            " 80%|████████  | 801/1000 [03:02<00:44,  4.46it/s]Epoch 801\n",
            "Loss = 6.4733e-04, PNorm = 38.7284, GNorm = 0.1143, lr_0 = 1.5813e-04\n",
            "Validation rmse = 0.829011\n",
            " 80%|████████  | 802/1000 [03:02<00:44,  4.46it/s]Epoch 802\n",
            "Loss = 5.8807e-04, PNorm = 38.7287, GNorm = 0.0836, lr_0 = 1.5768e-04\n",
            "Validation rmse = 0.833996\n",
            " 80%|████████  | 803/1000 [03:02<00:44,  4.45it/s]Epoch 803\n",
            "Loss = 5.2827e-04, PNorm = 38.7297, GNorm = 0.0932, lr_0 = 1.5722e-04\n",
            "Validation rmse = 0.829721\n",
            " 80%|████████  | 804/1000 [03:02<00:44,  4.43it/s]Epoch 804\n",
            "Loss = 7.1091e-04, PNorm = 38.7304, GNorm = 0.0635, lr_0 = 1.5677e-04\n",
            "Validation rmse = 0.828642\n",
            " 80%|████████  | 805/1000 [03:02<00:44,  4.43it/s]Epoch 805\n",
            "Validation rmse = 0.827974\n",
            " 81%|████████  | 806/1000 [03:03<00:43,  4.44it/s]Epoch 806\n",
            "Loss = 7.1659e-04, PNorm = 38.7323, GNorm = 0.1074, lr_0 = 1.5632e-04\n",
            "Validation rmse = 0.831682\n",
            " 81%|████████  | 807/1000 [03:03<00:43,  4.45it/s]Epoch 807\n",
            "Loss = 6.8533e-04, PNorm = 38.7321, GNorm = 0.0862, lr_0 = 1.5587e-04\n",
            "Validation rmse = 0.831826\n",
            " 81%|████████  | 808/1000 [03:03<00:43,  4.44it/s]Epoch 808\n",
            "Loss = 6.8816e-04, PNorm = 38.7333, GNorm = 0.1419, lr_0 = 1.5542e-04\n",
            "Validation rmse = 0.824999\n",
            " 81%|████████  | 809/1000 [03:03<00:42,  4.44it/s]Epoch 809\n",
            "Loss = 7.7304e-04, PNorm = 38.7340, GNorm = 0.2212, lr_0 = 1.5497e-04\n",
            "Validation rmse = 0.830148\n",
            " 81%|████████  | 810/1000 [03:04<00:42,  4.45it/s]Epoch 810\n",
            "Validation rmse = 0.836424\n",
            " 81%|████████  | 811/1000 [03:04<00:42,  4.46it/s]Epoch 811\n",
            "Loss = 5.8211e-04, PNorm = 38.7347, GNorm = 0.1681, lr_0 = 1.5453e-04\n",
            "Validation rmse = 0.826513\n",
            " 81%|████████  | 812/1000 [03:04<00:42,  4.45it/s]Epoch 812\n",
            "Loss = 1.1567e-03, PNorm = 38.7347, GNorm = 0.1451, lr_0 = 1.5408e-04\n",
            "Validation rmse = 0.820178\n",
            " 81%|████████▏ | 813/1000 [03:04<00:42,  4.45it/s]Epoch 813\n",
            "Loss = 6.1841e-04, PNorm = 38.7354, GNorm = 0.1498, lr_0 = 1.5364e-04\n",
            "Validation rmse = 0.841076\n",
            " 81%|████████▏ | 814/1000 [03:04<00:41,  4.45it/s]Epoch 814\n",
            "Loss = 7.4519e-04, PNorm = 38.7363, GNorm = 0.1125, lr_0 = 1.5320e-04\n",
            "Validation rmse = 0.830487\n",
            " 82%|████████▏ | 815/1000 [03:05<00:41,  4.45it/s]Epoch 815\n",
            "Validation rmse = 0.823875\n",
            " 82%|████████▏ | 816/1000 [03:05<00:41,  4.46it/s]Epoch 816\n",
            "Loss = 1.1144e-03, PNorm = 38.7374, GNorm = 0.0764, lr_0 = 1.5275e-04\n",
            "Validation rmse = 0.828367\n",
            " 82%|████████▏ | 817/1000 [03:05<00:41,  4.46it/s]Epoch 817\n",
            "Loss = 1.6170e-04, PNorm = 38.7382, GNorm = 0.0747, lr_0 = 1.5231e-04\n",
            "Validation rmse = 0.836743\n",
            " 82%|████████▏ | 818/1000 [03:05<00:40,  4.46it/s]Epoch 818\n",
            "Loss = 8.2858e-04, PNorm = 38.7396, GNorm = 0.1158, lr_0 = 1.5188e-04\n",
            "Validation rmse = 0.825032\n",
            " 82%|████████▏ | 819/1000 [03:06<00:40,  4.45it/s]Epoch 819\n",
            "Loss = 6.6487e-04, PNorm = 38.7410, GNorm = 0.1718, lr_0 = 1.5144e-04\n",
            "Validation rmse = 0.832270\n",
            " 82%|████████▏ | 820/1000 [03:06<00:40,  4.45it/s]Epoch 820\n",
            "Validation rmse = 0.832554\n",
            " 82%|████████▏ | 821/1000 [03:06<00:40,  4.46it/s]Epoch 821\n",
            "Loss = 8.6852e-04, PNorm = 38.7414, GNorm = 0.1815, lr_0 = 1.5100e-04\n",
            "Validation rmse = 0.822930\n",
            " 82%|████████▏ | 822/1000 [03:06<00:39,  4.46it/s]Epoch 822\n",
            "Loss = 1.1674e-03, PNorm = 38.7421, GNorm = 0.3408, lr_0 = 1.5057e-04\n",
            "Validation rmse = 0.840736\n",
            " 82%|████████▏ | 823/1000 [03:06<00:39,  4.46it/s]Epoch 823\n",
            "Loss = 7.5959e-04, PNorm = 38.7422, GNorm = 0.2840, lr_0 = 1.5013e-04\n",
            "Validation rmse = 0.826964\n",
            " 82%|████████▏ | 824/1000 [03:07<00:39,  4.45it/s]Epoch 824\n",
            "Loss = 8.3369e-04, PNorm = 38.7428, GNorm = 0.2853, lr_0 = 1.4970e-04\n",
            "Validation rmse = 0.826194\n",
            " 82%|████████▎ | 825/1000 [03:07<00:47,  3.71it/s]Epoch 825\n",
            "Validation rmse = 0.843492\n",
            " 83%|████████▎ | 826/1000 [03:07<00:44,  3.91it/s]Epoch 826\n",
            "Loss = 1.2462e-03, PNorm = 38.7445, GNorm = 0.1100, lr_0 = 1.4927e-04\n",
            "Validation rmse = 0.836987\n",
            " 83%|████████▎ | 827/1000 [03:08<00:42,  4.06it/s]Epoch 827\n",
            "Loss = 1.0629e-03, PNorm = 38.7458, GNorm = 0.3094, lr_0 = 1.4884e-04\n",
            "Validation rmse = 0.819213\n",
            " 83%|████████▎ | 828/1000 [03:08<00:41,  4.17it/s]Epoch 828\n",
            "Loss = 1.0792e-03, PNorm = 38.7468, GNorm = 0.2888, lr_0 = 1.4841e-04\n",
            "Validation rmse = 0.850399\n",
            " 83%|████████▎ | 829/1000 [03:08<00:40,  4.24it/s]Epoch 829\n",
            "Loss = 1.5666e-03, PNorm = 38.7484, GNorm = 0.5624, lr_0 = 1.4798e-04\n",
            "Validation rmse = 0.819516\n",
            " 83%|████████▎ | 830/1000 [03:08<00:39,  4.30it/s]Epoch 830\n",
            "Validation rmse = 0.824603\n",
            " 83%|████████▎ | 831/1000 [03:08<00:38,  4.34it/s]Epoch 831\n",
            "Loss = 1.7179e-03, PNorm = 38.7511, GNorm = 0.7750, lr_0 = 1.4756e-04\n",
            "Validation rmse = 0.844217\n",
            " 83%|████████▎ | 832/1000 [03:09<00:38,  4.37it/s]Epoch 832\n",
            "Loss = 1.3858e-03, PNorm = 38.7524, GNorm = 0.4506, lr_0 = 1.4713e-04\n",
            "Validation rmse = 0.819162\n",
            " 83%|████████▎ | 833/1000 [03:09<00:37,  4.40it/s]Epoch 833\n",
            "Loss = 7.5948e-04, PNorm = 38.7539, GNorm = 0.1410, lr_0 = 1.4671e-04\n",
            "Validation rmse = 0.841264\n",
            " 83%|████████▎ | 834/1000 [03:09<00:37,  4.42it/s]Epoch 834\n",
            "Loss = 7.1897e-04, PNorm = 38.7555, GNorm = 0.1283, lr_0 = 1.4629e-04\n",
            "Validation rmse = 0.821508\n",
            " 84%|████████▎ | 835/1000 [03:09<00:37,  4.43it/s]Epoch 835\n",
            "Validation rmse = 0.832600\n",
            " 84%|████████▎ | 836/1000 [03:10<00:36,  4.44it/s]Epoch 836\n",
            "Loss = 9.9427e-04, PNorm = 38.7567, GNorm = 0.1828, lr_0 = 1.4587e-04\n",
            "Validation rmse = 0.819974\n",
            " 84%|████████▎ | 837/1000 [03:10<00:36,  4.45it/s]Epoch 837\n",
            "Loss = 7.1177e-04, PNorm = 38.7573, GNorm = 0.2623, lr_0 = 1.4545e-04\n",
            "Validation rmse = 0.831018\n",
            " 84%|████████▍ | 838/1000 [03:10<00:36,  4.45it/s]Epoch 838\n",
            "Loss = 7.9539e-04, PNorm = 38.7579, GNorm = 0.1276, lr_0 = 1.4503e-04\n",
            "Validation rmse = 0.817862\n",
            " 84%|████████▍ | 839/1000 [03:10<00:36,  4.45it/s]Epoch 839\n",
            "Loss = 6.5578e-04, PNorm = 38.7586, GNorm = 0.2315, lr_0 = 1.4461e-04\n",
            "Validation rmse = 0.836536\n",
            " 84%|████████▍ | 840/1000 [03:10<00:35,  4.45it/s]Epoch 840\n",
            "Validation rmse = 0.817307\n",
            " 84%|████████▍ | 841/1000 [03:11<00:35,  4.46it/s]Epoch 841\n",
            "Loss = 1.8707e-03, PNorm = 38.7594, GNorm = 0.1557, lr_0 = 1.4419e-04\n",
            "Validation rmse = 0.831550\n",
            " 84%|████████▍ | 842/1000 [03:11<00:35,  4.46it/s]Epoch 842\n",
            "Loss = 6.7571e-04, PNorm = 38.7610, GNorm = 0.0797, lr_0 = 1.4378e-04\n",
            "Validation rmse = 0.825288\n",
            " 84%|████████▍ | 843/1000 [03:11<00:35,  4.45it/s]Epoch 843\n",
            "Loss = 6.1054e-04, PNorm = 38.7616, GNorm = 0.0946, lr_0 = 1.4336e-04\n",
            "Validation rmse = 0.828624\n",
            " 84%|████████▍ | 844/1000 [03:11<00:35,  4.44it/s]Epoch 844\n",
            "Loss = 4.8631e-04, PNorm = 38.7617, GNorm = 0.0520, lr_0 = 1.4295e-04\n",
            "Validation rmse = 0.823593\n",
            " 84%|████████▍ | 845/1000 [03:12<00:34,  4.45it/s]Epoch 845\n",
            "Validation rmse = 0.826931\n",
            " 85%|████████▍ | 846/1000 [03:12<00:34,  4.46it/s]Epoch 846\n",
            "Loss = 1.2714e-04, PNorm = 38.7625, GNorm = 0.0686, lr_0 = 1.4254e-04\n",
            "Validation rmse = 0.823110\n",
            " 85%|████████▍ | 847/1000 [03:12<00:34,  4.45it/s]Epoch 847\n",
            "Loss = 5.5433e-04, PNorm = 38.7631, GNorm = 0.1122, lr_0 = 1.4213e-04\n",
            "Validation rmse = 0.830032\n",
            " 85%|████████▍ | 848/1000 [03:12<00:34,  4.42it/s]Epoch 848\n",
            "Loss = 4.1968e-04, PNorm = 38.7636, GNorm = 0.1003, lr_0 = 1.4172e-04\n",
            "Validation rmse = 0.826805\n",
            " 85%|████████▍ | 849/1000 [03:12<00:34,  4.43it/s]Epoch 849\n",
            "Loss = 5.9663e-04, PNorm = 38.7643, GNorm = 0.0775, lr_0 = 1.4131e-04\n",
            "Validation rmse = 0.823972\n",
            " 85%|████████▌ | 850/1000 [03:13<00:33,  4.43it/s]Epoch 850\n",
            "Validation rmse = 0.835471\n",
            " 85%|████████▌ | 851/1000 [03:13<00:33,  4.44it/s]Epoch 851\n",
            "Loss = 3.4190e-04, PNorm = 38.7652, GNorm = 0.1221, lr_0 = 1.4090e-04\n",
            "Validation rmse = 0.824166\n",
            " 85%|████████▌ | 852/1000 [03:13<00:33,  4.45it/s]Epoch 852\n",
            "Loss = 3.2522e-04, PNorm = 38.7657, GNorm = 0.2732, lr_0 = 1.4050e-04\n",
            "Validation rmse = 0.830669\n",
            " 85%|████████▌ | 853/1000 [03:13<00:33,  4.45it/s]Epoch 853\n",
            "Loss = 7.5202e-04, PNorm = 38.7662, GNorm = 0.2294, lr_0 = 1.4009e-04\n",
            "Validation rmse = 0.822839\n",
            " 85%|████████▌ | 854/1000 [03:14<00:32,  4.45it/s]Epoch 854\n",
            "Loss = 6.1378e-04, PNorm = 38.7673, GNorm = 0.1343, lr_0 = 1.3969e-04\n",
            "Validation rmse = 0.827417\n",
            " 86%|████████▌ | 855/1000 [03:14<00:32,  4.45it/s]Epoch 855\n",
            "Validation rmse = 0.827735\n",
            " 86%|████████▌ | 856/1000 [03:14<00:32,  4.46it/s]Epoch 856\n",
            "Loss = 2.5633e-04, PNorm = 38.7675, GNorm = 0.0976, lr_0 = 1.3929e-04\n",
            "Validation rmse = 0.824330\n",
            " 86%|████████▌ | 857/1000 [03:14<00:32,  4.45it/s]Epoch 857\n",
            "Loss = 4.9629e-04, PNorm = 38.7682, GNorm = 0.0762, lr_0 = 1.3889e-04\n",
            "Validation rmse = 0.829766\n",
            " 86%|████████▌ | 858/1000 [03:14<00:31,  4.45it/s]Epoch 858\n",
            "Loss = 7.2598e-04, PNorm = 38.7685, GNorm = 0.0966, lr_0 = 1.3849e-04\n",
            "Validation rmse = 0.829812\n",
            " 86%|████████▌ | 859/1000 [03:15<00:31,  4.45it/s]Epoch 859\n",
            "Loss = 5.3789e-04, PNorm = 38.7690, GNorm = 0.1152, lr_0 = 1.3809e-04\n",
            "Validation rmse = 0.824370\n",
            " 86%|████████▌ | 860/1000 [03:15<00:31,  4.45it/s]Epoch 860\n",
            "Validation rmse = 0.836169\n",
            " 86%|████████▌ | 861/1000 [03:15<00:31,  4.45it/s]Epoch 861\n",
            "Loss = 2.2443e-04, PNorm = 38.7693, GNorm = 0.1736, lr_0 = 1.3769e-04\n",
            "Validation rmse = 0.823947\n",
            " 86%|████████▌ | 862/1000 [03:15<00:30,  4.46it/s]Epoch 862\n",
            "Loss = 5.7989e-04, PNorm = 38.7700, GNorm = 0.1508, lr_0 = 1.3729e-04\n",
            "Validation rmse = 0.833562\n",
            " 86%|████████▋ | 863/1000 [03:16<00:30,  4.43it/s]Epoch 863\n",
            "Loss = 6.8528e-04, PNorm = 38.7711, GNorm = 0.1414, lr_0 = 1.3690e-04\n",
            "Validation rmse = 0.821759\n",
            " 86%|████████▋ | 864/1000 [03:16<00:30,  4.44it/s]Epoch 864\n",
            "Loss = 5.9873e-04, PNorm = 38.7718, GNorm = 0.0387, lr_0 = 1.3650e-04\n",
            "Validation rmse = 0.832109\n",
            " 86%|████████▋ | 865/1000 [03:16<00:30,  4.44it/s]Epoch 865\n",
            "Validation rmse = 0.827936\n",
            " 87%|████████▋ | 866/1000 [03:16<00:30,  4.46it/s]Epoch 866\n",
            "Loss = 1.0622e-04, PNorm = 38.7717, GNorm = 0.0906, lr_0 = 1.3611e-04\n",
            "Validation rmse = 0.826687\n",
            " 87%|████████▋ | 867/1000 [03:16<00:29,  4.45it/s]Epoch 867\n",
            "Loss = 4.0774e-04, PNorm = 38.7724, GNorm = 0.1079, lr_0 = 1.3572e-04\n",
            "Validation rmse = 0.831662\n",
            " 87%|████████▋ | 868/1000 [03:17<00:29,  4.45it/s]Epoch 868\n",
            "Loss = 4.3515e-04, PNorm = 38.7727, GNorm = 0.0659, lr_0 = 1.3533e-04\n",
            "Validation rmse = 0.823649\n",
            " 87%|████████▋ | 869/1000 [03:17<00:29,  4.45it/s]Epoch 869\n",
            "Loss = 5.8617e-04, PNorm = 38.7728, GNorm = 0.0946, lr_0 = 1.3494e-04\n",
            "Validation rmse = 0.831202\n",
            " 87%|████████▋ | 870/1000 [03:17<00:29,  4.45it/s]Epoch 870\n",
            "Validation rmse = 0.830587\n",
            " 87%|████████▋ | 871/1000 [03:17<00:28,  4.46it/s]Epoch 871\n",
            "Loss = 7.0856e-05, PNorm = 38.7737, GNorm = 0.0359, lr_0 = 1.3455e-04\n",
            "Validation rmse = 0.830812\n",
            " 87%|████████▋ | 872/1000 [03:18<00:28,  4.45it/s]Epoch 872\n",
            "Loss = 1.4298e-04, PNorm = 38.7743, GNorm = 0.0360, lr_0 = 1.3416e-04\n",
            "Validation rmse = 0.827389\n",
            " 87%|████████▋ | 873/1000 [03:18<00:28,  4.45it/s]Epoch 873\n",
            "Loss = 5.5139e-04, PNorm = 38.7748, GNorm = 0.0222, lr_0 = 1.3378e-04\n",
            "Validation rmse = 0.830258\n",
            " 87%|████████▋ | 874/1000 [03:18<00:28,  4.45it/s]Epoch 874\n",
            "Loss = 4.7298e-04, PNorm = 38.7751, GNorm = 0.0582, lr_0 = 1.3339e-04\n",
            "Validation rmse = 0.826801\n",
            " 88%|████████▊ | 875/1000 [03:18<00:28,  4.45it/s]Epoch 875\n",
            "Validation rmse = 0.827780\n",
            " 88%|████████▊ | 876/1000 [03:19<00:27,  4.46it/s]Epoch 876\n",
            "Loss = 9.5114e-05, PNorm = 38.7758, GNorm = 0.1372, lr_0 = 1.3301e-04\n",
            "Validation rmse = 0.834117\n",
            " 88%|████████▊ | 877/1000 [03:19<00:27,  4.46it/s]Epoch 877\n",
            "Loss = 4.4931e-04, PNorm = 38.7762, GNorm = 0.2520, lr_0 = 1.3262e-04\n",
            "Validation rmse = 0.820747\n",
            " 88%|████████▊ | 878/1000 [03:19<00:27,  4.46it/s]Epoch 878\n",
            "Loss = 3.4348e-04, PNorm = 38.7768, GNorm = 0.1024, lr_0 = 1.3224e-04\n",
            "Validation rmse = 0.835100\n",
            " 88%|████████▊ | 879/1000 [03:19<00:27,  4.45it/s]Epoch 879\n",
            "Loss = 5.5191e-04, PNorm = 38.7774, GNorm = 0.0759, lr_0 = 1.3186e-04\n",
            "Validation rmse = 0.827487\n",
            " 88%|████████▊ | 880/1000 [03:19<00:26,  4.46it/s]Epoch 880\n",
            "Validation rmse = 0.831015\n",
            " 88%|████████▊ | 881/1000 [03:20<00:26,  4.46it/s]Epoch 881\n",
            "Loss = 1.0184e-03, PNorm = 38.7776, GNorm = 0.1928, lr_0 = 1.3148e-04\n",
            "Validation rmse = 0.829815\n",
            " 88%|████████▊ | 882/1000 [03:20<00:26,  4.46it/s]Epoch 882\n",
            "Loss = 4.5803e-04, PNorm = 38.7783, GNorm = 0.1164, lr_0 = 1.3110e-04\n",
            "Validation rmse = 0.822806\n",
            " 88%|████████▊ | 883/1000 [03:20<00:26,  4.46it/s]Epoch 883\n",
            "Loss = 7.0998e-04, PNorm = 38.7789, GNorm = 0.1371, lr_0 = 1.3072e-04\n",
            "Validation rmse = 0.828445\n",
            " 88%|████████▊ | 884/1000 [03:20<00:26,  4.45it/s]Epoch 884\n",
            "Loss = 5.6388e-04, PNorm = 38.7795, GNorm = 0.1281, lr_0 = 1.3035e-04\n",
            "Validation rmse = 0.830782\n",
            " 88%|████████▊ | 885/1000 [03:21<00:25,  4.45it/s]Epoch 885\n",
            "Validation rmse = 0.827074\n",
            " 89%|████████▊ | 886/1000 [03:21<00:25,  4.45it/s]Epoch 886\n",
            "Loss = 7.0463e-05, PNorm = 38.7800, GNorm = 0.0442, lr_0 = 1.2997e-04\n",
            "Validation rmse = 0.829708\n",
            " 89%|████████▊ | 887/1000 [03:21<00:25,  4.45it/s]Epoch 887\n",
            "Loss = 4.5763e-04, PNorm = 38.7802, GNorm = 0.0819, lr_0 = 1.2960e-04\n",
            "Validation rmse = 0.829733\n",
            " 89%|████████▉ | 888/1000 [03:21<00:25,  4.45it/s]Epoch 888\n",
            "Loss = 6.9276e-04, PNorm = 38.7813, GNorm = 0.1044, lr_0 = 1.2923e-04\n",
            "Validation rmse = 0.823031\n",
            " 89%|████████▉ | 889/1000 [03:21<00:24,  4.45it/s]Epoch 889\n",
            "Loss = 5.8213e-04, PNorm = 38.7821, GNorm = 0.0847, lr_0 = 1.2885e-04\n",
            "Validation rmse = 0.837332\n",
            " 89%|████████▉ | 890/1000 [03:22<00:24,  4.45it/s]Epoch 890\n",
            "Validation rmse = 0.831047\n",
            " 89%|████████▉ | 891/1000 [03:22<00:24,  4.46it/s]Epoch 891\n",
            "Loss = 1.6112e-04, PNorm = 38.7827, GNorm = 0.0803, lr_0 = 1.2848e-04\n",
            "Validation rmse = 0.826813\n",
            " 89%|████████▉ | 892/1000 [03:22<00:24,  4.45it/s]Epoch 892\n",
            "Loss = 6.2834e-04, PNorm = 38.7833, GNorm = 0.0915, lr_0 = 1.2811e-04\n",
            "Validation rmse = 0.836637\n",
            " 89%|████████▉ | 893/1000 [03:22<00:24,  4.45it/s]Epoch 893\n",
            "Loss = 5.7715e-04, PNorm = 38.7833, GNorm = 0.2771, lr_0 = 1.2774e-04\n",
            "Validation rmse = 0.826089\n",
            " 89%|████████▉ | 894/1000 [03:23<00:23,  4.45it/s]Epoch 894\n",
            "Loss = 6.0157e-04, PNorm = 38.7841, GNorm = 0.0566, lr_0 = 1.2738e-04\n",
            "Validation rmse = 0.826564\n",
            " 90%|████████▉ | 895/1000 [03:23<00:23,  4.45it/s]Epoch 895\n",
            "Validation rmse = 0.838147\n",
            " 90%|████████▉ | 896/1000 [03:23<00:23,  4.46it/s]Epoch 896\n",
            "Loss = 2.8290e-04, PNorm = 38.7845, GNorm = 0.0457, lr_0 = 1.2701e-04\n",
            "Validation rmse = 0.827341\n",
            " 90%|████████▉ | 897/1000 [03:23<00:23,  4.46it/s]Epoch 897\n",
            "Loss = 5.3896e-04, PNorm = 38.7857, GNorm = 0.0890, lr_0 = 1.2664e-04\n",
            "Validation rmse = 0.829285\n",
            " 90%|████████▉ | 898/1000 [03:23<00:22,  4.45it/s]Epoch 898\n",
            "Loss = 6.5501e-04, PNorm = 38.7858, GNorm = 0.1508, lr_0 = 1.2628e-04\n",
            "Validation rmse = 0.824701\n",
            " 90%|████████▉ | 899/1000 [03:24<00:22,  4.45it/s]Epoch 899\n",
            "Loss = 7.2828e-04, PNorm = 38.7863, GNorm = 0.1987, lr_0 = 1.2591e-04\n",
            "Validation rmse = 0.831366\n",
            " 90%|█████████ | 900/1000 [03:24<00:22,  4.45it/s]Epoch 900\n",
            "Validation rmse = 0.824056\n",
            " 90%|█████████ | 901/1000 [03:24<00:22,  4.46it/s]Epoch 901\n",
            "Loss = 1.0721e-03, PNorm = 38.7864, GNorm = 0.2737, lr_0 = 1.2555e-04\n",
            "Validation rmse = 0.832831\n",
            " 90%|█████████ | 902/1000 [03:24<00:21,  4.46it/s]Epoch 902\n",
            "Loss = 2.5943e-04, PNorm = 38.7867, GNorm = 0.1135, lr_0 = 1.2519e-04\n",
            "Validation rmse = 0.832683\n",
            " 90%|█████████ | 903/1000 [03:25<00:21,  4.46it/s]Epoch 903\n",
            "Loss = 5.4833e-04, PNorm = 38.7869, GNorm = 0.0740, lr_0 = 1.2483e-04\n",
            "Validation rmse = 0.820481\n",
            " 90%|█████████ | 904/1000 [03:25<00:21,  4.45it/s]Epoch 904\n",
            "Loss = 6.6260e-04, PNorm = 38.7874, GNorm = 0.2707, lr_0 = 1.2447e-04\n",
            "Validation rmse = 0.834789\n",
            " 90%|█████████ | 905/1000 [03:25<00:21,  4.45it/s]Epoch 905\n",
            "Validation rmse = 0.826888\n",
            " 91%|█████████ | 906/1000 [03:25<00:21,  4.46it/s]Epoch 906\n",
            "Loss = 2.8766e-04, PNorm = 38.7884, GNorm = 0.1862, lr_0 = 1.2411e-04\n",
            "Validation rmse = 0.827089\n",
            " 91%|█████████ | 907/1000 [03:25<00:20,  4.46it/s]Epoch 907\n",
            "Loss = 6.5510e-04, PNorm = 38.7896, GNorm = 0.2096, lr_0 = 1.2375e-04\n",
            "Validation rmse = 0.836180\n",
            " 91%|█████████ | 908/1000 [03:26<00:20,  4.45it/s]Epoch 908\n",
            "Loss = 6.9779e-04, PNorm = 38.7899, GNorm = 0.1410, lr_0 = 1.2340e-04\n",
            "Validation rmse = 0.827967\n",
            " 91%|█████████ | 909/1000 [03:26<00:21,  4.29it/s]Epoch 909\n",
            "Loss = 5.3766e-04, PNorm = 38.7910, GNorm = 0.0379, lr_0 = 1.2304e-04\n",
            "Validation rmse = 0.831317\n",
            " 91%|█████████ | 910/1000 [03:26<00:20,  4.34it/s]Epoch 910\n",
            "Validation rmse = 0.830534\n",
            " 91%|█████████ | 911/1000 [03:26<00:20,  4.38it/s]Epoch 911\n",
            "Loss = 1.9980e-04, PNorm = 38.7918, GNorm = 0.1186, lr_0 = 1.2269e-04\n",
            "Validation rmse = 0.829308\n",
            " 91%|█████████ | 912/1000 [03:27<00:19,  4.40it/s]Epoch 912\n",
            "Loss = 5.0637e-04, PNorm = 38.7922, GNorm = 0.1124, lr_0 = 1.2233e-04\n",
            "Validation rmse = 0.830935\n",
            " 91%|█████████▏| 913/1000 [03:27<00:19,  4.41it/s]Epoch 913\n",
            "Loss = 6.6542e-04, PNorm = 38.7923, GNorm = 0.1853, lr_0 = 1.2198e-04\n",
            "Validation rmse = 0.830979\n",
            " 91%|█████████▏| 914/1000 [03:27<00:19,  4.42it/s]Epoch 914\n",
            "Loss = 5.7205e-04, PNorm = 38.7929, GNorm = 0.0897, lr_0 = 1.2163e-04\n",
            "Validation rmse = 0.823003\n",
            " 92%|█████████▏| 915/1000 [03:27<00:19,  4.43it/s]Epoch 915\n",
            "Validation rmse = 0.836450\n",
            " 92%|█████████▏| 916/1000 [03:28<00:18,  4.45it/s]Epoch 916\n",
            "Loss = 8.5622e-04, PNorm = 38.7932, GNorm = 0.1434, lr_0 = 1.2128e-04\n",
            "Validation rmse = 0.823615\n",
            " 92%|█████████▏| 917/1000 [03:28<00:18,  4.45it/s]Epoch 917\n",
            "Loss = 1.6038e-04, PNorm = 38.7940, GNorm = 0.1063, lr_0 = 1.2093e-04\n",
            "Validation rmse = 0.831168\n",
            " 92%|█████████▏| 918/1000 [03:28<00:18,  4.45it/s]Epoch 918\n",
            "Loss = 6.7222e-04, PNorm = 38.7947, GNorm = 0.1289, lr_0 = 1.2058e-04\n",
            "Validation rmse = 0.828451\n",
            " 92%|█████████▏| 919/1000 [03:28<00:18,  4.45it/s]Epoch 919\n",
            "Loss = 6.0138e-04, PNorm = 38.7951, GNorm = 0.1609, lr_0 = 1.2024e-04\n",
            "Validation rmse = 0.828435\n",
            " 92%|█████████▏| 920/1000 [03:28<00:18,  4.44it/s]Epoch 920\n",
            "Validation rmse = 0.826428\n",
            " 92%|█████████▏| 921/1000 [03:29<00:17,  4.45it/s]Epoch 921\n",
            "Loss = 3.3505e-04, PNorm = 38.7957, GNorm = 0.1029, lr_0 = 1.1989e-04\n",
            "Validation rmse = 0.829335\n",
            " 92%|█████████▏| 922/1000 [03:29<00:17,  4.45it/s]Epoch 922\n",
            "Loss = 2.1286e-04, PNorm = 38.7964, GNorm = 0.0635, lr_0 = 1.1954e-04\n",
            "Validation rmse = 0.830817\n",
            " 92%|█████████▏| 923/1000 [03:29<00:17,  4.45it/s]Epoch 923\n",
            "Loss = 4.5314e-04, PNorm = 38.7965, GNorm = 0.1168, lr_0 = 1.1920e-04\n",
            "Validation rmse = 0.832118\n",
            " 92%|█████████▏| 924/1000 [03:29<00:17,  4.44it/s]Epoch 924\n",
            "Loss = 5.9242e-04, PNorm = 38.7969, GNorm = 0.2725, lr_0 = 1.1886e-04\n",
            "Validation rmse = 0.825581\n",
            " 92%|█████████▎| 925/1000 [03:30<00:16,  4.45it/s]Epoch 925\n",
            "Validation rmse = 0.829319\n",
            " 93%|█████████▎| 926/1000 [03:30<00:16,  4.43it/s]Epoch 926\n",
            "Loss = 1.0248e-03, PNorm = 38.7976, GNorm = 0.2156, lr_0 = 1.1851e-04\n",
            "Validation rmse = 0.827590\n",
            " 93%|█████████▎| 927/1000 [03:30<00:16,  4.44it/s]Epoch 927\n",
            "Loss = 5.8211e-04, PNorm = 38.7985, GNorm = 0.0561, lr_0 = 1.1817e-04\n",
            "Validation rmse = 0.825680\n",
            " 93%|█████████▎| 928/1000 [03:30<00:16,  4.44it/s]Epoch 928\n",
            "Loss = 6.4761e-04, PNorm = 38.7986, GNorm = 0.0351, lr_0 = 1.1783e-04\n",
            "Validation rmse = 0.829969\n",
            " 93%|█████████▎| 929/1000 [03:30<00:15,  4.44it/s]Epoch 929\n",
            "Loss = 4.9114e-04, PNorm = 38.7991, GNorm = 0.1168, lr_0 = 1.1749e-04\n",
            "Validation rmse = 0.831978\n",
            " 93%|█████████▎| 930/1000 [03:31<00:15,  4.44it/s]Epoch 930\n",
            "Validation rmse = 0.832121\n",
            " 93%|█████████▎| 931/1000 [03:31<00:18,  3.76it/s]Epoch 931\n",
            "Loss = 8.5776e-04, PNorm = 38.7996, GNorm = 0.2150, lr_0 = 1.1716e-04\n",
            "Validation rmse = 0.830595\n",
            " 93%|█████████▎| 932/1000 [03:31<00:17,  3.94it/s]Epoch 932\n",
            "Loss = 9.0664e-04, PNorm = 38.8004, GNorm = 0.1531, lr_0 = 1.1682e-04\n",
            "Validation rmse = 0.829767\n",
            " 93%|█████████▎| 933/1000 [03:31<00:16,  4.08it/s]Epoch 933\n",
            "Loss = 6.6792e-04, PNorm = 38.8009, GNorm = 0.1375, lr_0 = 1.1648e-04\n",
            "Validation rmse = 0.829847\n",
            " 93%|█████████▎| 934/1000 [03:32<00:15,  4.19it/s]Epoch 934\n",
            "Loss = 5.9535e-04, PNorm = 38.8015, GNorm = 0.0565, lr_0 = 1.1615e-04\n",
            "Validation rmse = 0.836357\n",
            " 94%|█████████▎| 935/1000 [03:32<00:15,  4.26it/s]Epoch 935\n",
            "Validation rmse = 0.829146\n",
            " 94%|█████████▎| 936/1000 [03:32<00:14,  4.33it/s]Epoch 936\n",
            "Loss = 1.5567e-04, PNorm = 38.8020, GNorm = 0.0443, lr_0 = 1.1581e-04\n",
            "Validation rmse = 0.831331\n",
            " 94%|█████████▎| 937/1000 [03:32<00:14,  4.37it/s]Epoch 937\n",
            "Loss = 8.5441e-04, PNorm = 38.8019, GNorm = 0.0544, lr_0 = 1.1548e-04\n",
            "Validation rmse = 0.828975\n",
            " 94%|█████████▍| 938/1000 [03:33<00:14,  4.39it/s]Epoch 938\n",
            "Loss = 5.8826e-04, PNorm = 38.8020, GNorm = 0.0822, lr_0 = 1.1515e-04\n",
            "Validation rmse = 0.834190\n",
            " 94%|█████████▍| 939/1000 [03:33<00:13,  4.41it/s]Epoch 939\n",
            "Loss = 5.3075e-04, PNorm = 38.8027, GNorm = 0.1086, lr_0 = 1.1481e-04\n",
            "Validation rmse = 0.827677\n",
            " 94%|█████████▍| 940/1000 [03:33<00:13,  4.42it/s]Epoch 940\n",
            "Validation rmse = 0.832273\n",
            " 94%|█████████▍| 941/1000 [03:33<00:13,  4.44it/s]Epoch 941\n",
            "Loss = 1.6612e-04, PNorm = 38.8034, GNorm = 0.0379, lr_0 = 1.1448e-04\n",
            "Validation rmse = 0.833307\n",
            " 94%|█████████▍| 942/1000 [03:34<00:13,  4.44it/s]Epoch 942\n",
            "Loss = 7.2816e-05, PNorm = 38.8039, GNorm = 0.0919, lr_0 = 1.1415e-04\n",
            "Validation rmse = 0.830041\n",
            " 94%|█████████▍| 943/1000 [03:34<00:12,  4.44it/s]Epoch 943\n",
            "Loss = 6.0579e-04, PNorm = 38.8041, GNorm = 0.0488, lr_0 = 1.1382e-04\n",
            "Validation rmse = 0.831164\n",
            " 94%|█████████▍| 944/1000 [03:34<00:12,  4.45it/s]Epoch 944\n",
            "Loss = 4.4267e-04, PNorm = 38.8043, GNorm = 0.0357, lr_0 = 1.1350e-04\n",
            "Validation rmse = 0.830363\n",
            " 94%|█████████▍| 945/1000 [03:34<00:12,  4.45it/s]Epoch 945\n",
            "Validation rmse = 0.832834\n",
            " 95%|█████████▍| 946/1000 [03:34<00:12,  4.46it/s]Epoch 946\n",
            "Loss = 6.6984e-04, PNorm = 38.8049, GNorm = 0.0939, lr_0 = 1.1317e-04\n",
            "Validation rmse = 0.827208\n",
            " 95%|█████████▍| 947/1000 [03:35<00:11,  4.46it/s]Epoch 947\n",
            "Loss = 2.0121e-04, PNorm = 38.8055, GNorm = 0.0819, lr_0 = 1.1284e-04\n",
            "Validation rmse = 0.833276\n",
            " 95%|█████████▍| 948/1000 [03:35<00:11,  4.45it/s]Epoch 948\n",
            "Loss = 3.9552e-04, PNorm = 38.8061, GNorm = 0.1027, lr_0 = 1.1252e-04\n",
            "Validation rmse = 0.830579\n",
            " 95%|█████████▍| 949/1000 [03:35<00:11,  4.45it/s]Epoch 949\n",
            "Loss = 5.6642e-04, PNorm = 38.8065, GNorm = 0.1265, lr_0 = 1.1220e-04\n",
            "Validation rmse = 0.833867\n",
            " 95%|█████████▌| 950/1000 [03:35<00:11,  4.45it/s]Epoch 950\n",
            "Validation rmse = 0.831621\n",
            " 95%|█████████▌| 951/1000 [03:36<00:10,  4.46it/s]Epoch 951\n",
            "Loss = 1.0492e-03, PNorm = 38.8068, GNorm = 0.1034, lr_0 = 1.1187e-04\n",
            "Validation rmse = 0.830375\n",
            " 95%|█████████▌| 952/1000 [03:36<00:10,  4.46it/s]Epoch 952\n",
            "Loss = 5.6950e-04, PNorm = 38.8077, GNorm = 0.1376, lr_0 = 1.1155e-04\n",
            "Validation rmse = 0.827432\n",
            " 95%|█████████▌| 953/1000 [03:36<00:10,  4.46it/s]Epoch 953\n",
            "Loss = 7.1936e-04, PNorm = 38.8081, GNorm = 0.1457, lr_0 = 1.1123e-04\n",
            "Validation rmse = 0.836674\n",
            " 95%|█████████▌| 954/1000 [03:36<00:10,  4.46it/s]Epoch 954\n",
            "Loss = 6.1723e-04, PNorm = 38.8081, GNorm = 0.1367, lr_0 = 1.1091e-04\n",
            "Validation rmse = 0.828074\n",
            " 96%|█████████▌| 955/1000 [03:36<00:10,  4.45it/s]Epoch 955\n",
            "Validation rmse = 0.835834\n",
            " 96%|█████████▌| 956/1000 [03:37<00:09,  4.46it/s]Epoch 956\n",
            "Loss = 9.7667e-04, PNorm = 38.8087, GNorm = 0.2201, lr_0 = 1.1059e-04\n",
            "Validation rmse = 0.831141\n",
            " 96%|█████████▌| 957/1000 [03:37<00:09,  4.45it/s]Epoch 957\n",
            "Loss = 5.8395e-04, PNorm = 38.8095, GNorm = 0.1981, lr_0 = 1.1027e-04\n",
            "Validation rmse = 0.832687\n",
            " 96%|█████████▌| 958/1000 [03:37<00:09,  4.43it/s]Epoch 958\n",
            "Loss = 5.1795e-04, PNorm = 38.8105, GNorm = 0.2697, lr_0 = 1.0995e-04\n",
            "Validation rmse = 0.833105\n",
            " 96%|█████████▌| 959/1000 [03:37<00:09,  4.43it/s]Epoch 959\n",
            "Loss = 6.6381e-04, PNorm = 38.8111, GNorm = 0.1507, lr_0 = 1.0964e-04\n",
            "Validation rmse = 0.829464\n",
            " 96%|█████████▌| 960/1000 [03:38<00:09,  4.44it/s]Epoch 960\n",
            "Validation rmse = 0.835856\n",
            " 96%|█████████▌| 961/1000 [03:38<00:08,  4.45it/s]Epoch 961\n",
            "Loss = 9.3061e-04, PNorm = 38.8116, GNorm = 0.0975, lr_0 = 1.0932e-04\n",
            "Validation rmse = 0.831287\n",
            " 96%|█████████▌| 962/1000 [03:38<00:08,  4.45it/s]Epoch 962\n",
            "Loss = 5.9860e-04, PNorm = 38.8120, GNorm = 0.0515, lr_0 = 1.0901e-04\n",
            "Validation rmse = 0.822024\n",
            " 96%|█████████▋| 963/1000 [03:38<00:08,  4.44it/s]Epoch 963\n",
            "Loss = 8.5286e-04, PNorm = 38.8125, GNorm = 0.1311, lr_0 = 1.0869e-04\n",
            "Validation rmse = 0.836214\n",
            " 96%|█████████▋| 964/1000 [03:38<00:08,  4.44it/s]Epoch 964\n",
            "Loss = 6.6840e-04, PNorm = 38.8132, GNorm = 0.1340, lr_0 = 1.0838e-04\n",
            "Validation rmse = 0.828130\n",
            " 96%|█████████▋| 965/1000 [03:39<00:07,  4.44it/s]Epoch 965\n",
            "Validation rmse = 0.833525\n",
            " 97%|█████████▋| 966/1000 [03:39<00:07,  4.45it/s]Epoch 966\n",
            "Loss = 8.6458e-04, PNorm = 38.8135, GNorm = 0.0993, lr_0 = 1.0807e-04\n",
            "Validation rmse = 0.833268\n",
            " 97%|█████████▋| 967/1000 [03:39<00:07,  4.45it/s]Epoch 967\n",
            "Loss = 9.0141e-04, PNorm = 38.8146, GNorm = 0.0507, lr_0 = 1.0776e-04\n",
            "Validation rmse = 0.826109\n",
            " 97%|█████████▋| 968/1000 [03:39<00:07,  4.45it/s]Epoch 968\n",
            "Loss = 3.4100e-04, PNorm = 38.8156, GNorm = 0.0343, lr_0 = 1.0745e-04\n",
            "Validation rmse = 0.829509\n",
            " 97%|█████████▋| 969/1000 [03:40<00:06,  4.45it/s]Epoch 969\n",
            "Loss = 6.2804e-04, PNorm = 38.8163, GNorm = 0.1257, lr_0 = 1.0714e-04\n",
            "Validation rmse = 0.831705\n",
            " 97%|█████████▋| 970/1000 [03:40<00:06,  4.45it/s]Epoch 970\n",
            "Validation rmse = 0.829431\n",
            " 97%|█████████▋| 971/1000 [03:40<00:06,  4.46it/s]Epoch 971\n",
            "Loss = 8.3391e-04, PNorm = 38.8169, GNorm = 0.1130, lr_0 = 1.0683e-04\n",
            "Validation rmse = 0.828886\n",
            " 97%|█████████▋| 972/1000 [03:40<00:06,  4.46it/s]Epoch 972\n",
            "Loss = 5.6492e-04, PNorm = 38.8175, GNorm = 0.0510, lr_0 = 1.0652e-04\n",
            "Validation rmse = 0.833789\n",
            " 97%|█████████▋| 973/1000 [03:40<00:06,  4.44it/s]Epoch 973\n",
            "Loss = 3.6469e-04, PNorm = 38.8174, GNorm = 0.0719, lr_0 = 1.0621e-04\n",
            "Validation rmse = 0.825496\n",
            " 97%|█████████▋| 974/1000 [03:41<00:05,  4.44it/s]Epoch 974\n",
            "Loss = 4.5567e-04, PNorm = 38.8179, GNorm = 0.0432, lr_0 = 1.0591e-04\n",
            "Validation rmse = 0.831541\n",
            " 98%|█████████▊| 975/1000 [03:41<00:05,  4.44it/s]Epoch 975\n",
            "Validation rmse = 0.826446\n",
            " 98%|█████████▊| 976/1000 [03:41<00:05,  4.46it/s]Epoch 976\n",
            "Loss = 1.4014e-03, PNorm = 38.8182, GNorm = 0.1348, lr_0 = 1.0560e-04\n",
            "Validation rmse = 0.831260\n",
            " 98%|█████████▊| 977/1000 [03:41<00:05,  4.46it/s]Epoch 977\n",
            "Loss = 8.1282e-04, PNorm = 38.8183, GNorm = 0.1204, lr_0 = 1.0530e-04\n",
            "Validation rmse = 0.831166\n",
            " 98%|█████████▊| 978/1000 [03:42<00:04,  4.46it/s]Epoch 978\n",
            "Loss = 5.8766e-04, PNorm = 38.8187, GNorm = 0.0532, lr_0 = 1.0499e-04\n",
            "Validation rmse = 0.826718\n",
            " 98%|█████████▊| 979/1000 [03:42<00:04,  4.45it/s]Epoch 979\n",
            "Loss = 4.5828e-04, PNorm = 38.8192, GNorm = 0.0354, lr_0 = 1.0469e-04\n",
            "Validation rmse = 0.829943\n",
            " 98%|█████████▊| 980/1000 [03:42<00:04,  4.46it/s]Epoch 980\n",
            "Validation rmse = 0.832555\n",
            " 98%|█████████▊| 981/1000 [03:42<00:04,  4.46it/s]Epoch 981\n",
            "Loss = 7.1935e-04, PNorm = 38.8196, GNorm = 0.1187, lr_0 = 1.0439e-04\n",
            "Validation rmse = 0.828936\n",
            " 98%|█████████▊| 982/1000 [03:42<00:04,  4.46it/s]Epoch 982\n",
            "Loss = 4.2457e-04, PNorm = 38.8200, GNorm = 0.1224, lr_0 = 1.0409e-04\n",
            "Validation rmse = 0.827747\n",
            " 98%|█████████▊| 983/1000 [03:43<00:03,  4.46it/s]Epoch 983\n",
            "Loss = 3.6119e-04, PNorm = 38.8201, GNorm = 0.0978, lr_0 = 1.0379e-04\n",
            "Validation rmse = 0.835204\n",
            " 98%|█████████▊| 984/1000 [03:43<00:03,  4.45it/s]Epoch 984\n",
            "Loss = 4.9026e-04, PNorm = 38.8205, GNorm = 0.0477, lr_0 = 1.0349e-04\n",
            "Validation rmse = 0.828225\n",
            " 98%|█████████▊| 985/1000 [03:43<00:03,  4.45it/s]Epoch 985\n",
            "Validation rmse = 0.828097\n",
            " 99%|█████████▊| 986/1000 [03:43<00:03,  4.46it/s]Epoch 986\n",
            "Loss = 1.4666e-04, PNorm = 38.8212, GNorm = 0.1281, lr_0 = 1.0319e-04\n",
            "Validation rmse = 0.831051\n",
            " 99%|█████████▊| 987/1000 [03:44<00:02,  4.46it/s]Epoch 987\n",
            "Loss = 9.6855e-05, PNorm = 38.8217, GNorm = 0.0464, lr_0 = 1.0290e-04\n",
            "Validation rmse = 0.833829\n",
            " 99%|█████████▉| 988/1000 [03:44<00:02,  4.46it/s]Epoch 988\n",
            "Loss = 5.7464e-04, PNorm = 38.8219, GNorm = 0.0904, lr_0 = 1.0260e-04\n",
            "Validation rmse = 0.828823\n",
            " 99%|█████████▉| 989/1000 [03:44<00:02,  4.45it/s]Epoch 989\n",
            "Loss = 4.9225e-04, PNorm = 38.8221, GNorm = 0.0944, lr_0 = 1.0230e-04\n",
            "Validation rmse = 0.832031\n",
            " 99%|█████████▉| 990/1000 [03:44<00:02,  4.45it/s]Epoch 990\n",
            "Validation rmse = 0.830056\n",
            " 99%|█████████▉| 991/1000 [03:45<00:02,  4.45it/s]Epoch 991\n",
            "Loss = 6.5199e-04, PNorm = 38.8226, GNorm = 0.0776, lr_0 = 1.0201e-04\n",
            "Validation rmse = 0.831230\n",
            " 99%|█████████▉| 992/1000 [03:45<00:01,  4.44it/s]Epoch 992\n",
            "Loss = 5.0034e-04, PNorm = 38.8230, GNorm = 0.0330, lr_0 = 1.0172e-04\n",
            "Validation rmse = 0.835251\n",
            " 99%|█████████▉| 993/1000 [03:45<00:01,  4.44it/s]Epoch 993\n",
            "Loss = 4.1412e-04, PNorm = 38.8233, GNorm = 0.0276, lr_0 = 1.0142e-04\n",
            "Validation rmse = 0.822699\n",
            " 99%|█████████▉| 994/1000 [03:45<00:01,  4.45it/s]Epoch 994\n",
            "Loss = 6.0920e-04, PNorm = 38.8233, GNorm = 0.0818, lr_0 = 1.0113e-04\n",
            "Validation rmse = 0.836770\n",
            "100%|█████████▉| 995/1000 [03:45<00:01,  4.44it/s]Epoch 995\n",
            "Validation rmse = 0.837801\n",
            "100%|█████████▉| 996/1000 [03:46<00:00,  4.46it/s]Epoch 996\n",
            "Loss = 1.5947e-04, PNorm = 38.8241, GNorm = 0.1694, lr_0 = 1.0084e-04\n",
            "Validation rmse = 0.825868\n",
            "100%|█████████▉| 997/1000 [03:46<00:00,  4.46it/s]Epoch 997\n",
            "Loss = 4.4523e-04, PNorm = 38.8241, GNorm = 0.1165, lr_0 = 1.0055e-04\n",
            "Validation rmse = 0.834672\n",
            "100%|█████████▉| 998/1000 [03:46<00:00,  4.45it/s]Epoch 998\n",
            "Loss = 3.4775e-04, PNorm = 38.8246, GNorm = 0.0719, lr_0 = 1.0026e-04\n",
            "Validation rmse = 0.831510\n",
            "100%|█████████▉| 999/1000 [03:46<00:00,  4.45it/s]Epoch 999\n",
            "Loss = 5.0966e-04, PNorm = 38.8249, GNorm = 0.0674, lr_0 = 1.0000e-04\n",
            "Validation rmse = 0.826338\n",
            "100%|██████████| 1000/1000 [03:47<00:00,  4.40it/s]\n",
            "Model 0 best validation rmse = 0.653701 on epoch 30\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"readout.1.weight\".\n",
            "Loading pretrained parameter \"readout.1.bias\".\n",
            "Loading pretrained parameter \"readout.4.weight\".\n",
            "Loading pretrained parameter \"readout.4.bias\".\n",
            "Moving model to cuda\n",
            "Model 0 test rmse = 0.992323         \n",
            "Ensemble test rmse = 0.992323\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 0.992323\n",
            "Overall test rmse = 0.992323 +/- 0.000000\n",
            "Elapsed time = 0:03:47\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'tests/data/regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_reg',\n",
        "    '--epochs', '1000',\n",
        "    '--save_smiles_splits'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('../data/B3DB/B3DB_classification.csv')\n",
        "\n",
        "df['BBB+/BBB-'] = df['BBB+/BBB-'].replace({'BBB+': 1, 'BBB-': 0})\n",
        "\n",
        "df.to_csv('../data/B3DB/B3DB_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating search space using parameters ['depth', 'dropout', 'ffn_num_layers', 'linked_hidden_size'].\n",
            "No manual trials loaded as part of hyperparameter search\n",
            "Initiating trial with seed 1\n",
            "Loaded 0 previous trials\n",
            "Parameters assigned with random search, 50 random trials remaining\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "\n",
            "python /opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/ipykernel_launcher.py --f=/home/nikolenko/.local/share/jupyter/runtime/kernel-v2-58492vrNaqGeFCDQr.json\n",
            "\n",
            "Args\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{'activation': 'ReLU',\n",
            " 'adding_bond_types': True,\n",
            " 'adding_h': True,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_constraints': [],\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'atom_targets': [],\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_constraints': [],\n",
            " 'bond_descriptor_scaling': True,\n",
            " 'bond_descriptors': None,\n",
            " 'bond_descriptors_path': None,\n",
            " 'bond_descriptors_size': 0,\n",
            " 'bond_features_size': 0,\n",
            " 'bond_targets': [],\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'config_save_path': 'B3DB/classification/hyperopt/best_hyperparams.json',\n",
            " 'constraints_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': True,\n",
            " 'data_path': '../data/B3DB/B3DB_classification.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'classification',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cuda'),\n",
            " 'dropout': 0.2,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 100,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 1400,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 1400,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'hyperopt_checkpoint_dir': 'B3DB/classification/hyperopt/hyperopt_logs',\n",
            " 'hyperopt_seed': 0,\n",
            " 'ignore_columns': None,\n",
            " 'ignore_nan_metrics': False,\n",
            " 'init_lr': 0.0001,\n",
            " 'is_atom_bond_targets': False,\n",
            " 'keeping_atom_map': False,\n",
            " 'linked_hidden_size': 1400,\n",
            " 'log_dir': 'B3DB/classification/hyperopt/hyperopt_logs',\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'binary_cross_entropy',\n",
            " 'manual_trial_dirs': None,\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'auc',\n",
            " 'metrics': ['auc'],\n",
            " 'minimize_score': False,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_adding_bond_types': False,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_descriptor_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'no_shared_atom_bond_ffn': False,\n",
            " 'num_folds': 1,\n",
            " 'num_iters': 100,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 16,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'B3DB/classification/hyperopt/hyperopt_checkpoints/trial_seed_1',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'search_parameter_keywords': ['basic'],\n",
            " 'search_parameters': ['depth',\n",
            "                       'dropout',\n",
            "                       'ffn_num_layers',\n",
            "                       'linked_hidden_size'],\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_descriptors_path': None,\n",
            " 'separate_test_constraints_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_descriptors_path': None,\n",
            " 'separate_val_constraints_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'shared_atom_bond_ffn': True,\n",
            " 'show_individual_scores': True,\n",
            " 'smiles_columns': ['SMILES'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'startup_random_iters': 50,\n",
            " 'target_columns': ['BBB+/BBB-'],\n",
            " 'target_weights': None,\n",
            " 'task_names': ['BBB+/BBB-'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0,\n",
            " 'weights_ffn_num_layers': 2}\n",
            "\n",
            "Setting molecule featurization parameters to default.\n",
            "\n",
            "Loading data\n",
            "\n",
            "0it [00:00, ?it/s]\n",
            "7807it [00:00, 145537.56it/s]\n",
            "  0%|          | 0/7807 [00:00<?, ?it/s]\n",
            "  5%|5         | 424/7807 [00:00<00:02, 3589.38it/s]\n",
            "100%|##########| 7807/7807 [00:00<00:00, 51145.57it/s]\n",
            "  0%|          | 0/7807 [00:00<?, ?it/s]\n",
            "  4%|4         | 324/7807 [00:00<00:02, 3236.95it/s]\n",
            " 10%|9         | 756/7807 [00:00<00:01, 3872.57it/s]\n",
            " 15%|#4        | 1148/7807 [00:00<00:01, 3893.56it/s]\n",
            " 20%|#9        | 1538/7807 [00:00<00:01, 3659.14it/s]\n",
            " 24%|##4       | 1906/7807 [00:00<00:01, 3603.69it/s]\n",
            " 29%|##9       | 2268/7807 [00:00<00:01, 3507.26it/s]\n",
            " 34%|###3      | 2652/7807 [00:00<00:01, 3608.42it/s]\n",
            " 39%|###8      | 3014/7807 [00:00<00:01, 3431.71it/s]\n",
            " 43%|####3     | 3360/7807 [00:00<00:01, 3360.16it/s]\n",
            " 47%|####7     | 3698/7807 [00:01<00:01, 3331.24it/s]\n",
            " 52%|#####2    | 4060/7807 [00:01<00:01, 3415.35it/s]\n",
            " 56%|#####6    | 4403/7807 [00:01<00:01, 3296.26it/s]\n",
            " 61%|######    | 4734/7807 [00:01<00:00, 3209.79it/s]\n",
            " 65%|######4   | 5057/7807 [00:01<00:00, 3026.82it/s]\n",
            " 69%|######9   | 5398/7807 [00:01<00:00, 3132.81it/s]\n",
            " 73%|#######3  | 5716/7807 [00:01<00:00, 3144.60it/s]\n",
            " 78%|#######7  | 6054/7807 [00:01<00:00, 3209.61it/s]\n",
            " 82%|########1 | 6377/7807 [00:01<00:00, 3085.32it/s]\n",
            " 86%|########5 | 6688/7807 [00:02<00:00, 3081.19it/s]\n",
            " 90%|########9 | 7006/7807 [00:02<00:00, 3108.20it/s]\n",
            " 94%|#########3| 7318/7807 [00:02<00:00, 3050.82it/s]\n",
            " 98%|#########7| 7624/7807 [00:02<00:00, 3051.94it/s]\n",
            "100%|##########| 7807/7807 [00:02<00:00, 3282.97it/s]\n",
            "Number of tasks = 1\n",
            "\n",
            "Fold 0\n",
            "\n",
            "Splitting data with seed 0\n",
            "\n",
            "Class sizes\n",
            "\n",
            "BBB+/BBB- 0: 36.52%, 1: 63.48%\n",
            "\n",
            "0it [00:00, ?it/s]\n",
            "7807it [00:00, 174964.37it/s]\n",
            "Total size = 7,807 | train size = 6,245 | val size = 781 | test size = 781\n",
            "\n",
            "Building model 0\n",
            "\n",
            "MoleculeModel(\n",
            "  (sigmoid): Sigmoid()\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=1400, bias=False)\n",
            "        (W_h): Linear(in_features=1400, out_features=1400, bias=False)\n",
            "        (W_o): Linear(in_features=1533, out_features=1400, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (readout): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=False)\n",
            "    (1): Linear(in_features=1400, out_features=1400, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): Linear(in_features=1400, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Number of parameters = 6,277,601\n",
            "\n",
            "Moving model to cuda\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:03<?, ?trial/s, best loss=?]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/nikolenko/work/chemprop/demo.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m hyperopt_arguments \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m--data_path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m../data/B3DB/B3DB_classification.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m--dataset_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m--search_parameter_keywords\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbasic\u001b[39m\u001b[39m'\u001b[39m  \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m args \u001b[39m=\u001b[39m HyperoptArgs()\u001b[39m.\u001b[39mparse_args(hyperopt_arguments)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bserv4/home/nikolenko/work/chemprop/demo.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m hyperopt(args)\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/utils.py:590\u001b[0m, in \u001b[0;36mtimeit.<locals>.timeit_decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    589\u001b[0m     start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 590\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    591\u001b[0m     delta \u001b[39m=\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mround\u001b[39m(time() \u001b[39m-\u001b[39m start_time))\n\u001b[1;32m    592\u001b[0m     info \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(logger_name)\u001b[39m.\u001b[39minfo \u001b[39mif\u001b[39;00m logger_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mprint\u001b[39m\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/hyperparameter_optimization.py:166\u001b[0m, in \u001b[0;36mhyperopt\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParameters assigned with TPE directed search\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m fmin(\n\u001b[1;32m    167\u001b[0m     fmin_objective,\n\u001b[1;32m    168\u001b[0m     space,\n\u001b[1;32m    169\u001b[0m     algo\u001b[39m=\u001b[39;49mpartial(tpe\u001b[39m.\u001b[39;49msuggest, n_startup_jobs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mstartup_random_iters),\n\u001b[1;32m    170\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(trials) \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    171\u001b[0m     trials\u001b[39m=\u001b[39;49mtrials,\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[39m# Create a trials object with only the last instance by merging the last data with an empty trials object\u001b[39;00m\n\u001b[1;32m    175\u001b[0m last_trial \u001b[39m=\u001b[39m merge_trials(Trials(), [trials\u001b[39m.\u001b[39mtrials[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/hyperparameter_optimization.py:100\u001b[0m, in \u001b[0;36mhyperopt.<locals>.objective\u001b[0;34m(hyperparams, seed)\u001b[0m\n\u001b[1;32m     97\u001b[0m     hyper_args\u001b[39m.\u001b[39mfinal_lr \u001b[39m=\u001b[39m hyperparams[\u001b[39m\"\u001b[39m\u001b[39mmax_lr\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m hyperparams[\u001b[39m\"\u001b[39m\u001b[39mfinal_lr_ratio\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     99\u001b[0m \u001b[39m# Cross validate\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m mean_score, std_score \u001b[39m=\u001b[39m cross_validate(args\u001b[39m=\u001b[39;49mhyper_args, train_func\u001b[39m=\u001b[39;49mrun_training)\n\u001b[1;32m    102\u001b[0m \u001b[39m# Record results\u001b[39;00m\n\u001b[1;32m    103\u001b[0m temp_model \u001b[39m=\u001b[39m MoleculeModel(hyper_args)\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/utils.py:590\u001b[0m, in \u001b[0;36mtimeit.<locals>.timeit_decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    589\u001b[0m     start_time \u001b[39m=\u001b[39m time()\n\u001b[0;32m--> 590\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    591\u001b[0m     delta \u001b[39m=\u001b[39m timedelta(seconds\u001b[39m=\u001b[39m\u001b[39mround\u001b[39m(time() \u001b[39m-\u001b[39m start_time))\n\u001b[1;32m    592\u001b[0m     info \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(logger_name)\u001b[39m.\u001b[39minfo \u001b[39mif\u001b[39;00m logger_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mprint\u001b[39m\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/train/cross_validate.py:119\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(args, train_func)\u001b[0m\n\u001b[1;32m    116\u001b[0m         model_scores \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    117\u001b[0m \u001b[39m# Otherwise, train the models\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     model_scores \u001b[39m=\u001b[39m train_func(args, data, logger)\n\u001b[1;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m metric, scores \u001b[39min\u001b[39;00m model_scores\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    122\u001b[0m     all_scores[metric]\u001b[39m.\u001b[39mappend(scores)\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/train/run_training.py:285\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(args, data, logger)\u001b[0m\n\u001b[1;32m    280\u001b[0m save_checkpoint(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir, MODEL_FILE_NAME), model, scaler,\n\u001b[1;32m    281\u001b[0m                 features_scaler, atom_descriptor_scaler, bond_descriptor_scaler,\n\u001b[1;32m    282\u001b[0m                 atom_bond_scaler, args)\n\u001b[1;32m    284\u001b[0m \u001b[39m# Optimizers\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m optimizer \u001b[39m=\u001b[39m build_optimizer(model, args)\n\u001b[1;32m    287\u001b[0m \u001b[39m# Learning rate schedulers\u001b[39;00m\n\u001b[1;32m    288\u001b[0m scheduler \u001b[39m=\u001b[39m build_lr_scheduler(optimizer, args)\n",
            "File \u001b[0;32m~/work/chemprop/chemprop/utils.py:499\u001b[0m, in \u001b[0;36mbuild_optimizer\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[39mBuilds a PyTorch Optimizer.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39m:return: An initialized Optimizer.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    497\u001b[0m params \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: model\u001b[39m.\u001b[39mparameters(), \u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: args\u001b[39m.\u001b[39minit_lr, \u001b[39m\"\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m}]\n\u001b[0;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m Adam(params)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{\u001b[39;00mweight_decay\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/optim/optimizer.py:278\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    275\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n\u001b[1;32m    277\u001b[0m \u001b[39mfor\u001b[39;00m param_group \u001b[39min\u001b[39;00m param_groups:\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_param_group(cast(\u001b[39mdict\u001b[39;49m, param_group))\n\u001b[1;32m    280\u001b[0m \u001b[39m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dynamo\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mdisable(fn, recursive)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcode_context\u001b[39;00m \u001b[39mimport\u001b[39;00m code_context\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:45\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbytecode_transformation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[1;32m     34\u001b[0m     Instruction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     transform_code_object,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcache_size\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     CacheSizeRelevantForFrame,\n\u001b[1;32m     41\u001b[0m     compute_cache_size,\n\u001b[1;32m     42\u001b[0m     exceeds_cache_size_limit,\n\u001b[1;32m     43\u001b[0m     is_recompilation,\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39meval_frame\u001b[39;00m \u001b[39mimport\u001b[39;00m always_optimize_code_objects, skip_code, TorchPatcher\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     augment_exc_message,\n\u001b[1;32m     48\u001b[0m     BackendCompilerFailed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     Unsupported,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mguards\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[1;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[1;32m     59\u001b[0m     GuardedCode,\n\u001b[1;32m     60\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:69\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[39mglobals\u001b[39m()[name] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39meval_frame, name)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config, convert_frame, external_utils, skipfiles, utils\n\u001b[1;32m     70\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcode_context\u001b[39;00m \u001b[39mimport\u001b[39;00m code_context\n\u001b[1;32m     71\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexc\u001b[39;00m \u001b[39mimport\u001b[39;00m CondOpArgsMismatchError, UserError, UserErrorType\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/skipfiles.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_content_store\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m getfile\n\u001b[0;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     41\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     42\u001b[0m     UserMethodVariable,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mA note on skipfiles:\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39myou don't want to inline them.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m BUILTIN_SKIPLIST \u001b[39m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m     abc,\n\u001b[1;32m     92\u001b[0m     collections,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     _weakrefset,\n\u001b[1;32m    122\u001b[0m )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/variables/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m VariableTracker\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbuiltin\u001b[39;00m \u001b[39mimport\u001b[39;00m BuiltinVariable\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/variables/base.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcurrent_scope_id\u001b[39;00m \u001b[39mimport\u001b[39;00m current_scope_id\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexc\u001b[39;00m \u001b[39mimport\u001b[39;00m unimplemented\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msource\u001b[39;00m \u001b[39mimport\u001b[39;00m AttrSource, Source\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m identity, istype\n\u001b[1;32m     12\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMutableLocalSource\u001b[39;00m(Enum):\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/site-packages/torch/_dynamo/source.py:245\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    240\u001b[0m         \u001b[39m# NB: use method call so that function stripping regexes work\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mname()\u001b[39m}\u001b[39;00m\u001b[39m.__neg__()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m \u001b[39m@dataclasses\u001b[39;49m\u001b[39m.\u001b[39;49mdataclass(frozen\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m--> 245\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mConvertIntSource\u001b[39;49;00m(ChainedSource):\n\u001b[1;32m    246\u001b[0m     \u001b[39mdef\u001b[39;49;00m \u001b[39m__post_init__\u001b[39;49m(\u001b[39mself\u001b[39;49m):\n\u001b[1;32m    247\u001b[0m         \u001b[39massert\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/dataclasses.py:1011\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[39mreturn\u001b[39;00m _process_class(\u001b[39mcls\u001b[39;49m, init, \u001b[39mrepr\u001b[39;49m, eq, order, unsafe_hash, frozen)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/dataclasses.py:973\u001b[0m, in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot overwrite attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    969\u001b[0m                             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39min class \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. Consider using \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    970\u001b[0m                             \u001b[39m'\u001b[39m\u001b[39mfunctools.total_ordering\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    972\u001b[0m \u001b[39mif\u001b[39;00m frozen:\n\u001b[0;32m--> 973\u001b[0m     \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m _frozen_get_del_attr(\u001b[39mcls\u001b[39;49m, field_list, \u001b[39mglobals\u001b[39;49m):\n\u001b[1;32m    974\u001b[0m         \u001b[39mif\u001b[39;00m _set_new_attribute(\u001b[39mcls\u001b[39m, fn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, fn):\n\u001b[1;32m    975\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot overwrite attribute \u001b[39m\u001b[39m{\u001b[39;00mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    976\u001b[0m                             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39min class \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/dataclasses.py:563\u001b[0m, in \u001b[0;36m_frozen_get_del_attr\u001b[0;34m(cls, fields, globals)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[39m# Special case for the zero-length tuple.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     fields_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m()\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    556\u001b[0m \u001b[39mreturn\u001b[39;00m (_create_fn(\u001b[39m'\u001b[39m\u001b[39m__setattr__\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    557\u001b[0m                   (\u001b[39m'\u001b[39m\u001b[39mself\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    558\u001b[0m                   (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mif type(self) is cls or name in \u001b[39m\u001b[39m{\u001b[39;00mfields_str\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    559\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m raise FrozenInstanceError(f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot assign to field \u001b[39m\u001b[39m{name!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    560\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msuper(cls, self).__setattr__(name, value)\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m    561\u001b[0m                    \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlocals\u001b[39m,\n\u001b[1;32m    562\u001b[0m                    \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mglobals\u001b[39m),\n\u001b[0;32m--> 563\u001b[0m         _create_fn(\u001b[39m'\u001b[39;49m\u001b[39m__delattr__\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    564\u001b[0m                   (\u001b[39m'\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    565\u001b[0m                   (\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mif type(self) is cls or name in \u001b[39;49m\u001b[39m{\u001b[39;49;00mfields_str\u001b[39m}\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    566\u001b[0m                     \u001b[39m'\u001b[39;49m\u001b[39m raise FrozenInstanceError(f\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcannot delete field \u001b[39;49m\u001b[39m{name!r}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m)\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    567\u001b[0m                    \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msuper(cls, self).__delattr__(name)\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m    568\u001b[0m                    \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m,\n\u001b[1;32m    569\u001b[0m                    \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m),\n\u001b[1;32m    570\u001b[0m         )\n",
            "File \u001b[0;32m/opt/anaconda3/envs/chemprop/lib/python3.8/dataclasses.py:398\u001b[0m, in \u001b[0;36m_create_fn\u001b[0;34m(name, args, body, globals, locals, return_type)\u001b[0m\n\u001b[1;32m    395\u001b[0m txt \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdef __create_fn__(\u001b[39m\u001b[39m{\u001b[39;00mlocal_vars\u001b[39m}\u001b[39;00m\u001b[39m):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mtxt\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m return \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    397\u001b[0m ns \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 398\u001b[0m exec(txt, \u001b[39mglobals\u001b[39;49m, ns)\n\u001b[1;32m    399\u001b[0m \u001b[39mreturn\u001b[39;00m ns[\u001b[39m'\u001b[39m\u001b[39m__create_fn__\u001b[39m\u001b[39m'\u001b[39m](\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mlocals\u001b[39m)\n",
            "File \u001b[0;32m<string>:1\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from chemprop.args import HyperoptArgs\n",
        "from chemprop.hyperparameter_optimization import hyperopt, chemprop_hyperopt\n",
        "\n",
        "\n",
        "hyperopt_arguments = [\n",
        "    '--data_path', '../data/B3DB/B3DB_classification.csv',\n",
        "    '--dataset_type', 'classification',\n",
        "    '--config_save_path', 'B3DB/classification/hyperopt/best_hyperparams.json',  \n",
        "    '--log_dir', 'B3DB/classification/hyperopt/hyperopt_logs', \n",
        "    '--save_dir', 'B3DB/classification/hyperopt/hyperopt_checkpoints',  \n",
        "    '--smiles_columns', 'SMILES',\n",
        "    '--target_columns', 'BBB+/BBB-',\n",
        "    '--epochs', '100',\n",
        "    '--save_smiles_splits',\n",
        "    '--adding_h',\n",
        "    '--show_individual_scores',\n",
        "    '--num_iters', '100',\n",
        "    '--search_parameter_keywords', 'basic'  \n",
        "]\n",
        "args = HyperoptArgs().parse_args(hyperopt_arguments)\n",
        "\n",
        "hyperopt(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZktZ7DsAAMn"
      },
      "source": [
        "# Predict from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a1-7UXcJCss",
        "outputId": "b9051fd3-0738-4b33-94bd-1125c79ba9f2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [00:00, 303495.22it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 196362.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"readout.1.weight\".\n",
            "Loading pretrained parameter \"readout.1.bias\".\n",
            "Loading pretrained parameter \"readout.4.weight\".\n",
            "Loading pretrained parameter \"readout.4.bias\".\n",
            "Moving model to cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_reg.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_reg/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_reg.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_reg'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j-4hbBeerlX0",
        "outputId": "675ef2dd-4bb6-4772-d5a3-e1837dfbdf5b",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smiles</th>\n",
              "      <th>logSolubility</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C/C1CCC(\\C)CC1</td>\n",
              "      <td>-4.47</td>\n",
              "      <td>-3.579554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1</td>\n",
              "      <td>-6.01</td>\n",
              "      <td>-4.636861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c1c(Br)ccc2ccccc12</td>\n",
              "      <td>-4.40</td>\n",
              "      <td>-4.427271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3</td>\n",
              "      <td>-8.60</td>\n",
              "      <td>-4.067773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2</td>\n",
              "      <td>-2.17</td>\n",
              "      <td>-2.282860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       smiles  logSolubility     preds\n",
              "0                              C/C1CCC(\\C)CC1          -4.47 -3.579554\n",
              "1   Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1          -6.01 -4.636861\n",
              "2                          c1c(Br)ccc2ccccc12          -4.40 -4.427271\n",
              "3  CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3          -8.60 -4.067773\n",
              "4             CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2          -2.17 -2.282860"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('test_checkpoints_reg/fold_0/test_full.csv')\n",
        "df['preds'] = [x[0] for x in preds]\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "hj726FiKqj4q",
        "outputId": "73391e45-cf2d-476e-9b22-beed9149e6d1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_parity(df.logSolubility, df.preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE9Tof7UK8cI"
      },
      "source": [
        "# Predict from SMILES list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kswx6y_uJHqW",
        "outputId": "eb7872f0-b290-411e-ea0a-09ceeff2900a",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "Validating SMILES\n",
            "Test size = 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"readout.1.weight\".\n",
            "Loading pretrained parameter \"readout.1.bias\".\n",
            "Loading pretrained parameter \"readout.4.weight\".\n",
            "Loading pretrained parameter \"readout.4.bias\".\n",
            "Moving model to cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to /dev/null\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "smiles = [['CCC'], ['CCCC'], ['OCC']]\n",
        "arguments = [\n",
        "    '--test_path', '/dev/null',\n",
        "    '--preds_path', '/dev/null',\n",
        "    '--checkpoint_dir', 'test_checkpoints_reg'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args, smiles=smiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54x-eGwxLEZ1"
      },
      "source": [
        "# Load model once, predict multiple times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICmfelGD7rcf",
        "outputId": "b4f6712f-615c-413f-aa76-71bb646fbc5c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"readout.1.weight\".\n",
            "Loading pretrained parameter \"readout.1.bias\".\n",
            "Loading pretrained parameter \"readout.4.weight\".\n",
            "Loading pretrained parameter \"readout.4.bias\".\n",
            "Moving model to cuda\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "Validating SMILES\n",
            "Test size = 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to /dev/null\n",
            "Elapsed time = 0:00:00\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "Validating SMILES\n",
            "Test size = 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to /dev/null\n",
            "Elapsed time = 0:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', '/dev/null',\n",
        "    '--preds_path', '/dev/null',\n",
        "    '--checkpoint_dir', 'test_checkpoints_reg'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "\n",
        "model_objects = chemprop.train.load_model(args=args)\n",
        "\n",
        "smiles = [['CCC'], ['CCCC'], ['OCC']]\n",
        "preds = chemprop.train.make_predictions(args=args, smiles=smiles, model_objects=model_objects)\n",
        "\n",
        "smiles = [['CCCC'], ['CCCCC'], ['COCC']]\n",
        "preds = chemprop.train.make_predictions(args=args, smiles=smiles, model_objects=model_objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jCqwGfYqj4w"
      },
      "source": [
        "# Reactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6RltQMn8qj4w",
        "outputId": "3e35a007-d79f-40ea-b906-b44e704f51dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e85a3a6-c974-41a2-a294-de8924b78e96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAM</th>\n",
              "      <th>ea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[O:1]([C:2]([C:3]([C:4](=[O:5])[C:6]([O:7][H:1...</td>\n",
              "      <td>8.898934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C@@:...</td>\n",
              "      <td>5.464328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[C@@:3]2([H:12])[C:4]([H...</td>\n",
              "      <td>5.270552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[C:1]([O:2][C:3]([C@@:4]([C:5]([H:14])([H:15])...</td>\n",
              "      <td>8.473006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[C:1]([C:2]#[C:3][C:4]([C:5](=[O:6])[H:12])([H...</td>\n",
              "      <td>5.579037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>[C:1]([c:2]1[c:3]([H:10])[n:4]([H:11])[n:5][c:...</td>\n",
              "      <td>14.662005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[N:3]([H:12])[C@:4]1([C:...</td>\n",
              "      <td>5.146017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...</td>\n",
              "      <td>8.362688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>[C:1]([c:2]1[c:3]([H:11])[o:4][c:5]([O:6][H:12...</td>\n",
              "      <td>12.416359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>[N:1]([c:2]1[c:3]([O:4][H:10])[n:5]([H:11])[c:...</td>\n",
              "      <td>7.785556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e85a3a6-c974-41a2-a294-de8924b78e96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e85a3a6-c974-41a2-a294-de8924b78e96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e85a3a6-c974-41a2-a294-de8924b78e96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   AAM         ea\n",
              "0    [O:1]([C:2]([C:3]([C:4](=[O:5])[C:6]([O:7][H:1...   8.898934\n",
              "1    [C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C@@:...   5.464328\n",
              "2    [C:1]([C@@:2]1([H:11])[C@@:3]2([H:12])[C:4]([H...   5.270552\n",
              "3    [C:1]([O:2][C:3]([C@@:4]([C:5]([H:14])([H:15])...   8.473006\n",
              "4    [C:1]([C:2]#[C:3][C:4]([C:5](=[O:6])[H:12])([H...   5.579037\n",
              "..                                                 ...        ...\n",
              "495  [C:1]([c:2]1[c:3]([H:10])[n:4]([H:11])[n:5][c:...  14.662005\n",
              "496  [C:1]([C@@:2]1([H:11])[N:3]([H:12])[C@:4]1([C:...   5.146017\n",
              "497  [C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...   8.362688\n",
              "498  [C:1]([c:2]1[c:3]([H:11])[o:4][c:5]([O:6][H:12...  12.416359\n",
              "499  [N:1]([c:2]1[c:3]([O:4][H:10])[n:5]([H:11])[c:...   7.785556\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reaction_reg_df = pd.read_csv('data/reaction_regression.csv')\n",
        "reaction_reg_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faZ5arGiqj4w",
        "outputId": "9c111207-8d8a-439c-cbad-1b0494d711a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/reaction_regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': True,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_reaction',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['AAM'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['ea'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 47996.34it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 127968.76it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 7069.00it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "500it [00:00, 63780.06it/s]\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  7.57it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00,  7.45it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00,  7.91it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  7.87it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  8.06it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  8.04it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:00<00:00,  8.07it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:01<00:00,  8.12it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.271719\n",
            " 20%|██        | 1/5 [00:01<00:05,  1.33s/it]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 7.7459e-01, PNorm = 34.6705, GNorm = 6.2133, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 10.25it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  9.73it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  9.57it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  8.95it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00,  9.80it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.165562\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.23s/it]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 12.25it/s]\u001b[ALoss = 8.0665e-01, PNorm = 34.7094, GNorm = 10.4500, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.38it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 10.69it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 10.33it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.293178\n",
            " 60%|██████    | 3/5 [00:03<00:02,  1.09s/it]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:01,  6.24it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00,  6.36it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00,  6.23it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  6.40it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  6.83it/s]\u001b[ALoss = 7.1648e-01, PNorm = 34.7282, GNorm = 2.6230, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  5.82it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:01<00:00,  5.71it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:01<00:00,  5.45it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\u001b[A\n",
            "                                             \u001b[AValidation rmse = 2.401798\n",
            " 80%|████████  | 4/5 [00:04<00:01,  1.28s/it]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:01,  4.01it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:01,  3.85it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:01,  3.94it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:01<00:01,  3.89it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:01<00:00,  4.14it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:01<00:00,  4.27it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:01<00:00,  5.10it/s]\u001b[ALoss = 6.5946e-01, PNorm = 34.7339, GNorm = 4.1201, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:01<00:00,  5.93it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.034656\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.40s/it]\n",
            "Model 0 best validation rmse = 2.034656 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test rmse = 1.969818\n",
            "Ensemble test rmse = 1.969818\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 1.969818\n",
            "Overall test rmse = 1.969818 +/- 0.000000\n",
            "Elapsed time = 0:00:08\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/reaction_regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_reaction',\n",
        "    '--epochs', '5',\n",
        "    '--reaction',\n",
        "    '--save_smiles_splits'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0uWRx5Zqj4w",
        "outputId": "156d4da5-3c18-4f6a-f127-4c7485f8ed0d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [00:00, 72666.39it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 73558.47it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_reaction.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_reaction/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_reaction.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_reaction'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "0jAsBzayqj4w",
        "outputId": "55660ec8-a9f0-4220-bd17-6a2255cf67a1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('test_checkpoints_reaction/fold_0/test_full.csv')\n",
        "df['preds'] = [x[0] for x in preds]\n",
        "\n",
        "plot_parity(df.ea, df.preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROjlinX0qj4x"
      },
      "source": [
        "# Multiple-Molecule Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1dc99YcRqj4x",
        "outputId": "e0d08eb1-2b48-4204-d4b8-1a2a9ba760ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b989578-f25c-4c4e-9779-0d7604f488c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mol a smiles</th>\n",
              "      <th>mol b Smiles</th>\n",
              "      <th>synergy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(C)CC1C(=O)NC(C(=O)NC(C(=O)NC(C(=O)NCCC(C(=O...</td>\n",
              "      <td>CC1(C(N2C(S1)C(C2=O)NC(=O)C(C3=CC=C(C=C3)O)N)C...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...</td>\n",
              "      <td>CC(C1CCC(C(O1)OC2C(CC(C(C2O)OC3C(C(C(CO3)(C)O)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...</td>\n",
              "      <td>CC(C)(C(=O)O)ON=C(C1=CSC(=N1)N)C(=O)NC2C3N(C2=...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...</td>\n",
              "      <td>CC(C)(C)NCC(=O)NC1=CC(=C2CC3CC4C(C(=O)C(=C(C4(...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C[C@H]([C@H]1C(=O)NCC[C@@H](C(=O)N[C@H](C(=O)N...</td>\n",
              "      <td>CN1C(=NC(=O)C(=O)N1)SCC2=C(N3C(C(C3=O)NC(=O)C(...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>CC(C)CC1C(=O)NC(C(=O)N2CCCC2C(=O)NC(C(=O)NC(C(...</td>\n",
              "      <td>[N+](=O)([O-])[O-].[Ag+]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...</td>\n",
              "      <td>C1=CC=C2C(=C1)C=CN2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>CC(C)CC1C(=O)NC(C(=O)NC(C(=O)NC(C(=O)NCCC(C(=O...</td>\n",
              "      <td>CC1C2C(C(=O)N2C(=C1SC3CC(NC3)C(=O)N(C)C)C(=O)O...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>CCOP(=O)(O)OP(=O)(O)O</td>\n",
              "      <td>C1=CC(=CC=C1C(C(CO)NC(=O)C(Cl)Cl)O)[N+](=O)[O-]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...</td>\n",
              "      <td>C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)O)O)OC3C(C(...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>259 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b989578-f25c-4c4e-9779-0d7604f488c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b989578-f25c-4c4e-9779-0d7604f488c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b989578-f25c-4c4e-9779-0d7604f488c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          mol a smiles  \\\n",
              "0    CC(C)CC1C(=O)NC(C(=O)NC(C(=O)NC(C(=O)NCCC(C(=O...   \n",
              "1    CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...   \n",
              "2    CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...   \n",
              "3    CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...   \n",
              "4    C[C@H]([C@H]1C(=O)NCC[C@@H](C(=O)N[C@H](C(=O)N...   \n",
              "..                                                 ...   \n",
              "254  CC(C)CC1C(=O)NC(C(=O)N2CCCC2C(=O)NC(C(=O)NC(C(...   \n",
              "255  CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...   \n",
              "256  CC(C)CC1C(=O)NC(C(=O)NC(C(=O)NC(C(=O)NCCC(C(=O...   \n",
              "257                              CCOP(=O)(O)OP(=O)(O)O   \n",
              "258  CCC(C)CCCC(=O)NC(CCN)C(=O)NC(C(C)O)C(=O)NC(CCN...   \n",
              "\n",
              "                                          mol b Smiles  synergy  \n",
              "0    CC1(C(N2C(S1)C(C2=O)NC(=O)C(C3=CC=C(C=C3)O)N)C...        1  \n",
              "1    CC(C1CCC(C(O1)OC2C(CC(C(C2O)OC3C(C(C(CO3)(C)O)...        0  \n",
              "2    CC(C)(C(=O)O)ON=C(C1=CSC(=N1)N)C(=O)NC2C3N(C2=...        0  \n",
              "3    CC(C)(C)NCC(=O)NC1=CC(=C2CC3CC4C(C(=O)C(=C(C4(...        1  \n",
              "4    CN1C(=NC(=O)C(=O)N1)SCC2=C(N3C(C(C3=O)NC(=O)C(...        1  \n",
              "..                                                 ...      ...  \n",
              "254                           [N+](=O)([O-])[O-].[Ag+]        0  \n",
              "255                                C1=CC=C2C(=C1)C=CN2        1  \n",
              "256  CC1C2C(C(=O)N2C(=C1SC3CC(NC3)C(=O)N(C)C)C(=O)O...        1  \n",
              "257    C1=CC(=CC=C1C(C(CO)NC(=O)C(Cl)Cl)O)[N+](=O)[O-]        1  \n",
              "258  C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)O)O)OC3C(C(...        1  \n",
              "\n",
              "[259 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multimolecule_df = pd.read_csv('data/classification_multimolecule.csv')\n",
        "multimolecule_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPRnEIzpqj4x",
        "outputId": "2538e992-2b00-4799-d02e-dde236a318e7",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/classification_multimolecule.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'classification',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'binary_cross_entropy',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'auc',\n",
            " 'metrics': ['auc'],\n",
            " 'minimize_score': False,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 2,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_multimolecule',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['mol a smiles', 'mol b Smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 1,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['synergy'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "259it [00:00, 27657.33it/s]\n",
            "100%|██████████| 259/259 [00:00<00:00, 71313.91it/s]\n",
            "100%|██████████| 259/259 [00:00<00:00, 2577.63it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "Class sizes\n",
            "synergy 0: 40.93%, 1: 59.07%\n",
            "0it [00:00, ?it/s]Warning: Repeated SMILES found in data, pickle file of split indices cannot distinguish entries and will not be generated.\n",
            "15it [00:00, 3696.94it/s]\n",
            "Total size = 259 | train size = 207 | val size = 26 | test size = 26\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (sigmoid): Sigmoid()\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "      (1): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=600, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 709,801\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:06,  1.71s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:02<00:04,  1.39s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:04<00:02,  1.29s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:05<00:01,  1.35s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.06it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\u001b[A\n",
            "                                             \u001b[AValidation auc = 0.606250\n",
            " 20%|██        | 1/5 [00:06<00:25,  6.42s/it]Epoch 1\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.12s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:03<00:05,  1.91s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:05<00:03,  1.57s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:06<00:01,  1.62s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.08s/it]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\u001b[A\n",
            "                                             \u001b[AValidation auc = 0.525000\n",
            " 40%|████      | 2/5 [00:13<00:20,  6.79s/it]Epoch 2\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.74it/s]\u001b[ALoss = 6.6435e-01, PNorm = 45.8623, GNorm = 1.1497, lr_0 = 3.8312e-04\n",
            "\n",
            " 40%|████      | 2/5 [00:01<00:01,  1.64it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:01<00:01,  1.60it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.63it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.32it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\u001b[A\n",
            "                                             \u001b[AValidation auc = 0.525000\n",
            " 60%|██████    | 3/5 [00:16<00:09,  4.94s/it]Epoch 3\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.63it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:01<00:01,  1.61it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:01<00:01,  1.63it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.65it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\u001b[A\n",
            "                                             \u001b[AValidation auc = 0.543750\n",
            " 80%|████████  | 4/5 [00:18<00:04,  4.07s/it]Epoch 4\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.65it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.44it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.27it/s]\u001b[ALoss = 6.1639e-01, PNorm = 45.8728, GNorm = 0.7998, lr_0 = 1.0000e-04\n",
            "\n",
            " 80%|████████  | 4/5 [00:03<00:00,  1.17it/s]\u001b[ALoss = 5.9861e-01, PNorm = 45.8732, GNorm = 1.6586, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.66it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\u001b[A\n",
            "                                             \u001b[AValidation auc = 0.543750\n",
            "100%|██████████| 5/5 [00:22<00:00,  4.52s/it]\n",
            "Model 0 best validation auc = 0.606250 on epoch 0\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test auc = 0.709091\n",
            "Ensemble test auc = 0.709091\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test auc = 0.709091\n",
            "Overall test auc = 0.709091 +/- 0.000000\n",
            "Elapsed time = 0:00:24\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/classification_multimolecule.csv',\n",
        "    '--dataset_type', 'classification',\n",
        "    '--save_dir', 'test_checkpoints_multimolecule',\n",
        "    '--epochs', '5',\n",
        "    '--save_smiles_splits',\n",
        "    '--number_of_molecules', '2',\n",
        "    '--split_key_molecule', '1' # defaults to 0 (1st column) if not specified\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug8U-ZdIqj4x",
        "outputId": "1f85c393-07da-4b87-da23-d8aaad59a9cb",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "26it [00:00, 60282.98it/s]\n",
            "100%|██████████| 26/26 [00:00<00:00, 65183.45it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.1.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_multimolecule.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_multimolecule/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_multimolecule.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_multimolecule',\n",
        "    '--number_of_molecules', '2',\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra4xqKLHqj4x"
      },
      "source": [
        "# Split Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTlgNjW1qj4x",
        "outputId": "5539ae3e-a2c9-4116-8886-b99cf533b539"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_splits',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'scaffold_balanced',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['logSolubility'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 72220.95it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 111107.39it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 67641.34it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "100%|██████████| 500/500 [00:00<00:00, 8980.61it/s]\n",
            "Total scaffolds = 148 | train scaffolds = 85 | val scaffolds = 37 | test scaffolds = 26\n",
            "Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:\n",
            "Scaffold 0\n",
            "Task 0: count = 134 | target average = -1.964269\n",
            "\n",
            "\n",
            "Scaffold 1\n",
            "Task 0: count = 121 | target average = -2.929471\n",
            "\n",
            "\n",
            "Scaffold 2\n",
            "Task 0: count = 17 | target average = -6.661176\n",
            "\n",
            "\n",
            "Scaffold 3\n",
            "Task 0: count = 12 | target average = -3.795000\n",
            "\n",
            "\n",
            "Scaffold 4\n",
            "Task 0: count = 9 | target average = -2.160778\n",
            "\n",
            "\n",
            "Scaffold 5\n",
            "Task 0: count = 8 | target average = -4.232875\n",
            "\n",
            "\n",
            "Scaffold 6\n",
            "Task 0: count = 6 | target average = -3.096667\n",
            "\n",
            "\n",
            "Scaffold 7\n",
            "Task 0: count = 5 | target average = -3.716800\n",
            "\n",
            "\n",
            "Scaffold 8\n",
            "Task 0: count = 5 | target average = -5.497000\n",
            "\n",
            "\n",
            "Scaffold 9\n",
            "Task 0: count = 4 | target average = -5.857500\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]Warning: Repeated SMILES found in data, pickle file of split indices cannot distinguish entries and will not be generated.\n",
            "276it [00:00, 95838.06it/s]\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 355,201\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  8.49it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 10.82it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00, 11.34it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:00<00:00, 11.08it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.382019\n",
            " 20%|██        | 1/5 [00:00<00:03,  1.12it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 7.9258e-01, PNorm = 34.0217, GNorm = 5.8172, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.97it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.43it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.70it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.55it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.269503\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.14it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 12.46it/s]\u001b[ALoss = 6.3368e-01, PNorm = 34.0699, GNorm = 2.3689, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.27it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.26it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.28it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.918212\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.14it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.59it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.60it/s]\u001b[ALoss = 4.3541e-01, PNorm = 34.0942, GNorm = 3.4748, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.25it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.50it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.776913\n",
            " 80%|████████  | 4/5 [00:03<00:00,  1.15it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 12.33it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.76it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.46it/s]\u001b[ALoss = 3.7779e-01, PNorm = 34.1045, GNorm = 2.0184, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.25it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.774567\n",
            "100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n",
            "Model 0 best validation rmse = 1.774567 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test rmse = 1.813285\n",
            "Ensemble test rmse = 1.813285\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 1.813285\n",
            "Overall test rmse = 1.813285 +/- 0.000000\n",
            "Elapsed time = 0:00:05\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_splits',\n",
        "    '--epochs', '5',\n",
        "    '--split_type', 'scaffold_balanced',\n",
        "    '--save_smiles_splits'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6d_mNCkqj4x",
        "outputId": "f402d75e-74ad-4a07-f7f9-31267be466b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [00:00, 74552.15it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 84870.58it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_splits.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_splits/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_splits.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_splits',\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wyzQ_o50qj4x",
        "outputId": "c601e3fe-b322-42a9-b8b0-689cc7a9d538"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAEJCAYAAACOg3IeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bX48e/KxBBBZKyAAipYZAoYVMRKmRRygQKKwFWxYou3tQVEf7WKWnzUqlesV1qsonXsfRIcaPVWpU5orQIymCAi8yDgwKSwyUBIsn5/nHNiEk5OTs60z7A+z7Of5Ex7r5wk67x7vcMWVcUYY4KV5nYAxpjEYknDGNMoljSMMY1iScMY0yiWNIwxjWJJwxjTKK4lDRE5TUSWicgGEflMRGa5FYsxJnji1jgNETkVOFVV14pIC2ANMF5VN7gSkDEmKBluHVhVvwK+8n7viMjnQCeg3qTRtm1b7dq1a2wCNCaFVFVVsXnzZoqLiw+oartAz3UtadQkIl2B/sBKP4/NAGYAnH766axevTqmsRmT7BzHYfTo0ZSVlQHsauj5rhdCReQk4GVgtqoeqfu4qi5S1VxVzW3XLmACNMY0ki9hrFixgvz8/KBe42rSEJFMPAnjf1V1iZuxGJOKrrzyyuqEMWnSpKBe42YhVIBngUOqOjuY1+Tm5qqdnhgTOZ988gnbt2/nsssuA0BE1qhqbqDXuNnSGAxcDQwTkULvltfYnezZs4eBAweSnp6OiNhWY0tPT2fgwIHs2bMn8r89k7Acx+GZZ54BoH///tUJI1iuJQ1V/beqiqr2VdUc7/Z6Y/czYcIEJk6cSGlpKapqW42ttLSUCRMmMGHChGj8Ck0C8tUwfvazn/H555+HtA/XTk9C4e/0JD09ndLSUrKyslyKKr6Vl5fTrFkzKisr3Q7FuKxm0bOgoIDLL7/8hOfE++lJRFRVVVnCCCArK4uqqiq3wzAuCyZhBCvhk4YxpmHvv/8+q1atCjthQJImDRHhqquuqr5dUVFBu3btGDNmTK3njR8/ngsuuKDWffPmzaNTp07k5ORUb999911Y8bz44ov06tWLtLS0egenlZWVcd5559GvXz969erF7373u+rHVJW5c+fSo0cPevbsyYIFC8KKx6QOX/lhzJgxbN26NeyEAUmaNLKzs1m/fj2lpaUAvPXWW3Tq1KnWc7777jvWrFnD4cOH2b59e63HbrzxRgoLC6u3Vq1ahRVP7969WbJkCRdffHG9z2nSpAnvvvsuRUVFFBYWsnTpUlasWAHAM888w+7du9m4cSOff/45U6ZMCSsekxocx2HkyJEsXboUgNNOOy0i+03KpAGQl5fHa6+9BkB+fj5Tp06t9fiSJUsYO3YsU6ZMoaCgIKqx9OzZk7PPPjvgc0SEk046CYDjx49z/PhxPENZ4M9//jN33nknaWmeX1f79u2jGq9JfL4axnvvvcfRo0cjuu+kTRq+ZFBWVsa6des4//zzaz3uSyRTp049Yfjsww8/XH1qMnTo0BP27ThOrdOXmtuGDaFP0q2srCQnJ4f27dszcuTI6pi3bdvG4sWLyc3NZfTo0WzZsiXkY5jkF8mipz9xMWEtGvr27cvOnTvJz88nL6/2mLFvvvmGLVu2cNFFFyEiZGZmsn79enr37g14Tk9uvvnmevfdokULCgsLIx5zeno6hYWFfPfdd0yYMKE6pmPHjtG0aVNWr17NkiVLmD59Oh988EHEj28SX0lJSVQTBiRxSwNg3Lhx3HzzzSecmrzwwgt8++23dOvWja5du1Ynl2BFq6Xh06pVK4YOHVp9Ltq5c2cmTpwIeAazrVu3LuxjmOTUtGlT+vXrF7WEAUnc0gCYPn06rVq1ok+fPrz33nvV9+fn57N06VIGDRoEwI4dOxgxYgT33ntvUPuNRktj//79ZGZm0qpVK0pLS3nrrbe45ZZbAE8vz7Jly+jWrRvvv/8+PXr0iOixTeJzHIdDhw7RpUsXFi5cGN2DuT3UuTHbueeeq3V5foTasrOzT7hv2bJl+h//8R+6Y8cO7dixo1ZVVdV6vH///rpixQr93e9+px07dtR+/fpVbzt27Dhhf42xZMkS7dSpk2ZlZWn79u31kksuUVXVvXv36ujRo1VVtaioSHNycrRPnz7aq1cvveuuu6pf/+2332peXp727t1bL7jgAi0sLGzU8f29RyZ5HDlyRAcPHqxnnnmmlpWVhbUvYLU28H+Y8MPIRYRE+hncYO9R8op00TMlhpEbk6qi3UtSH0saxiSoW2+9NeYJA5K8EGpMMrvnnnsYO3Ysl156aUyPm5QtjfT0dHJycujduzdjx46tnjuyc+dORITbb7+9+rkHDhwgMzOTX/3qVwBs2rSJH//4x+Tk5NCzZ09mzJgBwHvvvcfJJ59cq3v17bffDivOjRs3MmjQIJo0acL8+fPrfd4777zDgAEDyMnJ4aKLLmLr1q0A/Otf/2LAgAFkZGTw0ksvhRWLSQyO43DLLbdQWlpKq1atYp4wgOTvPZk2bZrec889qqq6Y8cO7datm+bk5FQ//uijj2q/fv30hhtuUFXVSy65RP/+979XP75u3TpV/b73JZK++eYb/fjjj/W2227TBx98sN7nde/eXTds2KCqqgsXLtRrrrmm+ucpKirSq6++Wl988cV6X+/vPTKJ58iRI3rRRRdpenq6vvvuu1E5BkH0niRlS6OmQYMGsXfv3urbzZs3p2fPntWzTRcvXswVV1xR/fhXX31F586dq2/36dMnarG1b9+egQMHkpmZGfB5IsKRI56F2g8fPkzHjh0B6Nq1K3379q2ek2KSl+M45OXlsXz5cgoKCvxOb4iVpK5pVFZW8s4773DdddfVut83L6VDhw6kp6fTsWNHvvzyS8AzhHzYsGFceOGFXHLJJVx77bXVs1w/+OADcnJyqvfz8ssvc+aZZ9ba9+TJk9m0adMJscyZM4dp06aF9HM8+eST5OXl0axZM1q2bFk9+9WkhroJI5ZFT3+SMmmUlpaSk5PD3r176dmzJyNHjqz1+KhRo7jjjjvo0KEDkydPrvXYtddey6WXXsrSpUt55ZVXePzxxykqKgLgRz/6Ef/4xz8CHnvx4sWR/WHwTKB7/fXXOf/883nwwQeZM2cOTz75ZMSPY+LT3r172bZtW1wkDEjSQmizZs0oLCxk165dqOoJw2qzsrI499xzeeihh/z+Ejp27Mj06dN55ZVXyMjIYP369UEfe/LkyX7npDz33HMh/Sz79++nqKioesbr5MmT+eijj0Lal0ksx44dQ1X54Q9/yJYtW+IiYUCStjR8mjdvzoIFCxg/fjy//OUvaz120003MWTIEFq3bl3r/qVLlzJ8+HAyMzP5+uuvOXjwIJ06dWLjxo1BHTPSLY1TTjmFw4cPs3nzZnr06MFbb71Fz549I3oME398pyQ//vGPufvuu8nOznY7pO81VCmNpy3UuSdjxozR5557Tnfs2KG9evU64flPP/10de/JjTfeqD169NC+fftq37599fnnn1dVT+9Jy5Yta81JCdRjEYyvvvpKO3XqpC1atNCTTz5ZO3XqpIcPH1ZV1dGjR+vevXtV1TN3pXfv3tq3b18dMmSIbtu2TVVVP/74Y+3UqZM2b95cW7dureecc47f4/h7j0z8qtlLEu7fWGNhc08M2HuUSNwuetrcE2MSSFVVFWPHjo2bXpL6WNIwJk6kpaVx/fXXx3XCgCQohKalpVFeXm4XTKpHeXm5Df6Kc47jsHbtWoYMGXLCKnPxKOH/mgYMGMD8+fMpLy93O5S4U15ezvz58xkwYIDboaSkqirl6LEKqtT7terEupJventeXh779u1zIcoQNFQpjafNX+/J7t27NTc3V9PS0hSwrcaWlpamubm5unv37nAK6iYElZVVuu9ImU55fLmeeetrOuXx5brvSJlWVn6/YpxvxS03eknqQ7z3nojIKOARIB14UlXvD/R8f70nxsSjo8cq+Pmzq1m+/WD1fYPOaMMT1+RyUpMM1xbQaUhc956ISDqwEBgNnANMFZFz3IrHmEhqnpXOqp2Hat23auchmmelA/D000/HXcIIlps1jfOAraq6XVXLgQLgJy7GY0zElJRXMrBr7dHGA7u2pqS8EoBf//rXfPzxxwmXMMDdpNEJ2F3j9h7vfbWIyAwRWS0iq/fv3x+z4IwJR/PMdBZM7c+gM9qQkSYMOqMNj0zJ4S+PLWTLli2ISMIWqOO+y1VVFwGLwFPTcDkcY4KSlia0yc7iiWtyaZ6VTnHZceY/8HvuveceunTpQvfu3d0OMWRuJo29QM3LWHf23mdMUkhLE79Fz/Hjx7sdWljcPD1ZBXQXkW4ikgVMAV51MR5jIi5ee0nC4VpLQ1UrRORXwD/xdLk+paqfuRWPMdGSkZGRNAkDXK5pqOrrwOtuxmBMNDiOQ1paGi1atGDZsmWIiNshRUzcF0KNSTS+U5JmzZrx5ptvJlXCAEsaxkRU3RpGsiUMSIIJa8bEi2QsevpjScOYCLn22muTPmGAJQ1jIuaee+7hpZdeSuqEAZY0jAmL4zg8+uij1ZcaSPSBW8GwpGFMiHw1jJkzZ7Ju3Tq3w4kZSxrGhKBm0TM/P59+/fq5HVLMWNIwppHqJoxJkya5HVJMWdIwppFWrlzJmjVr4iJhBLMOaaTZ4C5jgqSqiAgjRoxg+/btnHrqqa7GU1WlHCwuZ2b+J6zaeYiBXVuzYGp/2mRnkZYWvUFl1tIwJgiO4zBs2DBefvllANcTBkDJ8Upm5n/C8u0HqahSlm8/yMz8Tyg5XhnV41rSMKYBvhrGBx98QFVVldvhVGtoHdJosaRhTADxXPRsaB3SaLGkYUw9ysrK4jZhgP91SBdM7U/zzOi2NKwQakw9mjRpwuDBg5k1a1bcJQw4cR3SkvJKmmemR7UICgGShoj8Ec+VuvxS1ZlRicgYlzmOw9dff0337t154IEH3A4nIN86pED116gfM8Bjq4E1QFNgALDFu+UAdrVlk5R8NYxhw4ZRWlrqdjhxqd7UpKrPAojIL4CLVLXCe/sx4IPYhGdM7NRdD6NZs2ZuhxSXgimEngK0rHH7JO99xiSNVFlAJxKCOQm6H/hERJYBAlwMzItmUMbE2rx58yxhBCmoq8aLyA+A8703V6rq11GNqh521XgTLcXFxaxYsYLhw4eHtZ+qKqXkeGVMezMiKSJXjRfPyqgjgH6q+gqQJSLnRShGY1zjOA6zZs3CcRyys7MjkjAOFpfz82dX02PuG/z82dUcLC6PySSyWAqmpvEoMAiY6r3tAAujFpExMeCrYSxcuJAVK1ZEZJ9uzQWJtWBqGuer6gAR+QRAVb/1XkbRmIRUt+g5cuTIiOzXrbkgsRZMS+O4iKTjHeglIu2A+Jm1Y0wjRLOXxK25ILEWTNJYAPwNaC8i9wL/Bu6LalTGRMn+/fvZs2dPVHpJ3JoLEmvB9p78EBiOp8v1HVX9PNqB+WO9JyZUpaWlNG3aFBGhrKyMpk2bRuU41nvi2cnzqrpRVReq6p9U9XMReT5yYRoTXY7jMHLkSObMmQMQtYQB388FSRPv1wRKGMEK5vSkV80b3vrGueEcVEQeFJGNIrJORP4mIq3C2Z8x9alZwxg8eLDb4SSFepOGiNwqIg7QV0SOeDcH2Ae8EuZx3wJ6q2pfYDNwa5j7M+YENjQ8OupNGqp6n6q2AB5U1ZberYWqtlHVsP7JVfVN3wQ4YAXQOZz9GVOXqjJ+/PikTxhurEYezOnJxyJysu+GiLQSkUhee2468EYE92cMIsLs2bPJz89P6oThxgjUBntPRKRQVXPq3PeJqvZv4HVvAz/w89Bc73B0RGQukAtM1HoCEZEZwAyA008//dxdu3YFjNekNsdx+PDDDxk1apTboUTd0WMV/PzZ1SzffrD6vkFntOGJa3JDXpAnmN6TYPbsrzXS4OtUdUSgx0Xkp8AYYHh9CcO7n0XAIvB0uTZ0XJO6HMchLy+PVatWsW3bNjp16uR2SFEVz6uRrxaRP4jImd7tD3hW9AqZiIwCfgOMU9WScPZlDHyfMJYvX85f//rXpE8YEN+rkf8aKAcWe7djwA1hHvdPQAvgLREp9K4GZkxIaiaMZC561hW3q5GrajHw20geVFXPiuT+TGorKChIuYQB8bka+f+o6mwR+T/8rEququOiGpkxQfrZz37GoEGD6N27t9uhxJwbq5EHOopvqPj8WARiTGM4jsO0adO4++676d27d0omDLcEWo18jffr+7ELx5iG1RzpOW3aNEsYMRbo9ORTAl8sqW9UIjKmHlVVSvGx4zTPzmbRU89y+NABBl1wfsMvDPFYiTxbNZoCnZ6M8X719ZT4TleuIkAyMZFnf8Ce9+DA0WPMKihk1c5DDOzamgVT+1NVpRF/L3wjLWfmf1LrWG2ys1Luffcn0NyTXaq6Cxipqr9R1U+92y3AJbELMbWlymK1DSk5XsmsgsKYrL+ZKmt9hiqYcRoiIoNr3LgwyNeZCLA/YE8NI5ajH1Nlrc9QBfPPfx3wqIjsFJGdeFYnnx7VqEy1VP8D9hU9t3+xN2ajH1Nlrc9QNZg0VHWNqvYD+uG59kmOqq6NfmgGUvsPuGYvyf6v9sZs9GOqrPUZqmBmuXYAfg90VNXRInIOMEhV/xKLAGtKxTVCU7Uo528BnVgWhFO1+BypWa7PAE8Dc723N+OZgxLzpJGKYjlUOJ7+Ua6//voTFtCJ5ehHN0ZaJopgahptVfUFvNc68a64lfxt4zgSi8Vq462X5t5772XJkiUpNZckUQSTNIpFpA3fXyzpAuBwVKMyMRcPvTSO4/DQQw9RVVVFt27dGDeu/ulNbixzF89xxFIw7a45wKvAmSLyIdAOsPSfZNzupalZwxgyZAi5ufWfVsdLnSde4oi1gC0N7+UKhni3C4HrgV6qui4GsZkYcrOXpm7RM1DCgPhoFcVTHLEWMGmoaiUwVVUrVPUzVV2vqsdjFJuJIbe6GUO5zECoraJIn0q43TpzSzCnJx+KyJ/w9JgU++60sRrJxa0FXYqKiigsLGzUAjol5ZXMHHYWl/Y+lbPan8TWfUf55/qvKCmvrLenIxqnEr7WWc2FfX2ts2TucQlmnMYyP3erqg6LTkj1C3ecRjx1KSaCaL5fVVVVpKV5GroHDhygbdu2Qb+2srKKg8XltSavPTIlhzbZWaSn+288R2Pl7mSsaURqnMYkVT0QoZhc09Av2BJKbdH8h3AchzFjxjB9+nSuueaaRiUMgNKKqurJawDLtx9kVkGhJwHUkzSicSrhVuvMbYEuyzhWRPYD60Rkj3eiWsIKVLSKtzEK8SBaRT5fDePDDz8kOzs7pH34EsC8sedQeOdItt+Xx5+vGkDTjLR66xXRKvSmwgWf6wpUCL0X+JGqdgQuA+6LTUjREeiTJlWr4IFE45M5UtdWLSmv5I9Tc8jrcyq/+Otaesx9g1/8dS2Hist5fvlOv0nf5pNETqCkUaGqGwFUdSWeSw4krECfNKlaBffx16sQiU/mWvstO878hx6KyLVVm2emc1H3diesrzGroJCf5HTym/Rrnkpsvnc0T1yTm9C1BzcFqmm0F5E59d1W1T9EL6zI833S1D1Hb56ZnrJVcKi/dtG6eWa971eo+31o5s2MGjU65CX6atadsptk+E30LZtlVn9fN+nbfJLICPTOPUHt1kXd2wklUNEqUEJJdjVPzYDqT2nfJ3GoRT5/+73ppfU8cU3ggVv1qZuEVt8+wm+iP1J6vPr7VEj6bgi0GvldsQwkFur7pAm1Cp4MPS6BTs18xT1o/CdzpE/56iahv3+yl0em5FDw8RfV4zWKj1Ww9otDVq+IMlu2z6uxVfBk6XGJVq9CcdnxiO63bhKa938b2PDVYaacfzrzXv2Ms29/g+ufX0Ovjifzl59avSKarO0WokDNereaxKG0fJpnpvPYVQP4tuQ4p7Vuzu5DJZzSPDOsT2nHcZj/0EM8MvsmSirSIrJff3Wnrm1OYlZ+YZ3fgWe8hiWM6LGWRojircclnJZPeWUVty75lLNvf4Nbl3xKeWVVWLHcd999bN2yFZX0iO3XX5fp6W2ax9XvIFU0mDREpI2I/FFE1orIGhF5xLu+RkqLt7U7Qx1r4nld3UsDFIY1RuXOO+/kkUcfY/bidRHbr78u05Jj8fU7SBXBtDQKgH14BnhdDuzHM3ktpcXbYKFQWz7htphqjsX44stvOOI4NG3alNYts6MybLtm3al5Vnz9DlJFMCffp6rq3TVu3yMikyNxcBG5Cc8Fptsl2vyWYHtcYtXDEupYk3DGqPgbi/HwFX05yfszR3vsS6rO/XBbMC2NN0VkioikebcrgH+Ge2AROQ3Pldq+CHdfbvGN8fCNKvXNY/GJZQ9LqC2fcFpM/k6JbnxhnSdJxqgllopzP9wWzNR4B8jGu7AwnkTjW1dDVbVlSAcWeQm4G3gFyA2mpRFvlzBoaCZoNKZjNxRPKK2akF+nSo+5b1DhTYLj+nXkhqFn0b2DZ8xEs4x0yiqrrBWQQIKZGh/MxZJaqGqaqmZ4tzTvfS3CSBg/AfaqalEQz50hIqtFZPX+/ftDOVzUNFR8jHUPS6ifuqG+zik5Vl2IHNevIzdfcjbzXv2MHnPfYMZzazhUUk6zjDRrBSSZoD7uRGQccLH35nuq+o8gXvM28AM/D80FbiPIi0ir6iJgEXhaGsG8JlYaSgrJOqeluLiYpk2b0qJZExZMzWFmfiE3DD2Lv3+yh3njelWvplXw8Rdce1E3WtSzxoVJTA3+5YrI/cBA4H+9d80SkcGqemug16nqiHr21wfoBhSJCEBnYK2InKeqXzcmeLfVlxSKj1WQnZWRlHNafNPbe/bsyRNPPEGb7CY8cU0uzTLTaNa/M7e8vO77n3VKDoLnNMaN05NkGOYfj4L5uMsDclS1CkBEngU+AQImjfqo6qdAe99t70Wlg6ppxBt/SeGBy/ry9L93MPX8LrTJzkqq6n7N9TBmz54NfH9q45Qd55aX11Un0HYtmnCssoqZzxX6rfdEW2VlFQdLypmV787xk1mw7cZWNb4/ORqBJCJfl9+iaeey6Z7RzBvXi/lvbuIPb2+prm0kS3W/oQV06k5Vv2HoWfy/F+sO7orNwkZVVUpxeWX1EHNbWCmygmlp/B74xLvAsOCpbfw2UgGoatdI7csNaWlCdpOMWr0IkBzDmWs27/d/e4QuXboye/Zsvwvo1D1VO6v9Sa4N8S45XlnvehuJ/juJBw1dLCkNT1frBcAS4GU8V4xP+RGhNcXbkHKfcK7zUXeMydylu3lo4eNMnHiZ3+fXHZex+1CJa+9J86x0tu47Gpe/k2QQzDiN1Q3128ZKvI3T8InHpezDjaneMSbTckHwW6Op2TIpO15J8bEKZrpQUzh6rIKnPtjO+DqF2Uem5tA2u0nCniLGQjDjNIJJGvcDBzjxYkmH6n1RlMRr0oD4q9SHO7Cs7sAtgIw0YfO9o7nyiZU1EkEOber5Rwz2PYn0e+dLmPkrd9VaoCc7K73e66IYj4gM7gImAzcA/wLWeLf4/M91UbwVPMMZWOY4Dtu/2Ou3ef/FwZITZ67W0+QP5j2JxlB7X4F6+o/OoHuHkyg97hkXYwkjMoIZEdrNz3ZGLIIzoQu1zuLrJfndbb/l4Sv61Jo78sjUHN7fvK/W81ftPETzJqEXF6N1+Yh4S+LJJJjBXU2BXwIXAQp8ADymqmVRjs2EIdSBZa+88gpdunTl4T8upE3LZiyadi7ZWRls2XeUgpVfMPHczqzZ9R2vFn0JeBPRsUpOahraCNd4W8zINCyY3/RzgAP80Xv7P4HngUnRCsqEL9Rp4//5n1cycuxlzFpcVGvA2sJlW3m16EuWbz/EfRP78PqnXzGwa2senNSXNAl91GeyDrVPZsEUQjeo6jkN3RcL8VwIdUOkCoiO4zB16lTuvPNOzuk34IQC6pwR3Zl2YVdaNM1k676jnNU+G/B0q7ZqnslzH+1kwbtbQ+ohiceep1QWqULoWhG5oMZOz8cKoa6LVAHRV8NYunQpe/bsOeF0YVy/jozv35lf/HUtZ9/+BvNe/YyDxeWA0uakLJ77aCd/eHtLo+sRvjEkCGQ3SeeJaXbls0QRTNI4F/hIRHZ654ksBwaKyKcisi6q0Zl6RaKAWHdo+MSJE08ooN4w9KzqOSXVlz/ML6T0eBXZTTJY8O7WWvsMph5RN+Fd98xqSo9XgmJFywQQTNIYhWdW6hDv1s173xhgbPRCM4GEW0A8evSo37kkdUd2BhoOXnysgpnDzqr1WDA9NHbB7cQWTJfrLuAInolqbXybqu7yPmZcEO7Q9aysLE499dQTJp/VXfW7pLzC73G2fHOUGc+tYcp5pzNnRPfGLTFoPSYJLZhC6N3AT4FteLpcwbPM37DohnYiK4R+L9QCouM4lJWV0a5dO1QV75omtfZbs7jaLCONQyXHT5j+P//NTbxa9CWDzmjj6ZZtkhF0MTbWyyCa4EVqGPkmoI+qlkcyuFBY0qitsb0njuOQl5dHcXExq1atIj299id7oCvIl1Z41vrc8s3R6u5X+H5oeZoEX4ewHpP4FUzSCCatr8eznsa+hp5oYqu+C1r740sYy5cvp6Cg4ISEAQ1favLosQrmvfpZ2GMq7NIDiS2YQuh9eNbT+KeIvOrboh2YCV/NqfH7Dh3m9NO7+F1Ax6ehWkMkL0tgw7wTVzAfD88CDwCf8v1lDEyc83sho4WP075l83pf09DoTGshGAiupVGiqgtUdZmqvu/boh6ZCYv/Cxl9GrBbM5iWhLUQTDAtjQ9E5D7gVeCY705VXRu1qEzYQunWtJaECUYwSaO/9+sFNe5TIOZdriY4juPwzaHDIU0Ea0xx1aSmBv8qVHVoLAIxkeEbGt6lS1ceXvg4N77wadJcc8XEh2DW0+iAZ0Xyjqo6WkTOwbO48F+iHp1plLrXJWnfsrmdapiIC6YQ+gyeq8R39N7eDMyOVkAmdJs2bWL9+vXV3apWtDTREMxJa1tVfUFEbgVQ1QoRsZlFcaSiooKMjAxyc3PZuXMnrVq1avhFxoQomJZGsYi0wTvvxLu2xgapSeEAAArhSURBVOGoRmWC5jgOQ4cOZeHChQCWMEzUBZM05uDpbj1TRD7Es/zfr6MalQmKr4axfPlyOnTo4HY4JkUE03uyVkSGAGfjuSzjJlU9HvXITEANXVvVmGgJtiP+PKCr9/kDRARVfS5qUZmAKioqyMvLs4RhXBFMl+vzwJlAIeArgCqe0xTjgoyMDC6//HJmzZplCcPEXDAtjVzgHG1o4Y1GEpFf47lyWyXwmqr+JpL7T0aO47BlyxYGDBjArFmz3A7HpKhg19P4AfBVpA4qIkOBnwD9VPWYiLSP1L6Tla+GsWHDBnbs2MHJJ5/sdkgmRdWbNETk//CchrQANojIx9SesDYujOP+ArhfVY9592UL/ARQt+hpCcO4KVBLY34Uj9sD+JGI3AuUATer6ip/TxSRGcAMgNNPPz2KIcUn6yUx8SZQ0tgLdFDVD2veKSIXEcSpioi8jee0pq653uO2xjNzdiDwgoic4a9uoqqLgEXgWSO0oeMmm4cfftgShokrgZLG/wC3+rn/sPexgNc8UdUR9T0mIr8AlniTxMciUgW0BfY3GHGKue222xg+fDiDBw92OxRjgMAjQjuo6qd17/Te1zXM4/4dGAogIj2ALOBAmPtMGo7jcO211/L111+TkZFhCcPElUBJI9AkhmZhHvcp4AwRWQ8UANdEuks3UflqGM8//zx2uQYTjwKdnqwWkZ+r6hM17xSRnwFrwjmo9xoqV4Wzj2RUs+iZn5/PmDFj3A7JmBMEShqzgb+JyJV8nyRy8ZxKTIh2YKmmbsKYNGmS2yEZ41e9SUNVvwEu9A7E6u29+zVVfTcmkaWYkpISHMexhGHiXjCzXJcBy2IQS0o6evQoTZo0oUOHDqxZs4aMDFvM18S3YNbTMFHiOA6jRo1i2rRpAJYwTEKwpOGSmjWMiRMnuh2OMUGzpOECK3qaRGZJwwWTJ0+2hGESliUNF9xxxx0UFBRYwjAJySpvMeI4Dq+99hpTpkxh0KBBbodjTMispREDvhrG1VdfzdatW90Ox5iwWEsjyuquh3HWWWe5HZIxYbGWRhTZAjomGVnSiKI333yTlStXWsIwScVOT6JAVRERLrvsMjZv3ky3bt3cDsmYiLGWRoT5Tknef/99AEsYJulY0oggX8J4++23OXDAFiIzycmSRoTULXpedtllbodkTFRY0oiA4uJi6yUxKcOSRgQ0bdqU7t27W8IwKcF6T8LgOA6O49CxY0eefvppt8MxJiYsaYTIV8M4dOgQRUVFZGZmuh2SMTFhSSMEdYueljBMKrGaRiPZ0HCT6ixpNNJNN91kCcOkNDs9aaTf//73TJgwgdGjR7sdijGusJZGEBzH4Y477qC8vJy2bdtawjApzZJGAxzHIS8vj/vuu48VK1a4HY4xrrOkEYAvYSxfvpyCggIuvvhit0MyxnWWNOpRN2FY0dMYD1eShojkiMgKESkUkdUicp4bcQSyY8cONm7caAnDmDrc6j35b+AuVX1DRPK8t3/sUiy1lJeXk5WVRd++fdm+fTstWrRwOyRj4opbpycKtPR+fzLwpUtx1OI4DsOHD+f+++8HsIRhjB9uJY3ZwIMishuYD9xa3xNFZIb3FGb1/v37oxZQzRqGrRhuTP2idnoiIm8DP/Dz0FxgOHCjqr4sIlcAfwFG+NuPqi4CFgHk5uZqNGK1oqcxwYta0lBVv0kAQESeA2Z5b74IPBmtOBpSWVnJmDFjLGEYEyS3Tk++BIZ4vx8GbHEpDtLT05k2bZolDGOC5Fbvyc+BR0QkAygDZsQ6AMdxWL9+PYMGDeK6666L9eGNSViuJA1V/TdwrhvHhu+nt69bt44dO3bQpk0bt0IxJuGk3CzXuuthWMIwpnFSahi5LaBjTPhSKmk89thjljCMCVNKnZ7cdNNNDBkyhPPOi7upLsYkjKRvaTiOw5VXXsmuXbtIS0uzhGFMmJI6afhqGIsXL6aoqMjtcIxJCkmbNOoWPceNG+d2SMYkhaRMGtZLYkz0JGXSqKiooKKiwhKGMVGQVL0njuOQmZnJKaecwkcffURaWlLmRGNclTT/Vb5TkiuuuAJVtYRhTJQkRUujbg1DRNwOyZiklfAfx1b0NCa2Ej5pXH311ZYwjImhhE8ad911Fy+88IIlDGNiJCGThuM4PPXUUwD069ePiRMnuhyRMakj4ZKGr4YxY8YMPvvsM7fDMSblJFTSqKqqqi565ufn06tXL7dDMiblJFSX6+bNmykrKyM/P59Jkya5HY4xKSmhkkZJSQmLFy+2hGGMi0Q1KtcfigoR2Q/sisGh2gIHYnCcxrK4Gsfiapy2QLaqtgv0pIRKGrEiIqtVNdftOOqyuBrH4mqcYONKqEKoMcZ9ljSMMY1iScO/RW4HUA+Lq3EsrsYJKi6raRhjGsVaGsaYRrGkYYxpFEsa9RCRHBFZISKFIrJaROLmgiki8msR2Sgin4nIf7sdT00icpOIqIi0dTsWABF50PterRORv4lIK5fjGSUim0Rkq4j81s1YfETkNBFZJiIbvH9TswK+QFVt87MBbwKjvd/nAe+5HZM3lqHA20AT7+32bsdUI7bTgH/iGYDX1u14vDFdAmR4v38AeMDFWNKBbcAZQBZQBJwTB+/RqcAA7/ctgM2B4rKWRv0UaOn9/mTgSxdjqekXwP2qegxAVfe5HE9NDwO/wfPexQVVfVNVK7w3VwCdXQznPGCrqm5X1XKgAPiJi/EAoKpfqepa7/cO8DnQqb7nW9Ko32zgQRHZDcwHbnU5Hp8ewI9EZKWIvC8iA90OCEBEfgLsVdV4vpTddOANF4/fCdhd4/YeAvxzukFEugL9gZX1PSehJqxFmoi8DfzAz0NzgeHAjar6sohcAfwFGBEHcWUArYELgIHACyJyhnrbli7GdRueU4GYCxSXqr7ifc5coAL431jGlkhE5CTgZWC2qh6p93kx+FtLSCJyGGilqiqe5c0Pq2rLhl4Xg7iW4jkvX+a9vQ24QFX3uxhTH+AdoMR7V2c8p3PnqerXbsXlIyI/Ba4HhqtqSQNPj2Ycg4B5qnqp9/atAKp6n1sx+YhIJvAP4J+q+odAz7XTk/p9CQzxfj8M2OJiLDX9HU8xFBHpgaeg5uqMSVX9VFXbq2pXVe2Kp9k9IE4Sxig8dZZxbiYMr1VAdxHpJiJZwBTgVZdjwvuh+Bfg84YSBqT46UkDfg48IiIZQBkww+V4fJ4CnhKR9UA5cE0sTk0S2J+AJsBb3uvhrFDV/3IjEFWtEJFf4elhSgeeUtV4WLNyMHA18KmIFHrvu01VX/f3ZDs9McY0ip2eGGMaxZKGMaZRLGkYYxrFkoYxplEsaRhjGsW6XE2jiUgbPIO5wDMSsxLwDS47zzuvwiQp63I1YRGRecBRVZ1f476MGpPETJKxloaJCBF5Bs8guP7AhyJyhBrJxDsYbYyq7hSRq4CZeEazrgR+qaqV7kRuGstqGiaSOgMXquqc+p4gIj2BycBgVc3Bc2pzZYziMxFgLQ0TSS8G0WIYDpwLrPIO624GxNOaIKYBljRMJBXX+L6C2i3Zpt6vAjyrqvGyPolpJDs9MdGyExgAICIDgG7e+98BLheR9t7HWotIF1ciNCGxpGGi5WWgtYh8BvwKz7qTqOoG4HbgTRFZB7yFZ41KkyCsy9UY0yjW0jDGNIolDWNMo1jSMMY0iiUNY0yjWNIwxjSKJQ1jTKNY0jDGNMr/BylM2pp2GTgHAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('test_checkpoints_splits/fold_0/test_full.csv')\n",
        "df['preds'] = [x[0] for x in preds]\n",
        "\n",
        "plot_parity(df.logSolubility, df.preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNacITwVqj4x"
      },
      "source": [
        "# Ensembling and Uncertainty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpXC83NMqj4x",
        "outputId": "7f1dc6a6-53cd-4334-e993-d9329fc59dec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/reaction_regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 5,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': True,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_ensemble',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['AAM'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'scaffold_balanced',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['ea'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 86284.80it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 60688.51it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 77166.43it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "100%|██████████| 500/500 [00:00<00:00, 16531.62it/s]\n",
            "Total scaffolds = 203 | train scaffolds = 147 | val scaffolds = 29 | test scaffolds = 27\n",
            "Label averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels:\n",
            "Scaffold 0\n",
            "Task 0: count = 141 | target average = 8.010435\n",
            "\n",
            "\n",
            "Scaffold 1\n",
            "Task 0: count = 13 | target average = 9.241358\n",
            "\n",
            "\n",
            "Scaffold 2\n",
            "Task 0: count = 7 | target average = 7.232327\n",
            "\n",
            "\n",
            "Scaffold 3\n",
            "Task 0: count = 7 | target average = 7.289696\n",
            "\n",
            "\n",
            "Scaffold 4\n",
            "Task 0: count = 7 | target average = 6.381221\n",
            "\n",
            "\n",
            "Scaffold 5\n",
            "Task 0: count = 6 | target average = 6.927956\n",
            "\n",
            "\n",
            "Scaffold 6\n",
            "Task 0: count = 6 | target average = 8.997394\n",
            "\n",
            "\n",
            "Scaffold 7\n",
            "Task 0: count = 5 | target average = 7.520033\n",
            "\n",
            "\n",
            "Scaffold 8\n",
            "Task 0: count = 5 | target average = 8.068549\n",
            "\n",
            "\n",
            "Scaffold 9\n",
            "Task 0: count = 4 | target average = 7.458364\n",
            "\n",
            "\n",
            "500it [00:00, 90927.51it/s]\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.99it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.11it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.64it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.28it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.732327\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.65it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 9.6142e-01, PNorm = 34.6714, GNorm = 2.1701, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.16it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.37it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.45it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.97it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.342255\n",
            " 40%|████      | 2/5 [00:01<00:01,  1.64it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.13it/s]\u001b[ALoss = 9.8149e-01, PNorm = 34.7063, GNorm = 1.2760, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.84it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.66it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.15it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.459109\n",
            " 60%|██████    | 3/5 [00:01<00:01,  1.72it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 12.02it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.96it/s]\u001b[ALoss = 7.0097e-01, PNorm = 34.7281, GNorm = 3.2559, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.97it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.94it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.278640\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.40it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 12.26it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.79it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.56it/s]\u001b[ALoss = 6.5832e-01, PNorm = 34.7370, GNorm = 1.5438, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.57it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.200886\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.39it/s]\n",
            "Model 0 best validation rmse = 2.200886 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test rmse = 2.063817\n",
            "Building model 1\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.51it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.06it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.58it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.52it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.382831\n",
            " 20%|██        | 1/5 [00:00<00:03,  1.09it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 6.9498e-01, PNorm = 34.7268, GNorm = 1.8911, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.49it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.24it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 12.58it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 14.08it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.378330\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.20it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.38it/s]\u001b[ALoss = 9.4992e-01, PNorm = 34.7565, GNorm = 6.6179, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 18.08it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.48it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.40it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.331827\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.38it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.36it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.71it/s]\u001b[ALoss = 6.8234e-01, PNorm = 34.7775, GNorm = 1.9858, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.66it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.26it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.327268\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.48it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.77it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.47it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.21it/s]\u001b[ALoss = 6.7731e-01, PNorm = 34.7858, GNorm = 2.4888, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.80it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.261885\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.42it/s]\n",
            "Model 1 best validation rmse = 2.261885 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 1 test rmse = 2.100716\n",
            "Building model 2\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.55it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 18.25it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.51it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.26it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.236768\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.66it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 7.8392e-01, PNorm = 34.6746, GNorm = 2.7400, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.40it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.99it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.92it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.33it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.621285\n",
            " 40%|████      | 2/5 [00:01<00:01,  1.76it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 16.19it/s]\u001b[ALoss = 8.8711e-01, PNorm = 34.7106, GNorm = 7.5942, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.30it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.54it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.64it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.178063\n",
            " 60%|██████    | 3/5 [00:01<00:01,  1.67it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 16.72it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.42it/s]\u001b[ALoss = 6.6988e-01, PNorm = 34.7298, GNorm = 2.6633, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.52it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.32it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.198801\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.72it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.50it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.46it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.66it/s]\u001b[ALoss = 6.1597e-01, PNorm = 34.7378, GNorm = 3.5316, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.83it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.209044\n",
            "100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
            "Model 2 best validation rmse = 2.178063 on epoch 2\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 2 test rmse = 2.126568\n",
            "Building model 3\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 15.05it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 15.89it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 15.92it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.37it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.507891\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.52it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 1.0369e+00, PNorm = 34.6048, GNorm = 1.8233, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.51it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.31it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.61it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.90it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.420495\n",
            " 40%|████      | 2/5 [00:01<00:01,  1.57it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.17it/s]\u001b[ALoss = 8.9386e-01, PNorm = 34.6320, GNorm = 5.4624, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 15.81it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.63it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.10it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.388413\n",
            " 60%|██████    | 3/5 [00:01<00:01,  1.59it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.68it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 18.69it/s]\u001b[ALoss = 7.7755e-01, PNorm = 34.6502, GNorm = 5.8818, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 16.94it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 16.90it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.239898\n",
            " 80%|████████  | 4/5 [00:02<00:00,  1.60it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 18.58it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.79it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.73it/s]\u001b[ALoss = 6.7354e-01, PNorm = 34.6580, GNorm = 2.4950, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.42it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.189930\n",
            "100%|██████████| 5/5 [00:03<00:00,  1.60it/s]\n",
            "Model 3 best validation rmse = 2.189930 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 3 test rmse = 2.075962\n",
            "Building model 4\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=193, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=465, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 378,601\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 16.98it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 17.78it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 17.15it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 17.50it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.780604\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.65it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 9.4477e-01, PNorm = 34.6048, GNorm = 0.9831, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 17.50it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 16.50it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 15.53it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 14.02it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.337362\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.44it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.68it/s]\u001b[ALoss = 7.8064e-01, PNorm = 34.6384, GNorm = 1.7224, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.20it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 10.85it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 10.86it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.411323\n",
            " 60%|██████    | 3/5 [00:02<00:01,  1.32it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.56it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.93it/s]\u001b[ALoss = 7.3826e-01, PNorm = 34.6613, GNorm = 4.0008, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.89it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.80it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.280935\n",
            " 80%|████████  | 4/5 [00:03<00:00,  1.24it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.10it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 11.57it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 11.66it/s]\u001b[ALoss = 6.4870e-01, PNorm = 34.6701, GNorm = 5.0483, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.20it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 2.204269\n",
            "100%|██████████| 5/5 [00:04<00:00,  1.24it/s]\n",
            "Model 4 best validation rmse = 2.204269 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 4 test rmse = 2.108382\n",
            "Ensemble test rmse = 2.067441\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 2.067441\n",
            "Overall test rmse = 2.067441 +/- 0.000000\n",
            "Elapsed time = 0:00:19\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/reaction_regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_ensemble',\n",
        "    '--epochs', '5',\n",
        "    '--reaction',\n",
        "    '--save_smiles_splits',\n",
        "    '--ensemble_size', '5',\n",
        "    '--split_type', 'scaffold_balanced'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt8ItRG3qj4x",
        "outputId": "1a4fe1a8-70ba-49da-fc9e-715409a29fe6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [00:00, 78251.94it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 109626.35it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:01,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:01,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:01<00:00,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_ensemble.csv\n",
            "Elapsed time = 0:00:03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_ensemble/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_ensemble.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_ensemble',\n",
        "    '--ensemble_variance'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5WaSuowCqj4x",
        "outputId": "3e313c9c-43d3-4bb4-a80c-b6c7d270d8ec",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-38aabb4e-9212-493a-a0db-9b0d5ca19996\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAM</th>\n",
              "      <th>ea</th>\n",
              "      <th>ea_ensemble_uncal_var</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C@:3]([C:4]([H:12])([H:...</td>\n",
              "      <td>7.437500</td>\n",
              "      <td>0.051191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C@:3]([C:4]([H:12])([H:...</td>\n",
              "      <td>8.662633</td>\n",
              "      <td>0.362828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[N:4...</td>\n",
              "      <td>8.302808</td>\n",
              "      <td>0.073829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[O:1]([C:2]1([H:7])[C:3]([H:8])([H:9])[O:4][C:...</td>\n",
              "      <td>10.508875</td>\n",
              "      <td>0.356629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O:1]([C:2]1([C:6](=[O:7])[H:13])[C:3]([H:9])(...</td>\n",
              "      <td>9.142585</td>\n",
              "      <td>0.174254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[O:1]([C:2]1([C:6](=[O:7])[H:13])[C:3]([H:9])(...</td>\n",
              "      <td>8.655645</td>\n",
              "      <td>0.116326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[N:1](=[C:2]1\\[O:3][C@@:4]2([H:9])[C:5]([H:10]...</td>\n",
              "      <td>7.597202</td>\n",
              "      <td>0.044275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[N:1](=[C:2]1\\[O:3][C@@:4]2([H:9])[C:5]([H:10]...</td>\n",
              "      <td>8.631742</td>\n",
              "      <td>0.175392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[O:1]=[C:2]1[C:3]([H:8])([H:9])[N:4]2[C:5]([H:...</td>\n",
              "      <td>9.267970</td>\n",
              "      <td>0.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[C:1]([c:2]1[c:3]([H:11])[n:4]([H:12])[c:5]([O...</td>\n",
              "      <td>8.703622</td>\n",
              "      <td>0.050446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[C:1]([O:2][C@@:3]1([H:11])[C@@:4]2([H:12])[C:...</td>\n",
              "      <td>7.670585</td>\n",
              "      <td>0.076409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[C:1]([C@@:2]12[C:3]([H:11])([H:12])[C@:4]1([O...</td>\n",
              "      <td>7.286619</td>\n",
              "      <td>0.107827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[C:1]([C@:2]12[C@@:3]3([H:11])[C@:4]4([H:12])[...</td>\n",
              "      <td>8.877699</td>\n",
              "      <td>0.374892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[C:1]([C@:2]12[C@@:3]3([H:11])[C@:4]4([H:12])[...</td>\n",
              "      <td>5.327089</td>\n",
              "      <td>0.162265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[C:1](#[C:2][C:3]#[C:4][C@@:5]1([H:9])[C:6]([H...</td>\n",
              "      <td>7.464116</td>\n",
              "      <td>0.278382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[C:1](/[C:2](=[N:3]\\[O:4][H:11])[C@@:5]1([H:12...</td>\n",
              "      <td>8.581939</td>\n",
              "      <td>0.084502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[C:1]1([H:7])([H:8])[C@@:2]2([H:9])[C:3]([H:10...</td>\n",
              "      <td>7.991354</td>\n",
              "      <td>0.048565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[O:1]([c:2]1[n:3][n:4]([H:8])[n:5][c:6]1[H:9])...</td>\n",
              "      <td>6.699617</td>\n",
              "      <td>0.014819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[C:1]([c:2]1[n:3][n:4]([H:10])[n:5][c:6]1[H:11...</td>\n",
              "      <td>7.758332</td>\n",
              "      <td>0.024714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[N:1]([c:2]1[c:3]([H:10])[o:4][n:5][c:6]1[N:7]...</td>\n",
              "      <td>7.714368</td>\n",
              "      <td>0.011509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[N:1]([c:2]1[c:3]([H:10])[c:4]([N:5]([H:11])[H...</td>\n",
              "      <td>7.620089</td>\n",
              "      <td>0.049530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[C:1]([c:2]1[c:3]([H:11])[c:4]([N:5]([H:12])[H...</td>\n",
              "      <td>7.897841</td>\n",
              "      <td>0.023132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...</td>\n",
              "      <td>8.073214</td>\n",
              "      <td>0.064748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[C@:...</td>\n",
              "      <td>7.238061</td>\n",
              "      <td>0.030620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...</td>\n",
              "      <td>8.160344</td>\n",
              "      <td>0.162666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C@...</td>\n",
              "      <td>7.405831</td>\n",
              "      <td>0.057869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...</td>\n",
              "      <td>7.736525</td>\n",
              "      <td>0.051980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[C@:...</td>\n",
              "      <td>7.024516</td>\n",
              "      <td>0.036442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[O:1]([C@@:2]1([H:8])[C:3]([H:9])([H:10])[C@:4...</td>\n",
              "      <td>8.845977</td>\n",
              "      <td>0.183325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[C:1]([C@:2]12[C:3]([H:10])([H:11])[C:4]([H:12...</td>\n",
              "      <td>8.116722</td>\n",
              "      <td>0.182136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[O:3][C:4]([H:12])([H:13...</td>\n",
              "      <td>8.908027</td>\n",
              "      <td>0.265048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[O:3][C:4]([H:12])([H:13...</td>\n",
              "      <td>7.425850</td>\n",
              "      <td>0.088779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[O:1]=[C:2]1[C:3]([H:8])([H:9])[O:4][C@@:5]2([...</td>\n",
              "      <td>8.702798</td>\n",
              "      <td>0.237794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[C:1]([C@@:2]1([C:3]([O:4][H:12])([H:10])[H:11...</td>\n",
              "      <td>7.963273</td>\n",
              "      <td>0.081806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[C:1]1([H:6])([H:7])[C:2]([H:8])([H:9])[C@@:3]...</td>\n",
              "      <td>8.077995</td>\n",
              "      <td>0.145824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[N:1]#[C:2][C@@:3]1([H:7])[C:4]([H:8])([H:9])[...</td>\n",
              "      <td>7.693681</td>\n",
              "      <td>0.044768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C:4]...</td>\n",
              "      <td>7.850417</td>\n",
              "      <td>0.090569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C:4]...</td>\n",
              "      <td>7.768584</td>\n",
              "      <td>0.075748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[C:1]([C:2]#[C:3][C:4]([N:5]1[C:6]([H:13])([H:...</td>\n",
              "      <td>8.004091</td>\n",
              "      <td>0.077657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[N:1]([C:2](=[O:3])[C:4]([N:5]1[C:6]([H:12])([...</td>\n",
              "      <td>7.967761</td>\n",
              "      <td>0.065627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[C:1]([C:2]#[C:3][C:4]([N:5]1[C:6]([H:13])([H:...</td>\n",
              "      <td>9.012047</td>\n",
              "      <td>0.067033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[N:1]([C:2](=[O:3])[C:4]([N:5]1[C:6]([H:12])([...</td>\n",
              "      <td>7.712333</td>\n",
              "      <td>0.052295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C:...</td>\n",
              "      <td>7.955681</td>\n",
              "      <td>0.023752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...</td>\n",
              "      <td>9.677749</td>\n",
              "      <td>0.084125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...</td>\n",
              "      <td>8.062699</td>\n",
              "      <td>0.030905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[C:1]([C:2]1([C:3]([O:4][H:12])([H:10])[H:11])...</td>\n",
              "      <td>10.491706</td>\n",
              "      <td>0.295304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[C:1]1([H:7])([H:8])[C:2]([H:9])([H:10])[C:3](...</td>\n",
              "      <td>9.052074</td>\n",
              "      <td>0.064273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[C:1](#[C:2][C:3]1([H:8])[C:4]([H:9])([H:10])[...</td>\n",
              "      <td>8.012644</td>\n",
              "      <td>0.064509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[C:1]([O:2][C@@:3]1([H:11])[C:4]([H:12])([H:13...</td>\n",
              "      <td>7.975821</td>\n",
              "      <td>0.075249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[O:1]([C:2]([C:3]1([H:10])[C:4]([H:11])([H:12]...</td>\n",
              "      <td>9.594182</td>\n",
              "      <td>0.106705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38aabb4e-9212-493a-a0db-9b0d5ca19996')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38aabb4e-9212-493a-a0db-9b0d5ca19996 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38aabb4e-9212-493a-a0db-9b0d5ca19996');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  AAM         ea  \\\n",
              "0   [C:1]([C@@:2]1([H:10])[C@:3]([C:4]([H:12])([H:...   7.437500   \n",
              "1   [C:1]([C@@:2]1([H:10])[C@:3]([C:4]([H:12])([H:...   8.662633   \n",
              "2   [O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[N:4...   8.302808   \n",
              "3   [O:1]([C:2]1([H:7])[C:3]([H:8])([H:9])[O:4][C:...  10.508875   \n",
              "4   [O:1]([C:2]1([C:6](=[O:7])[H:13])[C:3]([H:9])(...   9.142585   \n",
              "5   [O:1]([C:2]1([C:6](=[O:7])[H:13])[C:3]([H:9])(...   8.655645   \n",
              "6   [N:1](=[C:2]1\\[O:3][C@@:4]2([H:9])[C:5]([H:10]...   7.597202   \n",
              "7   [N:1](=[C:2]1\\[O:3][C@@:4]2([H:9])[C:5]([H:10]...   8.631742   \n",
              "8   [O:1]=[C:2]1[C:3]([H:8])([H:9])[N:4]2[C:5]([H:...   9.267970   \n",
              "9   [C:1]([c:2]1[c:3]([H:11])[n:4]([H:12])[c:5]([O...   8.703622   \n",
              "10  [C:1]([O:2][C@@:3]1([H:11])[C@@:4]2([H:12])[C:...   7.670585   \n",
              "11  [C:1]([C@@:2]12[C:3]([H:11])([H:12])[C@:4]1([O...   7.286619   \n",
              "12  [C:1]([C@:2]12[C@@:3]3([H:11])[C@:4]4([H:12])[...   8.877699   \n",
              "13  [C:1]([C@:2]12[C@@:3]3([H:11])[C@:4]4([H:12])[...   5.327089   \n",
              "14  [C:1](#[C:2][C:3]#[C:4][C@@:5]1([H:9])[C:6]([H...   7.464116   \n",
              "15  [C:1](/[C:2](=[N:3]\\[O:4][H:11])[C@@:5]1([H:12...   8.581939   \n",
              "16  [C:1]1([H:7])([H:8])[C@@:2]2([H:9])[C:3]([H:10...   7.991354   \n",
              "17  [O:1]([c:2]1[n:3][n:4]([H:8])[n:5][c:6]1[H:9])...   6.699617   \n",
              "18  [C:1]([c:2]1[n:3][n:4]([H:10])[n:5][c:6]1[H:11...   7.758332   \n",
              "19  [N:1]([c:2]1[c:3]([H:10])[o:4][n:5][c:6]1[N:7]...   7.714368   \n",
              "20  [N:1]([c:2]1[c:3]([H:10])[c:4]([N:5]([H:11])[H...   7.620089   \n",
              "21  [C:1]([c:2]1[c:3]([H:11])[c:4]([N:5]([H:12])[H...   7.897841   \n",
              "22  [C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...   8.073214   \n",
              "23  [O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[C@:...   7.238061   \n",
              "24  [C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...   8.160344   \n",
              "25  [C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C@...   7.405831   \n",
              "26  [C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C@...   7.736525   \n",
              "27  [O:1]([C@@:2]1([H:9])[C:3]([H:10])([H:11])[C@:...   7.024516   \n",
              "28  [O:1]([C@@:2]1([H:8])[C:3]([H:9])([H:10])[C@:4...   8.845977   \n",
              "29  [C:1]([C@:2]12[C:3]([H:10])([H:11])[C:4]([H:12...   8.116722   \n",
              "30  [C:1]([C@@:2]1([H:11])[O:3][C:4]([H:12])([H:13...   8.908027   \n",
              "31  [C:1]([C@@:2]1([H:11])[O:3][C:4]([H:12])([H:13...   7.425850   \n",
              "32  [O:1]=[C:2]1[C:3]([H:8])([H:9])[O:4][C@@:5]2([...   8.702798   \n",
              "33  [C:1]([C@@:2]1([C:3]([O:4][H:12])([H:10])[H:11...   7.963273   \n",
              "34  [C:1]1([H:6])([H:7])[C:2]([H:8])([H:9])[C@@:3]...   8.077995   \n",
              "35  [N:1]#[C:2][C@@:3]1([H:7])[C:4]([H:8])([H:9])[...   7.693681   \n",
              "36  [C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C:4]...   7.850417   \n",
              "37  [C:1]1([H:8])([H:9])[O:2][C@@:3]2([H:10])[C:4]...   7.768584   \n",
              "38  [C:1]([C:2]#[C:3][C:4]([N:5]1[C:6]([H:13])([H:...   8.004091   \n",
              "39  [N:1]([C:2](=[O:3])[C:4]([N:5]1[C:6]([H:12])([...   7.967761   \n",
              "40  [C:1]([C:2]#[C:3][C:4]([N:5]1[C:6]([H:13])([H:...   9.012047   \n",
              "41  [N:1]([C:2](=[O:3])[C:4]([N:5]1[C:6]([H:12])([...   7.712333   \n",
              "42  [C:1]([C@@:2]1([H:11])[C:3]([H:12])([H:13])[C:...   7.955681   \n",
              "43  [C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...   9.677749   \n",
              "44  [C:1]([C@@:2]1([H:10])[C:3]([H:11])([H:12])[C:...   8.062699   \n",
              "45  [C:1]([C:2]1([C:3]([O:4][H:12])([H:10])[H:11])...  10.491706   \n",
              "46  [C:1]1([H:7])([H:8])[C:2]([H:9])([H:10])[C:3](...   9.052074   \n",
              "47  [C:1](#[C:2][C:3]1([H:8])[C:4]([H:9])([H:10])[...   8.012644   \n",
              "48  [C:1]([O:2][C@@:3]1([H:11])[C:4]([H:12])([H:13...   7.975821   \n",
              "49  [O:1]([C:2]([C:3]1([H:10])[C:4]([H:11])([H:12]...   9.594182   \n",
              "\n",
              "    ea_ensemble_uncal_var  \n",
              "0                0.051191  \n",
              "1                0.362828  \n",
              "2                0.073829  \n",
              "3                0.356629  \n",
              "4                0.174254  \n",
              "5                0.116326  \n",
              "6                0.044275  \n",
              "7                0.175392  \n",
              "8                0.310400  \n",
              "9                0.050446  \n",
              "10               0.076409  \n",
              "11               0.107827  \n",
              "12               0.374892  \n",
              "13               0.162265  \n",
              "14               0.278382  \n",
              "15               0.084502  \n",
              "16               0.048565  \n",
              "17               0.014819  \n",
              "18               0.024714  \n",
              "19               0.011509  \n",
              "20               0.049530  \n",
              "21               0.023132  \n",
              "22               0.064748  \n",
              "23               0.030620  \n",
              "24               0.162666  \n",
              "25               0.057869  \n",
              "26               0.051980  \n",
              "27               0.036442  \n",
              "28               0.183325  \n",
              "29               0.182136  \n",
              "30               0.265048  \n",
              "31               0.088779  \n",
              "32               0.237794  \n",
              "33               0.081806  \n",
              "34               0.145824  \n",
              "35               0.044768  \n",
              "36               0.090569  \n",
              "37               0.075748  \n",
              "38               0.077657  \n",
              "39               0.065627  \n",
              "40               0.067033  \n",
              "41               0.052295  \n",
              "42               0.023752  \n",
              "43               0.084125  \n",
              "44               0.030905  \n",
              "45               0.295304  \n",
              "46               0.064273  \n",
              "47               0.064509  \n",
              "48               0.075249  \n",
              "49               0.106705  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds_df = pd.read_csv('test_preds_ensemble.csv')\n",
        "preds_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "IDoQXtURqj4y",
        "outputId": "e76621bd-bb76-4ccc-a50f-4f8ccde4bbdc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('test_checkpoints_ensemble/fold_0/test_full.csv')\n",
        "plot_parity(df.ea, preds_df.ea, preds_df.ea_ensemble_uncal_var)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9IskYn_qj4y"
      },
      "source": [
        "# Fingerprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JIABGusqj4y",
        "outputId": "920e8b2b-40b7-4476-830b-39b8cb9d2868",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "500it [00:00, 110884.15it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 70909.62it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 500\n",
            "Encoding smiles into a fingerprint vector from 1 models.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [00:00<00:03,  2.48it/s]\u001b[A\n",
            " 30%|███       | 3/10 [00:00<00:00,  7.01it/s]\u001b[A\n",
            " 70%|███████   | 7/10 [00:00<00:00, 15.48it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_fingerprint.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'data/regression.csv',\n",
        "    '--preds_path', 'test_preds_fingerprint.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_reg',\n",
        "    '--fingerprint_type', 'MPN'\n",
        "]\n",
        "\n",
        "args = chemprop.args.FingerprintArgs().parse_args(arguments)\n",
        "preds = chemprop.train.molecule_fingerprint.molecule_fingerprint(args=args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zDA4Hxqj4y",
        "outputId": "6b8a8e4e-e889-40c5-b678-e5e0f3b23fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 300)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ucy2Bn5Kqj4y",
        "outputId": "7cd6b6c9-42f0-4a83-f780-f20b5a1cd3dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('data/regression.csv')\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_xy = pca.fit_transform(preds.squeeze())\n",
        "plt.scatter(pca_xy[:,0], pca_xy[:,1], s=30, c=df.logSolubility, edgecolor='w')\n",
        "plt.colorbar(label='logSolubility')\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGUPCknvqj4y"
      },
      "source": [
        "# Spectra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwF0PzS9qj4y",
        "outputId": "87532276-92af-4063-b344-276dc713d8b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/spectra.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'spectra',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': ['data/spectra_features.csv'],\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'sid',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'sid',\n",
            " 'metrics': ['sid'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 6,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_spectra',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random_with_repeated_smiles',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['400', '402', '404', '406', '408', '410'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': True,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "200it [00:00, 50063.31it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 57197.65it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 11280.32it/s]\n",
            "Number of tasks = 6\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "0it [00:00, ?it/s]Warning: Repeated SMILES found in data, pickle file of split indices cannot distinguish entries and will not be generated.\n",
            "1it [00:00, 756.55it/s]\n",
            "Total size = 200 | train size = 160 | val size = 20 | test size = 20\n",
            "Normalizing spectra and excluding spectra regions based on phase\n",
            "100%|██████████| 4/4 [00:00<00:00, 2786.45it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2413.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 3575.71it/s]\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=305, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=6, bias=True)\n",
            "    (5): nn_exp()\n",
            "  )\n",
            ")\n",
            "Number of parameters = 358,206\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  7.61it/s]\u001b[A\n",
            " 50%|█████     | 2/4 [00:00<00:00,  8.04it/s]\u001b[A\n",
            " 75%|███████▌  | 3/4 [00:00<00:00,  8.32it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 2807.43it/s]\n",
            "Validation sid = 0.038611\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.84it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 2/4 [00:00<00:00, 11.18it/s]\u001b[A\n",
            "100%|██████████| 4/4 [00:00<00:00, 13.65it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 2309.64it/s]\n",
            "Validation sid = 0.008126\n",
            " 40%|████      | 2/5 [00:00<00:01,  2.06it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.98it/s]\u001b[A\n",
            " 50%|█████     | 2/4 [00:00<00:00,  9.01it/s]\u001b[A\n",
            "100%|██████████| 4/4 [00:00<00:00, 12.72it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 1281.09it/s]\n",
            "Validation sid = 0.005895\n",
            " 60%|██████    | 3/5 [00:01<00:00,  2.05it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[ALoss = 1.3642e-03, PNorm = 34.2052, GNorm = 0.0428, lr_0 = 1.2915e-04\n",
            "\n",
            " 25%|██▌       | 1/4 [00:00<00:00,  9.24it/s]\u001b[A\n",
            " 75%|███████▌  | 3/4 [00:00<00:00, 10.44it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 2284.48it/s]\n",
            "Validation sid = 0.003364\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.09it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|█████     | 2/4 [00:00<00:00, 10.90it/s]\u001b[A\n",
            "100%|██████████| 4/4 [00:00<00:00, 13.02it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 1955.39it/s]\n",
            "Validation sid = 0.002056\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.08it/s]\n",
            "Model 0 best validation sid = 0.002056 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "100%|██████████| 1/1 [00:00<00:00, 3483.64it/s]\n",
            "Model 0 test sid = 0.003194\n",
            "100%|██████████| 1/1 [00:00<00:00, 2890.63it/s]\n",
            "Ensemble test sid = 0.003194\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test sid = 0.003194\n",
            "Overall test sid = 0.003194 +/- 0.000000\n",
            "Elapsed time = 0:00:03\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/spectra.csv',\n",
        "    '--dataset_type', 'spectra',\n",
        "    '--save_dir', 'test_checkpoints_spectra',\n",
        "    '--epochs', '5',\n",
        "    '--features_path', 'data/spectra_features.csv',\n",
        "    '--split_type', 'random_with_repeated_smiles',\n",
        "    '--save_smiles_splits'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2tFb6TKqj4y",
        "outputId": "9c16916d-fd25-47d4-9554-cdc63544fb08",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [00:00, 21715.27it/s]\n",
            "100%|██████████| 20/20 [00:00<00:00, 34923.43it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00, 1095.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_spectra.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_spectra/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_spectra.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_spectra',\n",
        "    '--features_path', 'data/spectra_features.csv'\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kinNKidqj4y"
      },
      "source": [
        "# Pretraining / Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM8pI9p6qj4y",
        "outputId": "650fd7e0-e9b6-4895-95f9-1368d80d7630"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': None,\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_transfer',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': True,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['logSolubility'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 111443.94it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 72653.80it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 55418.64it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "0it [00:00, ?it/s]Warning: Repeated SMILES found in data, pickle file of split indices cannot distinguish entries and will not be generated.\n",
            "276it [00:00, 81106.14it/s]\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of parameters = 355,201\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  9.02it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 10.07it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  9.61it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  9.72it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  8.96it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:00<00:00,  8.51it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:00<00:00,  8.17it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.706185\n",
            " 20%|██        | 1/5 [00:01<00:04,  1.15s/it]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  7.32it/s]\u001b[ALoss = 6.5336e-01, PNorm = 34.0271, GNorm = 6.2554, lr_0 = 7.1875e-04\n",
            "\n",
            " 25%|██▌       | 2/8 [00:00<00:00,  7.07it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00,  6.73it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  6.58it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  6.70it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  6.78it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:01<00:00,  7.02it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:01<00:00,  6.93it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.387877\n",
            " 40%|████      | 2/5 [00:02<00:03,  1.29s/it]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:00,  7.14it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00,  6.55it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00,  6.86it/s]\u001b[ALoss = 4.3137e-01, PNorm = 34.0799, GNorm = 5.1803, lr_0 = 6.1897e-04\n",
            "\n",
            " 50%|█████     | 4/8 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  7.08it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:00<00:00,  7.21it/s]\u001b[A\n",
            "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.432342\n",
            " 60%|██████    | 3/5 [00:03<00:02,  1.27s/it]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:00<00:01,  6.58it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00,  6.22it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00,  6.57it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00,  7.14it/s]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:00<00:00,  7.84it/s]\u001b[ALoss = 4.0926e-01, PNorm = 34.1025, GNorm = 6.6010, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00,  8.37it/s]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:01<00:00,  5.38it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.345148\n",
            " 80%|████████  | 4/5 [00:05<00:01,  1.30s/it]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:00<00:00, 11.57it/s]\u001b[A\n",
            " 50%|█████     | 4/8 [00:00<00:00, 10.71it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 10.93it/s]\u001b[ALoss = 3.1846e-01, PNorm = 34.1099, GNorm = 1.1095, lr_0 = 1.0000e-04\n",
            "\n",
            "100%|██████████| 8/8 [00:00<00:00, 11.14it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.262283\n",
            "100%|██████████| 5/5 [00:06<00:00,  1.20s/it]\n",
            "Model 0 best validation rmse = 1.262283 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test rmse = 1.657099\n",
            "Ensemble test rmse = 1.657099\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 1.657099\n",
            "Overall test rmse = 1.657099 +/- 0.000000\n",
            "Elapsed time = 0:00:07\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_transfer',\n",
        "    '--epochs', '5',\n",
        "    '--save_smiles_splits'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVDRXsCqj4z",
        "outputId": "0f7b4f86-fd1d-4317-e9b4-d1a3fe3eec62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Command line\n",
            "python /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-8f687a13-fd1d-4bb6-bf15-8368444c40f1.json\n",
            "Args\n",
            "{'activation': 'ReLU',\n",
            " 'adding_h': False,\n",
            " 'aggregation': 'mean',\n",
            " 'aggregation_norm': 100,\n",
            " 'atom_descriptor_scaling': True,\n",
            " 'atom_descriptors': None,\n",
            " 'atom_descriptors_path': None,\n",
            " 'atom_descriptors_size': 0,\n",
            " 'atom_features_size': 0,\n",
            " 'atom_messages': False,\n",
            " 'batch_size': 50,\n",
            " 'bias': False,\n",
            " 'bias_solvent': False,\n",
            " 'bond_feature_scaling': True,\n",
            " 'bond_features_path': None,\n",
            " 'bond_features_size': 0,\n",
            " 'cache_cutoff': 10000,\n",
            " 'checkpoint_dir': None,\n",
            " 'checkpoint_frzn': 'test_checkpoints_transfer/fold_0/model_0/model.pt',\n",
            " 'checkpoint_path': None,\n",
            " 'checkpoint_paths': None,\n",
            " 'class_balance': False,\n",
            " 'config_path': None,\n",
            " 'crossval_index_dir': None,\n",
            " 'crossval_index_file': None,\n",
            " 'crossval_index_sets': None,\n",
            " 'cuda': False,\n",
            " 'data_path': 'data/regression.csv',\n",
            " 'data_weights_path': None,\n",
            " 'dataset_type': 'regression',\n",
            " 'depth': 3,\n",
            " 'depth_solvent': 3,\n",
            " 'device': device(type='cpu'),\n",
            " 'dropout': 0.0,\n",
            " 'empty_cache': False,\n",
            " 'ensemble_size': 1,\n",
            " 'epochs': 5,\n",
            " 'evidential_regularization': 0,\n",
            " 'explicit_h': False,\n",
            " 'extra_metrics': [],\n",
            " 'features_generator': None,\n",
            " 'features_only': False,\n",
            " 'features_path': None,\n",
            " 'features_scaling': True,\n",
            " 'features_size': None,\n",
            " 'ffn_hidden_size': 300,\n",
            " 'ffn_num_layers': 2,\n",
            " 'final_lr': 0.0001,\n",
            " 'folds_file': None,\n",
            " 'freeze_first_only': False,\n",
            " 'frzn_ffn_layers': 0,\n",
            " 'gpu': None,\n",
            " 'grad_clip': None,\n",
            " 'hidden_size': 300,\n",
            " 'hidden_size_solvent': 300,\n",
            " 'ignore_columns': None,\n",
            " 'init_lr': 0.0001,\n",
            " 'log_frequency': 10,\n",
            " 'loss_function': 'mse',\n",
            " 'max_data_size': None,\n",
            " 'max_lr': 0.001,\n",
            " 'metric': 'rmse',\n",
            " 'metrics': ['rmse'],\n",
            " 'minimize_score': True,\n",
            " 'mpn_shared': False,\n",
            " 'multiclass_num_classes': 3,\n",
            " 'no_atom_descriptor_scaling': False,\n",
            " 'no_bond_features_scaling': False,\n",
            " 'no_cache_mol': False,\n",
            " 'no_cuda': False,\n",
            " 'no_features_scaling': False,\n",
            " 'num_folds': 1,\n",
            " 'num_lrs': 1,\n",
            " 'num_tasks': 1,\n",
            " 'num_workers': 8,\n",
            " 'number_of_molecules': 1,\n",
            " 'overwrite_default_atom_features': False,\n",
            " 'overwrite_default_bond_features': False,\n",
            " 'phase_features_path': None,\n",
            " 'pytorch_seed': 0,\n",
            " 'quiet': False,\n",
            " 'reaction': False,\n",
            " 'reaction_mode': 'reac_diff',\n",
            " 'reaction_solvent': False,\n",
            " 'resume_experiment': False,\n",
            " 'save_dir': 'test_checkpoints_transfer',\n",
            " 'save_preds': False,\n",
            " 'save_smiles_splits': False,\n",
            " 'seed': 0,\n",
            " 'separate_test_atom_descriptors_path': None,\n",
            " 'separate_test_bond_features_path': None,\n",
            " 'separate_test_features_path': None,\n",
            " 'separate_test_path': None,\n",
            " 'separate_test_phase_features_path': None,\n",
            " 'separate_val_atom_descriptors_path': None,\n",
            " 'separate_val_bond_features_path': None,\n",
            " 'separate_val_features_path': None,\n",
            " 'separate_val_path': None,\n",
            " 'separate_val_phase_features_path': None,\n",
            " 'show_individual_scores': False,\n",
            " 'smiles_columns': ['smiles'],\n",
            " 'spectra_activation': 'exp',\n",
            " 'spectra_phase_mask_path': None,\n",
            " 'spectra_target_floor': 1e-08,\n",
            " 'split_key_molecule': 0,\n",
            " 'split_sizes': [0.8, 0.1, 0.1],\n",
            " 'split_type': 'random',\n",
            " 'target_columns': None,\n",
            " 'target_weights': None,\n",
            " 'task_names': ['logSolubility'],\n",
            " 'test': False,\n",
            " 'test_fold_index': None,\n",
            " 'train_data_size': None,\n",
            " 'undirected': False,\n",
            " 'use_input_features': False,\n",
            " 'val_fold_index': None,\n",
            " 'warmup_epochs': 2.0}\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n",
            "500it [00:00, 109203.92it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 83936.44it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 99447.65it/s]\n",
            "Number of tasks = 1\n",
            "Fold 0\n",
            "Splitting data with seed 0\n",
            "Total size = 500 | train size = 400 | val size = 50 | test size = 50\n",
            "Fitting scaler\n",
            "Building model 0\n",
            "Loading and freezing parameters from test_checkpoints_transfer/fold_0/model_0/model.pt.\n",
            "MoleculeModel(\n",
            "  (encoder): MPN(\n",
            "    (encoder): ModuleList(\n",
            "      (0): MPNEncoder(\n",
            "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
            "        (act_func): ReLU()\n",
            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ffn): Sequential(\n",
            "    (0): Dropout(p=0.0, inplace=False)\n",
            "    (1): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.0, inplace=False)\n",
            "    (4): Linear(in_features=300, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Number of unfrozen parameters = 90,601\n",
            "Total number of parameters = 355,201\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]Epoch 0\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 24.62it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 24.17it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.297117\n",
            " 20%|██        | 1/5 [00:00<00:01,  2.05it/s]Epoch 1\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[ALoss = 3.4231e-01, PNorm = 34.0887, GNorm = 2.9127, lr_0 = 7.1875e-04\n",
            "\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 23.49it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 23.03it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.315881\n",
            " 40%|████      | 2/5 [00:00<00:01,  2.19it/s]Epoch 2\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 23.14it/s]\u001b[ALoss = 3.2340e-01, PNorm = 34.1111, GNorm = 2.3180, lr_0 = 6.1897e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 23.50it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.287416\n",
            " 60%|██████    | 3/5 [00:01<00:00,  2.07it/s]Epoch 3\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 22.48it/s]\u001b[ALoss = 3.2418e-01, PNorm = 34.1173, GNorm = 1.4311, lr_0 = 2.3714e-04\n",
            "\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 22.40it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.276664\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.01it/s]Epoch 4\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:00<00:00, 23.35it/s]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:00<00:00, 22.20it/s]\u001b[ALoss = 2.9644e-01, PNorm = 34.1190, GNorm = 0.9774, lr_0 = 1.0000e-04\n",
            "\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[AValidation rmse = 1.261734\n",
            "100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n",
            "Model 0 best validation rmse = 1.261734 on epoch 4\n",
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n",
            "Model 0 test rmse = 1.561036\n",
            "Ensemble test rmse = 1.561036\n",
            "1-fold cross validation\n",
            "\tSeed 0 ==> test rmse = 1.561036\n",
            "Overall test rmse = 1.561036 +/- 0.000000\n",
            "Elapsed time = 0:00:03\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--data_path', 'data/regression.csv',\n",
        "    '--dataset_type', 'regression',\n",
        "    '--save_dir', 'test_checkpoints_transfer',\n",
        "    '--epochs', '5',\n",
        "    '--checkpoint_frzn', 'test_checkpoints_transfer/fold_0/model_0/model.pt'\n",
        "]\n",
        "\n",
        "args = chemprop.args.TrainArgs().parse_args(arguments)\n",
        "mean_score, std_score = chemprop.train.cross_validate(args=args, train_func=chemprop.train.run_training)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKNdFKKqj4z",
        "outputId": "ff422d9e-9e5a-4d0e-d0aa-372e64cddf75",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training args\n",
            "Setting molecule featurization parameters to default.\n",
            "Loading data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50it [00:00, 110667.65it/s]\n",
            "100%|██████████| 50/50 [00:00<00:00, 80381.45it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating SMILES\n",
            "Test size = 50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
            "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
            "Loading pretrained parameter \"ffn.1.weight\".\n",
            "Loading pretrained parameter \"ffn.1.bias\".\n",
            "Loading pretrained parameter \"ffn.4.weight\".\n",
            "Loading pretrained parameter \"ffn.4.bias\".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving predictions to test_preds_transfer.csv\n",
            "Elapsed time = 0:00:01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "arguments = [\n",
        "    '--test_path', 'test_checkpoints_transfer/fold_0/test_smiles.csv',\n",
        "    '--preds_path', 'test_preds_transfer.csv',\n",
        "    '--checkpoint_dir', 'test_checkpoints_transfer',\n",
        "]\n",
        "\n",
        "args = chemprop.args.PredictArgs().parse_args(arguments)\n",
        "preds = chemprop.train.make_predictions(args=args)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chemprop_colab_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
